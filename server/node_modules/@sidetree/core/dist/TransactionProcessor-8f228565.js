import { _ as _catch, A as AnchorFile, M as MapFile, g as ArrayMethods, C as ChunkFile, h as _forTo, i as JsonAsync, j as _for } from './index-f6e63a58.js';
import { AnchoredDataSerializer, SidetreeError, ErrorCode, protocolParameters, FetchResultCode } from '@sidetree/common';
import 'fast-json-patch';
import 'jose';
import 'bip39';
import '@transmute/did-key-ed25519';
import 'hdkey';
import '@trust/keyto';
import '@transmute/did-key-secp256k1';
import 'time-span';
import 'crypto';
import { F as FeeManager, V as ValueTimeLockVerifier } from './ValueTimeLockVerifier-ce5b08d2.js';

/**
 * Implementation of the `ITransactionProcessor`.
 */

var TransactionProcessor = /*#__PURE__*/function () {
  function TransactionProcessor(downloadManager, operationStore, blockchain, versionMetadataFetcher) {
    this.downloadManager = downloadManager;
    this.operationStore = operationStore;
    this.blockchain = blockchain;
    this.versionMetadataFetcher = versionMetadataFetcher;
  }

  var _proto = TransactionProcessor.prototype;

  _proto.processTransaction = function processTransaction(transaction) {
    try {
      var _this2 = this;

      return Promise.resolve(_catch(function () {
        // Decode the anchor string.
        var anchoredData = AnchoredDataSerializer.deserialize(transaction.anchorString); // Verify enough fee paid.

        FeeManager.verifyTransactionFeeAndThrowOnError(transaction.transactionFeePaid, anchoredData.numberOfOperations, transaction.normalizedTransactionFee); // Download and verify anchor file.

        return Promise.resolve(_this2.downloadAndVerifyAnchorFile(transaction, anchoredData.anchorFileHash, anchoredData.numberOfOperations)).then(function (anchorFile) {
          // Download and verify map file.
          return Promise.resolve(_this2.downloadAndVerifyMapFile(anchorFile, anchoredData.numberOfOperations)).then(function (mapFile) {
            // Download and verify chunk file.
            return Promise.resolve(_this2.downloadAndVerifyChunkFile(mapFile)).then(function (chunkFileModel) {
              // Compose into operations from all the files downloaded.
              return Promise.resolve(_this2.composeAnchoredOperationModels(transaction, anchorFile, mapFile, chunkFileModel)).then(function (operations) {
                // If the code reaches here, it means that the batch of operations is valid, store the operations.
                return Promise.resolve(_this2.operationStore.put(operations)).then(function () {
                  return true;
                });
              });
            });
          });
        });
      }, function (error) {
        if (error instanceof SidetreeError) {
          // If error is potentially related to CAS network connectivity issues, we need to return false to retry later.
          if (error.code === ErrorCode.CasNotReachable || error.code === ErrorCode.CasFileNotFound) {
            return false;
          }

          console.info("Ignoring error: " + error.message);
          return true;
        } else {
          console.error("Unexpected error processing transaction, MUST investigate and fix: " + error.message);
          return false;
        }
      }));
    } catch (e) {
      return Promise.reject(e);
    }
  }
  /**
   * @param batchSize The size of the batch in number of operations.
   */
  ;

  _proto.downloadAndVerifyAnchorFile = function downloadAndVerifyAnchorFile(transaction, anchorFileHash, paidOperationCount) {
    try {
      var _this4 = this;

      // Verify the number of paid operations does not exceed the maximum allowed limit.
      if (paidOperationCount > protocolParameters.maxOperationsPerBatch) {
        throw new SidetreeError(ErrorCode.TransactionProcessorPaidOperationCountExceedsLimit, "Paid batch size of " + paidOperationCount + " operations exceeds the allowed limit of " + protocolParameters.maxOperationsPerBatch + ".");
      }

      console.info("Downloading anchor file '" + anchorFileHash + "', max file size limit " + protocolParameters.maxAnchorFileSizeInBytes + " bytes...");
      return Promise.resolve(_this4.downloadFileFromCas(anchorFileHash, protocolParameters.maxAnchorFileSizeInBytes)).then(function (fileBuffer) {
        return Promise.resolve(AnchorFile.parse(fileBuffer)).then(function (anchorFile) {
          function _temp(valueTimeLock) {
            ValueTimeLockVerifier.verifyLockAmountAndThrowOnError(valueTimeLock, paidOperationCount, transaction.transactionTime, transaction.writer, _this4.versionMetadataFetcher);
            return anchorFile;
          }

          var operationCountInAnchorFile = anchorFile.didUniqueSuffixes.length;

          if (operationCountInAnchorFile > paidOperationCount) {
            throw new SidetreeError(ErrorCode.AnchorFileOperationCountExceededPaidLimit, "Operation count " + operationCountInAnchorFile + " in anchor file exceeded limit of : " + paidOperationCount);
          } // Verify required lock if one was needed.


          var _anchorFile$model$wri = anchorFile.model.writer_lock_id;
          return _anchorFile$model$wri ? Promise.resolve(_this4.blockchain.getValueTimeLock(anchorFile.model.writer_lock_id)).then(_temp) : _temp(undefined);
        });
      });
    } catch (e) {
      return Promise.reject(e);
    }
  }
  /**
   * NOTE: In order to be forward-compatable with data-pruning feature,
   * we must continue to process the operations declared in the anchor file even if the map/chunk file is invalid.
   * This means that this method MUST ONLY throw errors that are retryable (e.g. network or file not found errors),
   * It is a design choice to hide the complexity of map file downloading and construction within this method,
   * instead of throwing errors and letting the caller handle them.
   * @returns `MapFile` if downloaded file is valid; `undefined` otherwise.
   * @throws SidetreeErrors that are retryable.
   */
  ;

  _proto.downloadAndVerifyMapFile = function downloadAndVerifyMapFile(anchorFile, paidOperationCount) {
    try {
      var _this6 = this;

      return Promise.resolve(_catch(function () {
        var anchorFileModel = anchorFile.model;
        console.info("Downloading map file '" + anchorFileModel.map_file_uri + "', max file size limit " + protocolParameters.maxMapFileSizeInBytes + "...");
        return Promise.resolve(_this6.downloadFileFromCas(anchorFileModel.map_file_uri, protocolParameters.maxMapFileSizeInBytes)).then(function (fileBuffer) {
          return Promise.resolve(MapFile.parse(fileBuffer)).then(function (mapFile) {
            // Calulate the max paid update operation count.
            var operationCountInAnchorFile = anchorFile.didUniqueSuffixes.length;
            var maxPaidUpdateOperationCount = paidOperationCount - operationCountInAnchorFile; // If the actual update operation count is greater than the max paid update operation count, the map file is invalid.

            var updateOperationCount = mapFile.updateOperations ? mapFile.updateOperations.length : 0;
            return updateOperationCount > maxPaidUpdateOperationCount ? undefined : ArrayMethods.areMutuallyExclusive(anchorFile.didUniqueSuffixes, mapFile.didUniqueSuffixes) ? mapFile : undefined;
          });
        });
      }, function (error) {
        if (error instanceof SidetreeError) {
          // If error is related to CAS network issues, we will surface them so retry can happen.
          if (error.code === ErrorCode.CasNotReachable || error.code === ErrorCode.CasFileNotFound) {
            throw error;
          }

          return undefined;
        } else {
          console.error("Unexpected error fetching map file " + anchorFile.model.map_file_uri + ", MUST investigate and fix: " + SidetreeError.stringify(error));
          return undefined;
        }
      }));
    } catch (e) {
      return Promise.reject(e);
    }
  }
  /**
   * NOTE: In order to be forward-compatable with data-pruning feature,
   * we must continue to process the operations declared in the anchor file even if the map/chunk file is invalid.
   * This means that this method MUST ONLY throw errors that are retryable (e.g. network or file not found errors),
   * It is a design choice to hide the complexity of chunk file downloading and construction within this method,
   * instead of throwing errors and letting the caller handle them.
   * @returns `ChunkFileModel` if downloaded file is valid; `undefined` otherwise.
   * @throws SidetreeErrors that are retryable.
   */
  ;

  _proto.downloadAndVerifyChunkFile = function downloadAndVerifyChunkFile(mapFile) {
    try {
      var _this8 = this;

      // Can't download chunk file if map file is not given.
      if (mapFile === undefined) {
        return Promise.resolve(undefined);
      }

      var chunkFileHash;
      return Promise.resolve(_catch(function () {
        chunkFileHash = mapFile.model.chunks[0].chunk_file_uri;
        console.info("Downloading chunk file '" + chunkFileHash + "', max size limit " + protocolParameters.maxChunkFileSizeInBytes + "...");
        return Promise.resolve(_this8.downloadFileFromCas(chunkFileHash, protocolParameters.maxChunkFileSizeInBytes)).then(function (fileBuffer) {
          return Promise.resolve(ChunkFile.parse(fileBuffer));
        });
      }, function (error) {
        if (error instanceof SidetreeError) {
          // If error is related to CAS network issues, we will surface them so retry can happen.
          if (error.code === ErrorCode.CasNotReachable || error.code === ErrorCode.CasFileNotFound) {
            throw error;
          }

          return undefined;
        } else {
          console.error("Unexpected error fetching chunk file " + chunkFileHash + ", MUST investigate and fix: " + SidetreeError.stringify(error));
          return undefined;
        }
      }));
    } catch (e) {
      return Promise.reject(e);
    }
  };

  _proto.composeAnchoredOperationModels = function composeAnchoredOperationModels(transaction, anchorFile, mapFile, chunkFile) {
    try {
      var _temp7 = function _temp7() {
        function _temp4() {
          // Add anchored timestamp to each operation.
          var anchoredOperationModels = [];

          for (var _i = 0; _i < operations.length; _i++) {
            var operation = operations[_i];
            var anchoredOperationModel = {
              didUniqueSuffix: operation.didUniqueSuffix,
              type: operation.type,
              operationBuffer: patchedOperationBuffers[_i],
              operationIndex: _i,
              transactionNumber: transaction.transactionNumber,
              transactionTime: transaction.transactionTime
            };
            anchoredOperationModels.push(anchoredOperationModel);
          }

          return anchoredOperationModels;
        }

        var _temp3 = _forTo(deactivateOperations, function (i) {
          var operation = deactivateOperations[i];
          var operationJsonString = operation.operationBuffer.toString();
          return Promise.resolve(JsonAsync.parse(operationJsonString)).then(function (operationObject) {
            operationObject.type = operation.type;
            var patchedOperationBuffer = Buffer.from(JSON.stringify(operationObject));
            patchedOperationBuffers.push(patchedOperationBuffer);
          });
        });

        return _temp3 && _temp3.then ? _temp3.then(_temp4) : _temp4(_temp3);
      };

      var createOperations = anchorFile.createOperations;
      var recoverOperations = anchorFile.recoverOperations;
      var deactivateOperations = anchorFile.deactivateOperations;
      var updateOperations = mapFile && mapFile.updateOperations ? mapFile.updateOperations : []; // Add the operations in the following order of types: create, recover, update, deactivate.

      var operations = [];
      operations.push.apply(operations, createOperations);
      operations.push.apply(operations, recoverOperations);
      operations.push.apply(operations, updateOperations);
      operations.push.apply(operations, deactivateOperations); // If chunk file is found/given, we need to add `type` and `delta` from chunk file to each operation.
      // NOTE: there is no delta for deactivate operations.

      var patchedOperationBuffers = [];

      var _temp8 = function () {
        if (chunkFile !== undefined) {
          // TODO: https://github.com/decentralized-identity/sidetree/issues/442
          // Use actual operation request object instead of buffer.
          var operationCountExcludingDeactivates = createOperations.length + recoverOperations.length + updateOperations.length;
          var _i2 = 0;

          var _temp9 = _for(function () {
            return _i2 < operationCountExcludingDeactivates && _i2 < chunkFile.deltas.length;
          }, function () {
            return _i2++;
          }, function () {
            var operation = operations[_i2];
            var operationJsonString = operation.operationBuffer.toString();
            return Promise.resolve(JsonAsync.parse(operationJsonString)).then(function (operationObject) {
              operationObject.type = operation.type;
              operationObject.delta = chunkFile.deltas[_i2];
              var patchedOperationBuffer = Buffer.from(JSON.stringify(operationObject));
              patchedOperationBuffers.push(patchedOperationBuffer);
            });
          });

          if (_temp9 && _temp9.then) return _temp9.then(function () {});
        }
      }();

      return Promise.resolve(_temp8 && _temp8.then ? _temp8.then(_temp7) : _temp7(_temp8));
    } catch (e) {
      return Promise.reject(e);
    }
  };

  _proto.downloadFileFromCas = function downloadFileFromCas(fileHash, maxFileSizeInBytes) {
    try {
      var _this10 = this;

      console.info("Downloading file '" + fileHash + "', max size limit " + maxFileSizeInBytes + "...");
      return Promise.resolve(_this10.downloadManager.download(fileHash, maxFileSizeInBytes)).then(function (fileFetchResult) {
        if (fileFetchResult.code === FetchResultCode.InvalidHash) {
          throw new SidetreeError(ErrorCode.CasFileHashNotValid, "File hash '" + fileHash + "' is not a valid hash.");
        }

        if (fileFetchResult.code === FetchResultCode.MaxSizeExceeded) {
          throw new SidetreeError(ErrorCode.CasFileTooLarge, "File '" + fileHash + "' exceeded max size limit of " + maxFileSizeInBytes + " bytes.");
        }

        if (fileFetchResult.code === FetchResultCode.NotAFile) {
          throw new SidetreeError(ErrorCode.CasFileNotAFile, "File hash '" + fileHash + "' points to a content that is not a file.");
        }

        if (fileFetchResult.code === FetchResultCode.CasNotReachable) {
          throw new SidetreeError(ErrorCode.CasNotReachable, "CAS not reachable for file '" + fileHash + "'.");
        }

        if (fileFetchResult.code === FetchResultCode.NotFound) {
          throw new SidetreeError(ErrorCode.CasFileNotFound, "File '" + fileHash + "' not found.");
        }

        console.info("File '" + fileHash + "' of size " + fileFetchResult.content.length + " downloaded.");
        return fileFetchResult.content;
      });
    } catch (e) {
      return Promise.reject(e);
    }
  };

  return TransactionProcessor;
}();

export default TransactionProcessor;
//# sourceMappingURL=TransactionProcessor-8f228565.js.map

{"version":3,"file":"TransactionProcessor-f7bea506.js","sources":["../src/TransactionProcessor.ts"],"sourcesContent":["/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AnchoredDataSerializer,\n  AnchoredOperationModel,\n  ChunkFileModel,\n  ErrorCode,\n  FetchResultCode,\n  IBlockchain,\n  IOperationStore,\n  ITransactionProcessor,\n  IVersionMetadataFetcher,\n  protocolParameters,\n  SidetreeError,\n  TransactionModel,\n} from '@sidetree/common';\nimport AnchorFile from './write/AnchorFile';\nimport ArrayMethods from './util/ArrayMethods';\nimport ChunkFile from './write/ChunkFile';\nimport DownloadManager from './DownloadManager';\nimport FeeManager from './FeeManager';\nimport JsonAsync from './util/JsonAsync';\nimport MapFile from './write/MapFile';\nimport ValueTimeLockVerifier from './ValueTimeLockVerifier';\n\n/**\n * Implementation of the `ITransactionProcessor`.\n */\nexport default class TransactionProcessor implements ITransactionProcessor {\n  public constructor(\n    private downloadManager: DownloadManager,\n    private operationStore: IOperationStore,\n    private blockchain: IBlockchain,\n    private versionMetadataFetcher: IVersionMetadataFetcher\n  ) {}\n\n  public async processTransaction(\n    transaction: TransactionModel\n  ): Promise<boolean> {\n    try {\n      // Decode the anchor string.\n      const anchoredData = AnchoredDataSerializer.deserialize(\n        transaction.anchorString\n      );\n\n      // Verify enough fee paid.\n      FeeManager.verifyTransactionFeeAndThrowOnError(\n        transaction.transactionFeePaid,\n        anchoredData.numberOfOperations,\n        transaction.normalizedTransactionFee\n      );\n\n      // Download and verify anchor file.\n      const anchorFile = await this.downloadAndVerifyAnchorFile(\n        transaction,\n        anchoredData.anchorFileHash,\n        anchoredData.numberOfOperations\n      );\n\n      // Download and verify map file.\n      const mapFile = await this.downloadAndVerifyMapFile(\n        anchorFile,\n        anchoredData.numberOfOperations\n      );\n\n      // Download and verify chunk file.\n      const chunkFileModel = await this.downloadAndVerifyChunkFile(mapFile);\n\n      // Compose into operations from all the files downloaded.\n      const operations = await this.composeAnchoredOperationModels(\n        transaction,\n        anchorFile,\n        mapFile,\n        chunkFileModel\n      );\n\n      // If the code reaches here, it means that the batch of operations is valid, store the operations.\n      await this.operationStore.put(operations);\n\n      return true;\n    } catch (error) {\n      if (error instanceof SidetreeError) {\n        // If error is potentially related to CAS network connectivity issues, we need to return false to retry later.\n        if (\n          error.code === ErrorCode.CasNotReachable ||\n          error.code === ErrorCode.CasFileNotFound\n        ) {\n          return false;\n        }\n\n        console.info(`Ignoring error: ${error.message}`);\n        return true;\n      } else {\n        console.error(\n          `Unexpected error processing transaction, MUST investigate and fix: ${error.message}`\n        );\n        return false;\n      }\n    }\n  }\n\n  /**\n   * @param batchSize The size of the batch in number of operations.\n   */\n  private async downloadAndVerifyAnchorFile(\n    transaction: TransactionModel,\n    anchorFileHash: string,\n    paidOperationCount: number\n  ): Promise<AnchorFile> {\n    // Verify the number of paid operations does not exceed the maximum allowed limit.\n    if (paidOperationCount > protocolParameters.maxOperationsPerBatch) {\n      throw new SidetreeError(\n        ErrorCode.TransactionProcessorPaidOperationCountExceedsLimit,\n        `Paid batch size of ${paidOperationCount} operations exceeds the allowed limit of ${protocolParameters.maxOperationsPerBatch}.`\n      );\n    }\n\n    console.info(\n      `Downloading anchor file '${anchorFileHash}', max file size limit ${protocolParameters.maxAnchorFileSizeInBytes} bytes...`\n    );\n\n    const fileBuffer = await this.downloadFileFromCas(\n      anchorFileHash,\n      protocolParameters.maxAnchorFileSizeInBytes\n    );\n    const anchorFile = await AnchorFile.parse(fileBuffer);\n\n    const operationCountInAnchorFile = anchorFile.didUniqueSuffixes.length;\n    if (operationCountInAnchorFile > paidOperationCount) {\n      throw new SidetreeError(\n        ErrorCode.AnchorFileOperationCountExceededPaidLimit,\n        `Operation count ${operationCountInAnchorFile} in anchor file exceeded limit of : ${paidOperationCount}`\n      );\n    }\n\n    // Verify required lock if one was needed.\n    const valueTimeLock = anchorFile.model.writer_lock_id\n      ? await this.blockchain.getValueTimeLock(anchorFile.model.writer_lock_id)\n      : undefined;\n    ValueTimeLockVerifier.verifyLockAmountAndThrowOnError(\n      valueTimeLock,\n      paidOperationCount,\n      transaction.transactionTime,\n      transaction.writer,\n      this.versionMetadataFetcher\n    );\n\n    return anchorFile;\n  }\n\n  /**\n   * NOTE: In order to be forward-compatable with data-pruning feature,\n   * we must continue to process the operations declared in the anchor file even if the map/chunk file is invalid.\n   * This means that this method MUST ONLY throw errors that are retryable (e.g. network or file not found errors),\n   * It is a design choice to hide the complexity of map file downloading and construction within this method,\n   * instead of throwing errors and letting the caller handle them.\n   * @returns `MapFile` if downloaded file is valid; `undefined` otherwise.\n   * @throws SidetreeErrors that are retryable.\n   */\n  private async downloadAndVerifyMapFile(\n    anchorFile: AnchorFile,\n    paidOperationCount: number\n  ): Promise<MapFile | undefined> {\n    try {\n      const anchorFileModel = anchorFile.model;\n      console.info(\n        `Downloading map file '${anchorFileModel.map_file_uri}', max file size limit ${protocolParameters.maxMapFileSizeInBytes}...`\n      );\n\n      const fileBuffer = await this.downloadFileFromCas(\n        anchorFileModel.map_file_uri,\n        protocolParameters.maxMapFileSizeInBytes\n      );\n      const mapFile = await MapFile.parse(fileBuffer);\n\n      // Calulate the max paid update operation count.\n      const operationCountInAnchorFile = anchorFile.didUniqueSuffixes.length;\n      const maxPaidUpdateOperationCount =\n        paidOperationCount - operationCountInAnchorFile;\n\n      // If the actual update operation count is greater than the max paid update operation count, the map file is invalid.\n      const updateOperationCount = mapFile.updateOperations\n        ? mapFile.updateOperations.length\n        : 0;\n      if (updateOperationCount > maxPaidUpdateOperationCount) {\n        return undefined;\n      }\n\n      // If we find operations for the same DID between anchor and map files, the map file is invalid.\n      if (\n        !ArrayMethods.areMutuallyExclusive(\n          anchorFile.didUniqueSuffixes,\n          mapFile.didUniqueSuffixes\n        )\n      ) {\n        return undefined;\n      }\n\n      return mapFile;\n    } catch (error) {\n      if (error instanceof SidetreeError) {\n        // If error is related to CAS network issues, we will surface them so retry can happen.\n        if (\n          error.code === ErrorCode.CasNotReachable ||\n          error.code === ErrorCode.CasFileNotFound\n        ) {\n          throw error;\n        }\n\n        return undefined;\n      } else {\n        console.error(\n          `Unexpected error fetching map file ${\n            anchorFile.model.map_file_uri\n          }, MUST investigate and fix: ${SidetreeError.stringify(error)}`\n        );\n        return undefined;\n      }\n    }\n  }\n\n  /**\n   * NOTE: In order to be forward-compatable with data-pruning feature,\n   * we must continue to process the operations declared in the anchor file even if the map/chunk file is invalid.\n   * This means that this method MUST ONLY throw errors that are retryable (e.g. network or file not found errors),\n   * It is a design choice to hide the complexity of chunk file downloading and construction within this method,\n   * instead of throwing errors and letting the caller handle them.\n   * @returns `ChunkFileModel` if downloaded file is valid; `undefined` otherwise.\n   * @throws SidetreeErrors that are retryable.\n   */\n  private async downloadAndVerifyChunkFile(\n    mapFile: MapFile | undefined\n  ): Promise<ChunkFileModel | undefined> {\n    // Can't download chunk file if map file is not given.\n    if (mapFile === undefined) {\n      return undefined;\n    }\n\n    let chunkFileHash;\n    try {\n      chunkFileHash = mapFile.model.chunks[0].chunk_file_uri;\n      console.info(\n        `Downloading chunk file '${chunkFileHash}', max size limit ${protocolParameters.maxChunkFileSizeInBytes}...`\n      );\n\n      const fileBuffer = await this.downloadFileFromCas(\n        chunkFileHash,\n        protocolParameters.maxChunkFileSizeInBytes\n      );\n      const chunkFileModel = await ChunkFile.parse(fileBuffer);\n\n      return chunkFileModel;\n    } catch (error) {\n      if (error instanceof SidetreeError) {\n        // If error is related to CAS network issues, we will surface them so retry can happen.\n        if (\n          error.code === ErrorCode.CasNotReachable ||\n          error.code === ErrorCode.CasFileNotFound\n        ) {\n          throw error;\n        }\n\n        return undefined;\n      } else {\n        console.error(\n          `Unexpected error fetching chunk file ${chunkFileHash}, MUST investigate and fix: ${SidetreeError.stringify(\n            error\n          )}`\n        );\n        return undefined;\n      }\n    }\n  }\n\n  private async composeAnchoredOperationModels(\n    transaction: TransactionModel,\n    anchorFile: AnchorFile,\n    mapFile: MapFile | undefined,\n    chunkFile: ChunkFileModel | undefined\n  ): Promise<AnchoredOperationModel[]> {\n    const createOperations = anchorFile.createOperations;\n    const recoverOperations = anchorFile.recoverOperations;\n    const deactivateOperations = anchorFile.deactivateOperations;\n    const updateOperations =\n      mapFile && mapFile.updateOperations ? mapFile.updateOperations : [];\n\n    // Add the operations in the following order of types: create, recover, update, deactivate.\n    const operations = [];\n    operations.push(...createOperations);\n    operations.push(...recoverOperations);\n    operations.push(...updateOperations);\n    operations.push(...deactivateOperations);\n\n    // If chunk file is found/given, we need to add `type` and `delta` from chunk file to each operation.\n    // NOTE: there is no delta for deactivate operations.\n    const patchedOperationBuffers: Buffer[] = [];\n    if (chunkFile !== undefined) {\n      // TODO: https://github.com/decentralized-identity/sidetree/issues/442\n      // Use actual operation request object instead of buffer.\n\n      const operationCountExcludingDeactivates =\n        createOperations.length +\n        recoverOperations.length +\n        updateOperations.length;\n      for (\n        let i = 0;\n        i < operationCountExcludingDeactivates && i < chunkFile.deltas.length;\n        i++\n      ) {\n        const operation = operations[i];\n        const operationJsonString = operation.operationBuffer.toString();\n        const operationObject = await JsonAsync.parse(operationJsonString);\n        operationObject.type = operation.type;\n        operationObject.delta = chunkFile.deltas[i];\n\n        const patchedOperationBuffer = Buffer.from(\n          JSON.stringify(operationObject)\n        );\n        patchedOperationBuffers.push(patchedOperationBuffer);\n      }\n    }\n\n    for (let i = 0; i < deactivateOperations.length; i++) {\n      const operation = deactivateOperations[i];\n      const operationJsonString = operation.operationBuffer.toString();\n      const operationObject = await JsonAsync.parse(operationJsonString);\n      operationObject.type = operation.type;\n\n      const patchedOperationBuffer = Buffer.from(\n        JSON.stringify(operationObject)\n      );\n      patchedOperationBuffers.push(patchedOperationBuffer);\n    }\n\n    // Add anchored timestamp to each operation.\n    const anchoredOperationModels = [];\n    for (let i = 0; i < operations.length; i++) {\n      const operation = operations[i];\n\n      const anchoredOperationModel: AnchoredOperationModel = {\n        didUniqueSuffix: operation.didUniqueSuffix,\n        type: operation.type,\n        operationBuffer: patchedOperationBuffers[i],\n        operationIndex: i,\n        transactionNumber: transaction.transactionNumber,\n        transactionTime: transaction.transactionTime,\n      };\n\n      anchoredOperationModels.push(anchoredOperationModel);\n    }\n    return anchoredOperationModels;\n  }\n\n  private async downloadFileFromCas(\n    fileHash: string,\n    maxFileSizeInBytes: number\n  ): Promise<Buffer> {\n    console.info(\n      `Downloading file '${fileHash}', max size limit ${maxFileSizeInBytes}...`\n    );\n\n    const fileFetchResult = await this.downloadManager.download(\n      fileHash,\n      maxFileSizeInBytes\n    );\n\n    if (fileFetchResult.code === FetchResultCode.InvalidHash) {\n      throw new SidetreeError(\n        ErrorCode.CasFileHashNotValid,\n        `File hash '${fileHash}' is not a valid hash.`\n      );\n    }\n\n    if (fileFetchResult.code === FetchResultCode.MaxSizeExceeded) {\n      throw new SidetreeError(\n        ErrorCode.CasFileTooLarge,\n        `File '${fileHash}' exceeded max size limit of ${maxFileSizeInBytes} bytes.`\n      );\n    }\n\n    if (fileFetchResult.code === FetchResultCode.NotAFile) {\n      throw new SidetreeError(\n        ErrorCode.CasFileNotAFile,\n        `File hash '${fileHash}' points to a content that is not a file.`\n      );\n    }\n\n    if (fileFetchResult.code === FetchResultCode.CasNotReachable) {\n      throw new SidetreeError(\n        ErrorCode.CasNotReachable,\n        `CAS not reachable for file '${fileHash}'.`\n      );\n    }\n\n    if (fileFetchResult.code === FetchResultCode.NotFound) {\n      throw new SidetreeError(\n        ErrorCode.CasFileNotFound,\n        `File '${fileHash}' not found.`\n      );\n    }\n\n    console.info(\n      `File '${fileHash}' of size ${\n        fileFetchResult.content!.length\n      } downloaded.`\n    );\n\n    return fileFetchResult.content!;\n  }\n}\n"],"names":["downloadManager","operationStore","blockchain","versionMetadataFetcher","processTransaction","transaction","this","anchoredData","AnchoredDataSerializer","deserialize","anchorString","FeeManager","verifyTransactionFeeAndThrowOnError","transactionFeePaid","numberOfOperations","normalizedTransactionFee","_this2","downloadAndVerifyAnchorFile","anchorFileHash","anchorFile","downloadAndVerifyMapFile","mapFile","downloadAndVerifyChunkFile","chunkFileModel","composeAnchoredOperationModels","operations","put","error","SidetreeError","code","ErrorCode","CasNotReachable","CasFileNotFound","console","info","message","paidOperationCount","protocolParameters","maxOperationsPerBatch","TransactionProcessorPaidOperationCountExceedsLimit","maxAnchorFileSizeInBytes","_this4","downloadFileFromCas","fileBuffer","AnchorFile","parse","valueTimeLock","ValueTimeLockVerifier","verifyLockAmountAndThrowOnError","transactionTime","writer","operationCountInAnchorFile","didUniqueSuffixes","length","AnchorFileOperationCountExceededPaidLimit","model","writer_lock_id","getValueTimeLock","undefined","anchorFileModel","map_file_uri","maxMapFileSizeInBytes","_this6","MapFile","updateOperations","ArrayMethods","areMutuallyExclusive","stringify","chunkFileHash","chunks","chunk_file_uri","maxChunkFileSizeInBytes","_this8","ChunkFile","chunkFile","anchoredOperationModels","i","operation","push","didUniqueSuffix","type","operationBuffer","patchedOperationBuffers","operationIndex","transactionNumber","deactivateOperations","operationJsonString","toString","JsonAsync","operationObject","patchedOperationBuffer","Buffer","from","JSON","createOperations","recoverOperations","operationCountExcludingDeactivates","deltas","delta","fileHash","maxFileSizeInBytes","download","fileFetchResult","FetchResultCode","InvalidHash","CasFileHashNotValid","MaxSizeExceeded","CasFileTooLarge","NotAFile","CasFileNotAFile","NotFound","content"],"mappings":"qYA+CYA,EACAC,EACAC,EACAC,wBAHAH,sBACAC,kBACAC,8BACAC,6BAGGC,4BACXC,aAgB2BC,qDAZnBC,EAAeC,yBAAuBC,YAC1CJ,EAAYK,qBAIdC,aAAWC,oCACTP,EAAYQ,mBACZN,EAAaO,mBACbT,EAAYU,0CAIWC,EAAKC,4BAC5BZ,EACAE,EAAaW,eACbX,EAAaO,oCAHTK,0BAOgBH,EAAKI,yBACzBD,EACAZ,EAAaO,oCAFTO,0BAMuBL,EAAKM,2BAA2BD,mBAAvDE,0BAGmBP,EAAKQ,+BAC5BnB,EACAc,EACAE,EACAE,mBAJIE,0BAQAT,EAAKf,eAAeyB,IAAID,4BAEvB,6BACAE,UACHA,aAAiBC,gBAGjBD,EAAME,OAASC,YAAUC,iBACzBJ,EAAME,OAASC,YAAUE,kBAK3BC,QAAQC,wBAAwBP,EAAMQ,UAC/B,IAEPF,QAAQN,4EACgEA,EAAMQ,UAEvE,6CAQClB,qCACZZ,EACAa,EACAkB,aAcyB9B,QAXrB8B,EAAqBC,qBAAmBC,4BACpC,IAAIV,gBACRE,YAAUS,yEACYH,8CAA8DC,qBAAmBC,kCAI3GL,QAAQC,iCACsBhB,4BAAwCmB,qBAAmBG,sDAGhEC,EAAKC,oBAC5BxB,EACAmB,qBAAmBG,0CAFfG,0BAImBC,aAAWC,MAAMF,mBAApCxB,cAWA2B,UAGNC,wBAAsBC,gCACpBF,EACAV,EACA/B,EAAY4C,gBACZ5C,EAAY6C,OACZT,EAAKtC,wBAGAgB,MApBDgC,EAA6BhC,EAAWiC,kBAAkBC,UAC5DF,EAA6Bf,QACzB,IAAIR,gBACRE,YAAUwB,6DACSH,yCAAiEf,UAKlEjB,EAAWoC,MAAMC,+BAC7Bf,EAAKvC,WAAWuD,iBAAiBtC,EAAWoC,MAAMC,gCACxDE,+CAqBQtC,kCACZD,EACAiB,aAQ2B9B,qDALnBqD,EAAkBxC,EAAWoC,aACnCtB,QAAQC,8BACmByB,EAAgBC,uCAAsCvB,qBAAmBwB,6CAG3EC,EAAKpB,oBAC5BiB,EAAgBC,aAChBvB,qBAAmBwB,uCAFflB,0BAIgBoB,UAAQlB,MAAMF,mBAA9BtB,UAQuBA,EAAQ2C,iBACjC3C,EAAQ2C,iBAAiBX,OACzB,GALFjB,EAFiCjB,EAAWiC,kBAAkBC,YASvDK,EAKNO,eAAaC,qBACZ/C,EAAWiC,kBACX/B,EAAQ+B,mBAML/B,OAHEqC,oBAIF/B,MACHA,aAAiBC,oBAGjBD,EAAME,OAASC,YAAUC,iBACzBJ,EAAME,OAASC,YAAUE,sBAEnBL,OAKRM,QAAQN,4CAEJR,EAAWoC,MAAMK,4CACYhC,gBAAcuC,UAAUxC,8CAgBjDL,oCACZD,WAOI+C,IAOuB9D,iCAXXoD,IAAZrC,OACKqC,8BAKPU,EAAgB/C,EAAQkC,MAAMc,OAAO,GAAGC,eACxCrC,QAAQC,gCACqBkC,uBAAkC/B,qBAAmBkC,+CAGzDC,EAAK9B,oBAC5B0B,EACA/B,qBAAmBkC,yCAFf5B,0BAIuB8B,YAAU5B,MAAMF,mBAGtChB,MACHA,aAAiBC,oBAGjBD,EAAME,OAASC,YAAUC,iBACzBJ,EAAME,OAASC,YAAUE,sBAEnBL,OAKRM,QAAQN,8CACkCyC,iCAA4CxC,gBAAcuC,UAChGxC,8CAQIH,wCACZnB,EACAc,EACAE,EACAqD,6CAyDMC,EAA0B,GACvBC,EAAI,EAAGA,EAAInD,EAAW4B,OAAQuB,IAAK,KACpCC,EAAYpD,EAAWmD,GAW7BD,EAAwBG,KAT+B,CACrDC,gBAAiBF,EAAUE,gBAC3BC,KAAMH,EAAUG,KAChBC,gBAAiBC,EAAwBN,GACzCO,eAAgBP,EAChBQ,kBAAmB/E,EAAY+E,kBAC/BnC,gBAAiB5C,EAAY4C,yBAK1B0B,iBA5BaU,YAAXT,OACDC,EAAYQ,EAAqBT,GACjCU,EAAsBT,EAAUI,gBAAgBM,kCACxBC,YAAU3C,MAAMyC,mBAAxCG,GACNA,EAAgBT,KAAOH,EAAUG,SAE3BU,EAAyBC,OAAOC,KACpCC,KAAK1B,UAAUsB,IAEjBP,EAAwBJ,KAAKY,yCAnDzBI,EAAmB3E,EAAW2E,iBAC9BC,EAAoB5E,EAAW4E,kBAC/BV,EAAuBlE,EAAWkE,qBAClCrB,EACJ3C,GAAWA,EAAQ2C,iBAAmB3C,EAAQ2C,iBAAmB,GAG7DvC,EAAa,GACnBA,EAAWqD,WAAXrD,EAAmBqE,GACnBrE,EAAWqD,WAAXrD,EAAmBsE,GACnBtE,EAAWqD,WAAXrD,EAAmBuC,GACnBvC,EAAWqD,WAAXrD,EAAmB4D,OAIbH,EAAoC,wBACxBxB,IAAdgB,OAIIsB,EACJF,EAAiBzC,OACjB0C,EAAkB1C,OAClBW,EAAiBX,OAEbuB,EAAI,8BACRA,EAAIoB,GAAsCpB,EAAIF,EAAUuB,OAAO5C,4BAC/DuB,sBAEMC,EAAYpD,EAAWmD,GACvBU,EAAsBT,EAAUI,gBAAgBM,kCACxBC,YAAU3C,MAAMyC,mBAAxCG,GACNA,EAAgBT,KAAOH,EAAUG,KACjCS,EAAgBS,MAAQxB,EAAUuB,OAAOrB,OAEnCc,EAAyBC,OAAOC,KACpCC,KAAK1B,UAAUsB,IAEjBP,EAAwBJ,KAAKY,8IAmCrBhD,6BACZyD,EACAC,cAEAnE,QAAQC,0BACeiE,uBAA6BC,yBAGtB9F,KAAKN,gBAAgBqG,SACjDF,EACAC,mBAFIE,MAKFA,EAAgBzE,OAAS0E,kBAAgBC,kBACrC,IAAI5E,gBACRE,YAAU2E,kCACIN,+BAIdG,EAAgBzE,OAAS0E,kBAAgBG,sBACrC,IAAI9E,gBACRE,YAAU6E,yBACDR,kCAAwCC,gBAIjDE,EAAgBzE,OAAS0E,kBAAgBK,eACrC,IAAIhF,gBACRE,YAAU+E,8BACIV,kDAIdG,EAAgBzE,OAAS0E,kBAAgBxE,sBACrC,IAAIH,gBACRE,YAAUC,+CACqBoE,WAI/BG,EAAgBzE,OAAS0E,kBAAgBO,eACrC,IAAIlF,gBACRE,YAAUE,yBACDmE,yBAIblE,QAAQC,cACGiE,eACPG,EAAgBS,QAAS1D,uBAItBiD,EAAgBS"}
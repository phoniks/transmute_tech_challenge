{"version":3,"file":"index-0a641848.js","sources":["../node_modules/babel-plugin-transform-async-to-promises/helpers.js","../src/util/ArrayMethods.ts","../src/util/Compressor.ts","../src/DocumentComposer.ts","../src/util/JsonAsync.ts","../src/OperationUtils.ts","../src/CreateOperation.ts","../src/util/Jwk.ts","../src/util/Jws.ts","../src/DeactivateOperation.ts","../src/RecoverOperation.ts","../src/write/AnchorFile.ts","../src/write/BatchScheduler.ts","../src/write/ChunkFile.ts","../src/DownloadManager.ts","../src/UpdateOperation.ts","../src/write/MapFile.ts","../src/ThroughputLimiter.ts","../src/Observer.ts","../src/Operation.ts","../src/test/generators/OperationGenerator.ts","../src/Resolver.ts","../src/ServiceInfoProvider.ts","../src/VersionManager.ts"],"sourcesContent":["// A type of promise-like that resolves synchronously and supports only one observer\nexport const _Pact = /*#__PURE__*/(function() {\n\tfunction _Pact() {}\n\t_Pact.prototype.then = function(onFulfilled, onRejected) {\n\t\tconst result = new _Pact();\n\t\tconst state = this.s;\n\t\tif (state) {\n\t\t\tconst callback = state & 1 ? onFulfilled : onRejected;\n\t\t\tif (callback) {\n\t\t\t\ttry {\n\t\t\t\t\t_settle(result, 1, callback(this.v));\n\t\t\t\t} catch (e) {\n\t\t\t\t\t_settle(result, 2, e);\n\t\t\t\t}\n\t\t\t\treturn result;\n\t\t\t} else {\n\t\t\t\treturn this;\n\t\t\t}\n\t\t}\n\t\tthis.o = function(_this) {\n\t\t\ttry {\n\t\t\t\tconst value = _this.v;\n\t\t\t\tif (_this.s & 1) {\n\t\t\t\t\t_settle(result, 1, onFulfilled ? onFulfilled(value) : value);\n\t\t\t\t} else if (onRejected) {\n\t\t\t\t\t_settle(result, 1, onRejected(value));\n\t\t\t\t} else {\n\t\t\t\t\t_settle(result, 2, value);\n\t\t\t\t}\n\t\t\t} catch (e) {\n\t\t\t\t_settle(result, 2, e);\n\t\t\t}\n\t\t};\n\t\treturn result;\n\t}\n\treturn _Pact;\n})();\n\n// Settles a pact synchronously\nexport function _settle(pact, state, value) {\n\tif (!pact.s) {\n\t\tif (value instanceof _Pact) {\n\t\t\tif (value.s) {\n\t\t\t\tif (state & 1) {\n\t\t\t\t\tstate = value.s;\n\t\t\t\t}\n\t\t\t\tvalue = value.v;\n\t\t\t} else {\n\t\t\t\tvalue.o = _settle.bind(null, pact, state);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tif (value && value.then) {\n\t\t\tvalue.then(_settle.bind(null, pact, state), _settle.bind(null, pact, 2));\n\t\t\treturn;\n\t\t}\n\t\tpact.s = state;\n\t\tpact.v = value;\n\t\tconst observer = pact.o;\n\t\tif (observer) {\n\t\t\tobserver(pact);\n\t\t}\n\t}\n}\n\nexport function _isSettledPact(thenable) {\n\treturn thenable instanceof _Pact && thenable.s & 1;\n}\n\n// Converts argument to a function that always returns a Promise\nexport function _async(f) {\n\treturn function() {\n\t\tfor (var args = [], i = 0; i < arguments.length; i++) {\n\t\t\targs[i] = arguments[i];\n\t\t}\n\t\ttry {\n\t\t\treturn Promise.resolve(f.apply(this, args));\n\t\t} catch(e) {\n\t\t\treturn Promise.reject(e);\n\t\t}\n\t}\n}\n\n// Awaits on a value that may or may not be a Promise (equivalent to the await keyword in ES2015, with continuations passed explicitly)\nexport function _await(value, then, direct) {\n\tif (direct) {\n\t\treturn then ? then(value) : value;\n\t}\n\tif (!value || !value.then) {\n\t\tvalue = Promise.resolve(value);\n\t}\n\treturn then ? value.then(then) : value;\n}\n\n// Awaits on a value that may or may not be a Promise, then ignores it\nexport function _awaitIgnored(value, direct) {\n\tif (!direct) {\n\t\treturn value && value.then ? value.then(_empty) : Promise.resolve();\n\t}\n}\n\n// Proceeds after a value has resolved, or proceeds immediately if the value is not thenable\nexport function _continue(value, then) {\n\treturn value && value.then ? value.then(then) : then(value);\n}\n\n// Proceeds after a value has resolved, or proceeds immediately if the value is not thenable\nexport function _continueIgnored(value) {\n\tif (value && value.then) {\n\t\treturn value.then(_empty);\n\t}\n}\n\n// Asynchronously iterate through an object that has a length property, passing the index as the first argument to the callback (even as the length property changes)\nexport function _forTo(array, body, check) {\n\tvar i = -1, pact, reject;\n\tfunction _cycle(result) {\n\t\ttry {\n\t\t\twhile (++i < array.length && (!check || !check())) {\n\t\t\t\tresult = body(i);\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\t\tresult = result.v;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresult.then(_cycle, reject || (reject = _settle.bind(null, pact = new _Pact(), 2)));\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (pact) {\n\t\t\t\t_settle(pact, 1, result);\n\t\t\t} else {\n\t\t\t\tpact = result;\n\t\t\t}\n\t\t} catch (e) {\n\t\t\t_settle(pact || (pact = new _Pact()), 2, e);\n\t\t}\n\t}\n\t_cycle();\n\treturn pact;\n}\n\n// Asynchronously iterate through an object's properties (including properties inherited from the prototype)\n// Uses a snapshot of the object's properties\nexport function _forIn(target, body, check) {\n\tvar keys = [];\n\tfor (var key in target) {\n\t\tkeys.push(key);\n\t}\n\treturn _forTo(keys, function(i) { return body(keys[i]); }, check);\n}\n\n// Asynchronously iterate through an object's own properties (excluding properties inherited from the prototype)\n// Uses a snapshot of the object's properties\nexport function _forOwn(target, body, check) {\n\tvar keys = [];\n\tfor (var key in target) {\n\t\tif (Object.prototype.hasOwnProperty.call(target, key)) {\n\t\t\tkeys.push(key);\n\t\t}\n\t}\n\treturn _forTo(keys, function(i) { return body(keys[i]); }, check);\n}\n\nexport const _iteratorSymbol = /*#__PURE__*/ typeof Symbol !== \"undefined\" ? (Symbol.iterator || (Symbol.iterator = Symbol(\"Symbol.iterator\"))) : \"@@iterator\";\n\n// Asynchronously iterate through an object's values\n// Uses for...of if the runtime supports it, otherwise iterates until length on a copy\nexport function _forOf(target, body, check) {\n\tif (typeof target[_iteratorSymbol] === \"function\") {\n\t\tvar iterator = target[_iteratorSymbol](), step, pact, reject;\n\t\tfunction _cycle(result) {\n\t\t\ttry {\n\t\t\t\twhile (!(step = iterator.next()).done && (!check || !check())) {\n\t\t\t\t\tresult = body(step.value);\n\t\t\t\t\tif (result && result.then) {\n\t\t\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\t\t\tresult = result.v;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tresult.then(_cycle, reject || (reject = _settle.bind(null, pact = new _Pact(), 2)));\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (pact) {\n\t\t\t\t\t_settle(pact, 1, result);\n\t\t\t\t} else {\n\t\t\t\t\tpact = result;\n\t\t\t\t}\n\t\t\t} catch (e) {\n\t\t\t\t_settle(pact || (pact = new _Pact()), 2, e);\n\t\t\t}\n\t\t}\n\t\t_cycle();\n\t\tif (iterator.return) {\n\t\t\tvar _fixup = function(value) {\n\t\t\t\ttry {\n\t\t\t\t\tif (!step.done) {\n\t\t\t\t\t\titerator.return();\n\t\t\t\t\t}\n\t\t\t\t} catch(e) {\n\t\t\t\t}\n\t\t\t\treturn value;\n\t\t\t}\n\t\t\tif (pact && pact.then) {\n\t\t\t\treturn pact.then(_fixup, function(e) {\n\t\t\t\t\tthrow _fixup(e);\n\t\t\t\t});\n\t\t\t}\n\t\t\t_fixup();\n\t\t}\n\t\treturn pact;\n\t}\n\t// No support for Symbol.iterator\n\tif (!(\"length\" in target)) {\n\t\tthrow new TypeError(\"Object is not iterable\");\n\t}\n\t// Handle live collections properly\n\tvar values = [];\n\tfor (var i = 0; i < target.length; i++) {\n\t\tvalues.push(target[i]);\n\t}\n\treturn _forTo(values, function(i) { return body(values[i]); }, check);\n}\n\nexport const _asyncIteratorSymbol = /*#__PURE__*/ typeof Symbol !== \"undefined\" ? (Symbol.asyncIterator || (Symbol.asyncIterator = Symbol(\"Symbol.asyncIterator\"))) : \"@@asyncIterator\";\n\n// Asynchronously iterate on a value using it's async iterator if present, or its synchronous iterator if missing\nexport function _forAwaitOf(target, body, check) {\n\tif (typeof target[_asyncIteratorSymbol] === \"function\") {\n\t\tvar pact = new _Pact();\n\t\tvar iterator = target[_asyncIteratorSymbol]();\n\t\titerator.next().then(_resumeAfterNext).then(void 0, _reject);\n\t\treturn pact;\n\t\tfunction _resumeAfterBody(result) {\n\t\t\tif (check && check()) {\n\t\t\t\treturn _settle(pact, 1, iterator.return ? iterator.return().then(function() { return result; }) : result);\n\t\t\t}\n\t\t\titerator.next().then(_resumeAfterNext).then(void 0, _reject);\n\t\t}\n\t\tfunction _resumeAfterNext(step) {\n\t\t\tif (step.done) {\n\t\t\t\t_settle(pact, 1);\n\t\t\t} else {\n\t\t\t\tPromise.resolve(body(step.value)).then(_resumeAfterBody).then(void 0, _reject);\n\t\t\t}\n\t\t}\n\t\tfunction _reject(error) {\n\t\t\t_settle(pact, 2, iterator.return ? iterator.return().then(function() { return error; }) : error);\n\t\t}\n\t}\n\treturn Promise.resolve(_forOf(target, function(value) { return Promise.resolve(value).then(body); }, check));\n}\n\n// Asynchronously implement a generic for loop\nexport function _for(test, update, body) {\n\tvar stage;\n\tfor (;;) {\n\t\tvar shouldContinue = test();\n\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\tshouldContinue = shouldContinue.v;\n\t\t}\n\t\tif (!shouldContinue) {\n\t\t\treturn result;\n\t\t}\n\t\tif (shouldContinue.then) {\n\t\t\tstage = 0;\n\t\t\tbreak;\n\t\t}\n\t\tvar result = body();\n\t\tif (result && result.then) {\n\t\t\tif (_isSettledPact(result)) {\n\t\t\t\tresult = result.s;\n\t\t\t} else {\n\t\t\t\tstage = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (update) {\n\t\t\tvar updateValue = update();\n\t\t\tif (updateValue && updateValue.then && !_isSettledPact(updateValue)) {\n\t\t\t\tstage = 2;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tvar pact = new _Pact();\n\tvar reject = _settle.bind(null, pact, 2);\n\t(stage === 0 ? shouldContinue.then(_resumeAfterTest) : stage === 1 ? result.then(_resumeAfterBody) : updateValue.then(_resumeAfterUpdate)).then(void 0, reject);\n\treturn pact;\n\tfunction _resumeAfterBody(value) {\n\t\tresult = value;\n\t\tdo {\n\t\t\tif (update) {\n\t\t\t\tupdateValue = update();\n\t\t\t\tif (updateValue && updateValue.then && !_isSettledPact(updateValue)) {\n\t\t\t\t\tupdateValue.then(_resumeAfterUpdate).then(void 0, reject);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tshouldContinue = test();\n\t\t\tif (!shouldContinue || (_isSettledPact(shouldContinue) && !shouldContinue.v)) {\n\t\t\t\t_settle(pact, 1, result);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (shouldContinue.then) {\n\t\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tresult = body();\n\t\t\tif (_isSettledPact(result)) {\n\t\t\t\tresult = result.v;\n\t\t\t}\n\t\t} while (!result || !result.then);\n\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t}\n\tfunction _resumeAfterTest(shouldContinue) {\n\t\tif (shouldContinue) {\n\t\t\tresult = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t} else {\n\t\t\t\t_resumeAfterBody(result);\n\t\t\t}\n\t\t} else {\n\t\t\t_settle(pact, 1, result);\n\t\t}\n\t}\n\tfunction _resumeAfterUpdate() {\n\t\tif (shouldContinue = test()) {\n\t\t\tif (shouldContinue.then) {\n\t\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t} else {\n\t\t\t\t_resumeAfterTest(shouldContinue);\n\t\t\t}\n\t\t} else {\n\t\t\t_settle(pact, 1, result);\n\t\t}\n\t}\n}\n\n// Asynchronously implement a do ... while loop\nexport function _do(body, test) {\n\tvar awaitBody;\n\tdo {\n\t\tvar result = body();\n\t\tif (result && result.then) {\n\t\t\tif (_isSettledPact(result)) {\n\t\t\t\tresult = result.v;\n\t\t\t} else {\n\t\t\t\tawaitBody = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tvar shouldContinue = test();\n\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\tshouldContinue = shouldContinue.v;\n\t\t}\n\t\tif (!shouldContinue) {\n\t\t\treturn result;\n\t\t}\n\t} while (!shouldContinue.then);\n\tconst pact = new _Pact();\n\tconst reject = _settle.bind(null, pact, 2);\n\t(awaitBody ? result.then(_resumeAfterBody) : shouldContinue.then(_resumeAfterTest)).then(void 0, reject);\n\treturn pact;\n\tfunction _resumeAfterBody(value) {\n\t\tresult = value;\n\t\tfor (;;) {\n\t\t\tshouldContinue = test();\n\t\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\t\tshouldContinue = shouldContinue.v;\n\t\t\t}\n\t\t\tif (!shouldContinue) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (shouldContinue.then) {\n\t\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tresult = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\tresult = result.v;\n\t\t\t\t} else {\n\t\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t_settle(pact, 1, result);\n\t}\n\tfunction _resumeAfterTest(shouldContinue) {\n\t\tif (shouldContinue) {\n\t\t\tdo {\n\t\t\t\tresult = body();\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\t\tresult = result.v;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tshouldContinue = test();\n\t\t\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\t\t\tshouldContinue = shouldContinue.v;\n\t\t\t\t}\n\t\t\t\tif (!shouldContinue) {\n\t\t\t\t\t_settle(pact, 1, result);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t} while (!shouldContinue.then);\n\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t} else {\n\t\t\t_settle(pact, 1, result);\n\t\t}\n\t}\n}\n\n// Asynchronously implement a switch statement\nexport function _switch(discriminant, cases) {\n\tvar dispatchIndex = -1;\n\tvar awaitBody;\n\touter: {\n\t\tfor (var i = 0; i < cases.length; i++) {\n\t\t\tvar test = cases[i][0];\n\t\t\tif (test) {\n\t\t\t\tvar testValue = test();\n\t\t\t\tif (testValue && testValue.then) {\n\t\t\t\t\tbreak outer;\n\t\t\t\t}\n\t\t\t\tif (testValue === discriminant) {\n\t\t\t\t\tdispatchIndex = i;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// Found the default case, set it as the pending dispatch case\n\t\t\t\tdispatchIndex = i;\n\t\t\t}\n\t\t}\n\t\tif (dispatchIndex !== -1) {\n\t\t\tdo {\n\t\t\t\tvar body = cases[dispatchIndex][1];\n\t\t\t\twhile (!body) {\n\t\t\t\t\tdispatchIndex++;\n\t\t\t\t\tbody = cases[dispatchIndex][1];\n\t\t\t\t}\n\t\t\t\tvar result = body();\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tawaitBody = true;\n\t\t\t\t\tbreak outer;\n\t\t\t\t}\n\t\t\t\tvar fallthroughCheck = cases[dispatchIndex][2];\n\t\t\t\tdispatchIndex++;\n\t\t\t} while (fallthroughCheck && !fallthroughCheck());\n\t\t\treturn result;\n\t\t}\n\t}\n\tconst pact = new _Pact();\n\tconst reject = _settle.bind(null, pact, 2);\n\t(awaitBody ? result.then(_resumeAfterBody) : testValue.then(_resumeAfterTest)).then(void 0, reject);\n\treturn pact;\n\tfunction _resumeAfterTest(value) {\n\t\tfor (;;) {\n\t\t\tif (value === discriminant) {\n\t\t\t\tdispatchIndex = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (++i === cases.length) {\n\t\t\t\tif (dispatchIndex !== -1) {\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\t_settle(pact, 1, result);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\ttest = cases[i][0];\n\t\t\tif (test) {\n\t\t\t\tvalue = test();\n\t\t\t\tif (value && value.then) {\n\t\t\t\t\tvalue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdispatchIndex = i;\n\t\t\t}\n\t\t}\n\t\tdo {\n\t\t\tvar body = cases[dispatchIndex][1];\n\t\t\twhile (!body) {\n\t\t\t\tdispatchIndex++;\n\t\t\t\tbody = cases[dispatchIndex][1];\n\t\t\t}\n\t\t\tvar result = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar fallthroughCheck = cases[dispatchIndex][2];\n\t\t\tdispatchIndex++;\n\t\t} while (fallthroughCheck && !fallthroughCheck());\n\t\t_settle(pact, 1, result);\n\t}\n\tfunction _resumeAfterBody(result) {\n\t\tfor (;;) {\n\t\t\tvar fallthroughCheck = cases[dispatchIndex][2];\n\t\t\tif (!fallthroughCheck || fallthroughCheck()) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdispatchIndex++;\n\t\t\tvar body = cases[dispatchIndex][1];\n\t\t\twhile (!body) {\n\t\t\t\tdispatchIndex++;\n\t\t\t\tbody = cases[dispatchIndex][1];\n\t\t\t}\n\t\t\tresult = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\t_settle(pact, 1, result);\n\t}\n}\n\n// Asynchronously call a function and pass the result to explicitly passed continuations\nexport function _call(body, then, direct) {\n\tif (direct) {\n\t\treturn then ? then(body()) : body();\n\t}\n\ttry {\n\t\tvar result = Promise.resolve(body());\n\t\treturn then ? result.then(then) : result;\n\t} catch (e) {\n\t\treturn Promise.reject(e);\n\t}\n}\n\n// Asynchronously call a function and swallow the result\nexport function _callIgnored(body, direct) {\n\treturn _call(body, _empty, direct);\n}\n\n// Asynchronously call a function and pass the result to explicitly passed continuations\nexport function _invoke(body, then) {\n\tvar result = body();\n\tif (result && result.then) {\n\t\treturn result.then(then);\n\t}\n\treturn then(result);\n}\n\n// Asynchronously call a function and swallow the result\nexport function _invokeIgnored(body) {\n\tvar result = body();\n\tif (result && result.then) {\n\t\treturn result.then(_empty);\n\t}\n}\n\n// Asynchronously call a function and send errors to recovery continuation\nexport function _catch(body, recover) {\n\ttry {\n\t\tvar result = body();\n\t} catch(e) {\n\t\treturn recover(e);\n\t}\n\tif (result && result.then) {\n\t\treturn result.then(void 0, recover);\n\t}\n\treturn result;\n}\n\n// Asynchronously await a promise and pass the result to a finally continuation\nexport function _finallyRethrows(body, finalizer) {\n\ttry {\n\t\tvar result = body();\n\t} catch (e) {\n\t\treturn finalizer(true, e);\n\t}\n\tif (result && result.then) {\n\t\treturn result.then(finalizer.bind(null, false), finalizer.bind(null, true));\n\t}\n\treturn finalizer(false, result);\n}\n\n// Asynchronously await a promise and invoke a finally continuation that always overrides the result\nexport function _finally(body, finalizer) {\n\ttry {\n\t\tvar result = body();\n\t} catch (e) {\n\t\treturn finalizer();\n\t}\n\tif (result && result.then) {\n\t\treturn result.then(finalizer, finalizer);\n\t}\n\treturn finalizer();\n}\n\n// Rethrow or return a value from a finally continuation\nexport function _rethrow(thrown, value) {\n\tif (thrown)\n\t\tthrow value;\n\treturn value;\n}\n\n// Empty function to implement break and other control flow that ignores asynchronous results\nexport function _empty() {\n}\n\n// Sentinel value for early returns in generators \nexport const _earlyReturn = /*#__PURE__*/ {};\n\n// Asynchronously call a function and send errors to recovery continuation, skipping early returns\nexport function _catchInGenerator(body, recover) {\n\treturn _catch(body, function(e) {\n\t\tif (e === _earlyReturn) {\n\t\t\tthrow e;\n\t\t}\n\t\treturn recover(e);\n\t});\n}\n\n// Asynchronous generator class; accepts the entrypoint of the generator, to which it passes itself when the generator should start\nexport const _AsyncGenerator = /*#__PURE__*/(function() {\n\tfunction _AsyncGenerator(entry) {\n\t\tthis._entry = entry;\n\t\tthis._pact = null;\n\t\tthis._resolve = null;\n\t\tthis._return = null;\n\t\tthis._promise = null;\n\t}\n\n\tfunction _wrapReturnedValue(value) {\n\t\treturn { value: value, done: true };\n\t}\n\tfunction _wrapYieldedValue(value) {\n\t\treturn { value: value, done: false };\n\t}\n\n\t_AsyncGenerator.prototype._yield = function(value) {\n\t\t// Yield the value to the pending next call\n\t\tthis._resolve(value && value.then ? value.then(_wrapYieldedValue) : _wrapYieldedValue(value));\n\t\t// Return a pact for an upcoming next/return/throw call\n\t\treturn this._pact = new _Pact();\n\t};\n\t_AsyncGenerator.prototype.next = function(value) {\n\t\t// Advance the generator, starting it if it has yet to be started\n\t\tconst _this = this;\n\t\treturn _this._promise = new Promise(function (resolve) {\n\t\t\tconst _pact = _this._pact;\n\t\t\tif (_pact === null) {\n\t\t\t\tconst _entry = _this._entry;\n\t\t\t\tif (_entry === null) {\n\t\t\t\t\t// Generator is started, but not awaiting a yield expression\n\t\t\t\t\t// Abandon the next call!\n\t\t\t\t\treturn resolve(_this._promise);\n\t\t\t\t}\n\t\t\t\t// Start the generator\n\t\t\t\t_this._entry = null;\n\t\t\t\t_this._resolve = resolve;\n\t\t\t\tfunction returnValue(value) {\n\t\t\t\t\t_this._resolve(value && value.then ? value.then(_wrapReturnedValue) : _wrapReturnedValue(value));\n\t\t\t\t\t_this._pact = null;\n\t\t\t\t\t_this._resolve = null;\n\t\t\t\t}\n\t\t\t\tvar result = _entry(_this);\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tresult.then(returnValue, function(error) {\n\t\t\t\t\t\tif (error === _earlyReturn) {\n\t\t\t\t\t\t\treturnValue(_this._return);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tconst pact = new _Pact();\n\t\t\t\t\t\t\t_this._resolve(pact);\n\t\t\t\t\t\t\t_this._pact = null;\n\t\t\t\t\t\t\t_this._resolve = null;\n\t\t\t\t\t\t\t_resolve(pact, 2, error);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t} else {\n\t\t\t\t\treturnValue(result);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// Generator is started and a yield expression is pending, settle it\n\t\t\t\t_this._pact = null;\n\t\t\t\t_this._resolve = resolve;\n\t\t\t\t_settle(_pact, 1, value);\n\t\t\t}\n\t\t});\n\t};\n\t_AsyncGenerator.prototype.return = function(value) {\n\t\t// Early return from the generator if started, otherwise abandons the generator\n\t\tconst _this = this;\n\t\treturn _this._promise = new Promise(function (resolve) {\n\t\t\tconst _pact = _this._pact;\n\t\t\tif (_pact === null) {\n\t\t\t\tif (_this._entry === null) {\n\t\t\t\t\t// Generator is started, but not awaiting a yield expression\n\t\t\t\t\t// Abandon the return call!\n\t\t\t\t\treturn resolve(_this._promise);\n\t\t\t\t}\n\t\t\t\t// Generator is not started, abandon it and return the specified value\n\t\t\t\t_this._entry = null;\n\t\t\t\treturn resolve(value && value.then ? value.then(_wrapReturnedValue) : _wrapReturnedValue(value));\n\t\t\t}\n\t\t\t// Settle the yield expression with a rejected \"early return\" value\n\t\t\t_this._return = value;\n\t\t\t_this._resolve = resolve;\n\t\t\t_this._pact = null;\n\t\t\t_settle(_pact, 2, _earlyReturn);\n\t\t});\n\t};\n\t_AsyncGenerator.prototype.throw = function(error) {\n\t\t// Inject an exception into the pending yield expression\n\t\tconst _this = this;\n\t\treturn _this._promise = new Promise(function (resolve, reject) {\n\t\t\tconst _pact = _this._pact;\n\t\t\tif (_pact === null) {\n\t\t\t\tif (_this._entry === null) {\n\t\t\t\t\t// Generator is started, but not awaiting a yield expression\n\t\t\t\t\t// Abandon the throw call!\n\t\t\t\t\treturn resolve(_this._promise);\n\t\t\t\t}\n\t\t\t\t// Generator is not started, abandon it and return a rejected Promise containing the error\n\t\t\t\t_this._entry = null;\n\t\t\t\treturn reject(error);\n\t\t\t}\n\t\t\t// Settle the yield expression with the value as a rejection\n\t\t\t_this._resolve = resolve;\n\t\t\t_this._pact = null;\n\t\t\t_settle(_pact, 2, error);\n\t\t});\n\t};\n\n\t_AsyncGenerator.prototype[_asyncIteratorSymbol] = function() {\n\t\treturn this;\n\t};\n\t\n\treturn _AsyncGenerator;\n})();\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Class containing methods that operates against an array.\n */\nexport default class ArrayMethods {\n  /**\n   * Checkes to see if there are duplicates in the given array.\n   */\n  public static hasDuplicates<T>(array: Array<T>): boolean {\n    const uniqueValues = new Set<T>();\n\n    for (let i = 0; i < array.length; i++) {\n      const value = array[i];\n      if (uniqueValues.has(value)) {\n        return true;\n      }\n      uniqueValues.add(value);\n    }\n\n    return false;\n  }\n\n  /**\n   * Checks that entries in array 2 is not in array 1.\n   */\n  public static areMutuallyExclusive<T>(\n    array1: Array<T>,\n    array2: Array<T>\n  ): boolean {\n    const valuesInArray1 = new Set<T>(array1);\n\n    for (const value of array2) {\n      if (valuesInArray1.has(value)) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst pako = require('pako');\n\n/**\n * Encapsulates functionality to compress/decompress data.\n */\nexport default class Compressor {\n  /**\n   * Compresses the data in gzip and return it as buffer.\n   * @param inputAsBuffer The input string to be compressed.\n   */\n  public static async compress(inputAsBuffer: Buffer): Promise<Buffer> {\n    const result = pako.deflate(Buffer.from(inputAsBuffer));\n    return Buffer.from(result);\n  }\n\n  /**\n   * Decompresses the input and returns it as buffer.\n   * @param inputAsBuffer The gzip compressed data.\n   */\n  public static async decompress(inputAsBuffer: Buffer): Promise<Buffer> {\n    const result = pako.inflate(inputAsBuffer);\n    return Buffer.from(result);\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  DocumentModel,\n  Encoder,\n  DidState,\n  ErrorCode,\n  SidetreeError,\n  PublicKeyPurpose,\n} from '@sidetree/common';\nimport UpdateOperation from './UpdateOperation';\nimport jsonpatch from 'fast-json-patch';\n\n/**\n * Class that handles the composition of operations into final external-facing document.\n */\nexport default class DocumentComposer {\n  /**\n   * Transforms the given DID state into a DID Document.\n   */\n  public static transformToExternalDocument(\n    didState: DidState,\n    did: string\n  ): any {\n    // If the DID is deactivated.\n    if (didState.nextRecoveryCommitmentHash === undefined) {\n      return { status: 'deactivated' };\n    }\n\n    const document = didState.document as DocumentModel;\n\n    const shortFormDid = did.split('?')[0];\n\n    // Only populate `publicKey` if general purpose exists.\n    // Only populate `authentication` if auth purpose exists.\n    const authentication: any[] = [];\n    const assertionMethod: any[] = [];\n    const capabilityInvocation: any[] = [];\n    const capabilityDelegation: any[] = [];\n    const keyAgreement: any[] = [];\n\n    const public_keys: any[] = [];\n    if (Array.isArray(document.public_keys)) {\n      for (const publicKey of document.public_keys) {\n        const id = '#' + publicKey.id;\n        const didDocumentPublicKey = {\n          id: id,\n          controller: shortFormDid,\n          type: publicKey.type,\n          publicKeyJwk: publicKey.jwk,\n        };\n        const purposeSet: Set<string> = new Set(publicKey.purpose);\n\n        if (purposeSet.has(PublicKeyPurpose.General)) {\n          public_keys.push(didDocumentPublicKey);\n\n          if (purposeSet.has(PublicKeyPurpose.Auth)) {\n            authentication.push(id);\n          }\n          if (purposeSet.has(PublicKeyPurpose.AssertionMethod)) {\n            assertionMethod.push(id);\n          }\n          if (purposeSet.has(PublicKeyPurpose.CapabilityInvocation)) {\n            capabilityInvocation.push(id);\n          }\n          if (purposeSet.has(PublicKeyPurpose.CapabilityDelegation)) {\n            capabilityDelegation.push(id);\n          }\n          if (purposeSet.has(PublicKeyPurpose.KeyAgreement)) {\n            keyAgreement.push(id);\n          }\n        } else if (purposeSet.has(PublicKeyPurpose.Auth)) {\n          authentication.push(didDocumentPublicKey);\n        } else if (purposeSet.has(PublicKeyPurpose.AssertionMethod)) {\n          assertionMethod.push(assertionMethod);\n        } else if (purposeSet.has(PublicKeyPurpose.CapabilityInvocation)) {\n          capabilityInvocation.push(didDocumentPublicKey);\n        } else if (purposeSet.has(PublicKeyPurpose.CapabilityDelegation)) {\n          capabilityDelegation.push(didDocumentPublicKey);\n        } else if (purposeSet.has(PublicKeyPurpose.KeyAgreement)) {\n          keyAgreement.push(didDocumentPublicKey);\n        }\n      }\n    }\n\n    // Only update `service_endpoints` if the array is present\n    const service_endpoints = [];\n    if (Array.isArray(document.service_endpoints)) {\n      for (const serviceEndpoint of document.service_endpoints) {\n        const didDocumentServiceEndpoint = {\n          id: '#' + serviceEndpoint.id,\n          type: serviceEndpoint.type,\n          serviceEndpoint: serviceEndpoint.endpoint,\n        };\n        service_endpoints.push(didDocumentServiceEndpoint);\n      }\n    }\n\n    const didDocument: any = {\n      id: shortFormDid,\n      '@context': ['https://www.w3.org/ns/did/v1', { '@base': shortFormDid }],\n    };\n\n    if (public_keys.length !== 0) {\n      didDocument.publicKey = public_keys;\n    }\n\n    if (authentication.length !== 0) {\n      didDocument.authentication = authentication;\n    }\n\n    if (assertionMethod.length !== 0) {\n      didDocument.assertionMethod = assertionMethod;\n    }\n\n    if (capabilityInvocation.length !== 0) {\n      didDocument.capabilityInvocation = capabilityInvocation;\n    }\n\n    if (capabilityDelegation.length !== 0) {\n      didDocument.capabilityDelegation = capabilityDelegation;\n    }\n\n    if (keyAgreement.length !== 0) {\n      didDocument.keyAgreement = keyAgreement;\n    }\n\n    if (service_endpoints.length !== 0) {\n      didDocument.service = service_endpoints;\n    }\n\n    const didResolutionResult: any = {\n      '@context': 'https://www.w3.org/ns/did-resolution/v1',\n      didDocument: didDocument,\n      methodMetadata: {\n        recoveryCommitment: didState.nextRecoveryCommitmentHash,\n        updateCommitment: didState.nextUpdateCommitmentHash,\n      },\n    };\n\n    return JSON.parse(JSON.stringify(didResolutionResult));\n  }\n\n  /**\n   * Applies the update operation to the given document.\n   * @returns The resultant document.\n   * @throws SidetreeError if invalid operation is given.\n   */\n  public static async applyUpdateOperation(\n    operation: UpdateOperation,\n    document: any\n  ): Promise<any> {\n    const resultantDocument = DocumentComposer.applyPatches(\n      document,\n      operation.delta!.patches\n    );\n\n    return resultantDocument;\n  }\n\n  /**\n   * Validates the schema of the given full document.\n   * @throws SidetreeError if given document patch fails validation.\n   */\n  private static validateDocument(document: any) {\n    if (document === undefined) {\n      throw new SidetreeError(ErrorCode.DocumentComposerDocumentMissing);\n    }\n\n    const allowedProperties = new Set(['public_keys', 'service_endpoints']);\n    for (const property in document) {\n      if (!allowedProperties.has(property)) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerUnknownPropertyInDocument,\n          `Unexpected property ${property} in document.`\n        );\n      }\n    }\n\n    // Verify 'public_keys' property if it exists.\n    if (Object.prototype.hasOwnProperty.call(document, 'public_keys')) {\n      DocumentComposer.validatePublicKeys(document.public_keys);\n    }\n\n    // Verify 'service_endpoints' property if it exists.\n    if (Object.prototype.hasOwnProperty.call(document, 'service_endpoints')) {\n      // Verify each endpoint entry in service_endpoints.\n      DocumentComposer.validateServiceEndpoints(document.service_endpoints);\n    }\n  }\n\n  /**\n   * Validates the schema of the given update document patch.\n   * @throws SidetreeError if given document patch fails validation.\n   */\n  public static validateDocumentPatches(patches: any) {\n    if (!Array.isArray(patches)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerUpdateOperationDocumentPatchesNotArray\n      );\n    }\n\n    for (const patch of patches) {\n      DocumentComposer.validatePatch(patch);\n    }\n  }\n\n  private static validatePatch(patch: any) {\n    const action = patch.action;\n    switch (action) {\n      case 'replace':\n        DocumentComposer.validateDocument(patch.document);\n        break;\n      case 'add-public-keys':\n        DocumentComposer.validateAddPublicKeysPatch(patch);\n        break;\n      case 'remove-public-keys':\n        DocumentComposer.validateRemovePublicKeysPatch(patch);\n        break;\n      case 'add-service-endpoints':\n        DocumentComposer.validateAddServiceEndpointsPatch(patch);\n        break;\n      case 'remove-service-endpoints':\n        DocumentComposer.validateRemoveServiceEndpointsPatch(patch);\n        break;\n      case 'ietf-json-patch':\n        DocumentComposer.validateIetfJsonPatch(patch);\n        break;\n      default:\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchMissingOrUnknownAction\n        );\n    }\n  }\n\n  private static validateIetfJsonPatch(patch: any): void {\n    const patchProperties = Object.keys(patch);\n    if (patchProperties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchMissingOrUnknownProperty\n      );\n    }\n    const error = jsonpatch.validate(patch.patches);\n    if (error) {\n      console.warn(error);\n      throw new SidetreeError(error.name);\n    }\n  }\n\n  private static validateAddPublicKeysPatch(patch: any) {\n    const patchProperties = Object.keys(patch);\n    if (patchProperties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchMissingOrUnknownProperty\n      );\n    }\n\n    DocumentComposer.validatePublicKeys(patch.public_keys);\n  }\n\n  private static validatePublicKeys(public_keys: any) {\n    if (!Array.isArray(public_keys)) {\n      throw new SidetreeError(ErrorCode.DocumentComposerPublicKeysNotArray);\n    }\n\n    const publicKeyIdSet: Set<string> = new Set();\n    for (const publicKey of public_keys) {\n      const publicKeyProperties = Object.keys(publicKey);\n      // the expected fields are id, purpose, type and jwk\n      if (publicKeyProperties.length !== 4) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyMissingOrUnknownProperty\n        );\n      }\n\n      if (typeof publicKey.jwk !== 'object' || Array.isArray(publicKey.jwk)) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyJwkMissingOrIncorrectType\n        );\n      }\n\n      if (typeof publicKey.type !== 'string') {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyTypeMissingOrIncorrectType\n        );\n      }\n\n      DocumentComposer.validateId(publicKey.id);\n\n      // 'id' must be unique\n      if (publicKeyIdSet.has(publicKey.id)) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyIdDuplicated\n        );\n      }\n      publicKeyIdSet.add(publicKey.id);\n\n      if (!Array.isArray(publicKey.purpose) || publicKey.purpose.length === 0) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyPurposeMissingOrUnknown\n        );\n      }\n\n      if (publicKey.purpose.length > Object.values(PublicKeyPurpose).length) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyPurposeExceedsMaxLength\n        );\n      }\n\n      const validPurposes = new Set(Object.values(PublicKeyPurpose));\n      // Purpose must be one of the valid ones in KeyPurpose\n      for (const purpose of publicKey.purpose) {\n        if (!validPurposes.has(purpose)) {\n          throw new SidetreeError(\n            ErrorCode.DocumentComposerPublicKeyInvalidPurpose\n          );\n        }\n      }\n    }\n  }\n\n  private static validateRemovePublicKeysPatch(patch: any) {\n    const patchProperties = Object.keys(patch);\n    if (patchProperties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchMissingOrUnknownProperty\n      );\n    }\n\n    if (!Array.isArray(patch.public_keys)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchPublicKeyIdsNotArray\n      );\n    }\n\n    for (const publicKeyId of patch.public_keys) {\n      if (typeof publicKeyId !== 'string') {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchPublicKeyIdNotString\n        );\n      }\n    }\n  }\n\n  /**\n   * validate update patch for removing service endpoints\n   */\n  private static validateRemoveServiceEndpointsPatch(patch: any) {\n    const patchProperties = Object.keys(patch);\n    if (patchProperties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchMissingOrUnknownProperty\n      );\n    }\n\n    if (!Array.isArray(patch.ids)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchServiceEndpointIdsNotArray\n      );\n    }\n\n    for (const id of patch.ids) {\n      DocumentComposer.validateId(id);\n    }\n  }\n\n  /**\n   * Validates update patch for adding service endpoints.\n   */\n  private static validateAddServiceEndpointsPatch(patch: any) {\n    const patchProperties = Object.keys(patch);\n    if (patchProperties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchMissingOrUnknownProperty\n      );\n    }\n\n    if (!Array.isArray(patch.service_endpoints)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchServiceEndpointsNotArray\n      );\n    }\n\n    DocumentComposer.validateServiceEndpoints(patch.service_endpoints);\n  }\n\n  /**\n   * Validates and parses services endpoints\n   * @param service_endpoints the service endpoints to validate and parse\n   */\n  private static validateServiceEndpoints(service_endpoints: any) {\n    if (!Array.isArray(service_endpoints)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchServiceEndpointsNotArray\n      );\n    }\n\n    for (const serviceEndpoint of service_endpoints) {\n      const serviceEndpointProperties = Object.keys(serviceEndpoint);\n      if (serviceEndpointProperties.length !== 3) {\n        // type, id, and endpoint\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerServiceEndpointMissingOrUnknownProperty\n        );\n      }\n\n      DocumentComposer.validateId(serviceEndpoint.id);\n\n      if (typeof serviceEndpoint.type !== 'string') {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchServiceEndpointTypeNotString\n        );\n      }\n      if (serviceEndpoint.type.length > 30) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchServiceEndpointTypeTooLong\n        );\n      }\n      if (typeof serviceEndpoint.endpoint !== 'string') {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchServiceEndpointServiceEndpointNotString\n        );\n      }\n      if (serviceEndpoint.endpoint.length > 100) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchServiceEndpointServiceEndpointTooLong\n        );\n      }\n\n      try {\n        // just want to validate url, no need to assign to variable, it will throw if not valid\n        // tslint:disable-next-line\n        new URL(serviceEndpoint.endpoint);\n      } catch {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchServiceEndpointServiceEndpointNotValidUrl\n        );\n      }\n    }\n  }\n\n  private static validateId(id: any) {\n    if (typeof id !== 'string') {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerIdNotString,\n        `ID not string: ${JSON.stringify(id)} is of type '${typeof id}'`\n      );\n    }\n    if (id.length > 50) {\n      throw new SidetreeError(ErrorCode.DocumentComposerIdTooLong);\n    }\n\n    if (!Encoder.isBase64UrlString(id)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerIdNotUsingBase64UrlCharacterSet\n      );\n    }\n  }\n\n  /**\n   * Applies the given patches in order to the given document.\n   * NOTE: Assumes no schema validation is needed, since validation should've already occurred at the time of the operation being parsed.\n   * @returns The resultant document.\n   */\n  public static applyPatches(document: any, patches: any[]): any {\n    // Loop through and apply all patches.\n    let resultantDocument = document;\n    for (const patch of patches) {\n      resultantDocument = DocumentComposer.applyPatchToDidDocument(\n        resultantDocument,\n        patch\n      );\n    }\n\n    return resultantDocument;\n  }\n\n  /**\n   * Applies the given patch to the given DID Document.\n   */\n  private static applyPatchToDidDocument(\n    document: DocumentModel,\n    patch: any\n  ): any {\n    if (patch.action === 'replace') {\n      return patch.document;\n    } else if (patch.action === 'add-public-keys') {\n      return DocumentComposer.addPublicKeys(document, patch);\n    } else if (patch.action === 'remove-public-keys') {\n      return DocumentComposer.removePublicKeys(document, patch);\n    } else if (patch.action === 'add-service-endpoints') {\n      return DocumentComposer.addServiceEndpoints(document, patch);\n    } else if (patch.action === 'remove-service-endpoints') {\n      return DocumentComposer.removeServiceEndpoints(document, patch);\n    } else if (patch.action === 'ietf-json-patch') {\n      return DocumentComposer.applyIetfJsonPatch(document, patch);\n    }\n  }\n\n  private static applyIetfJsonPatch(document: any, patch: any) {\n    const res = jsonpatch.applyPatch({ ...document }, patch.patches);\n    return res.newDocument;\n  }\n\n  /**\n   * Adds public keys to document.\n   */\n  private static addPublicKeys(\n    document: DocumentModel,\n    patch: any\n  ): DocumentModel {\n    const publicKeyMap = new Map(\n      (document.public_keys || []).map((publicKey) => [publicKey.id, publicKey])\n    );\n\n    // Loop through all given public keys and add them if they don't exist already.\n    for (const publicKey of patch.public_keys) {\n      // NOTE: If a key ID already exists, we will just replace the existing key.\n      // Not throwing error will minimize the need (thus risk) of reusing exposed update reveal value.\n      publicKeyMap.set(publicKey.id, publicKey);\n    }\n\n    document.public_keys = Array.from(publicKeyMap.entries()).map(\n      (pkm: any) => pkm[1]\n    );\n\n    return document;\n  }\n\n  /**\n   * Removes public keys from document.\n   */\n  private static removePublicKeys(\n    document: DocumentModel,\n    patch: any\n  ): DocumentModel {\n    const publicKeyMap = new Map(\n      (document.public_keys || []).map((publicKey) => [publicKey.id, publicKey])\n    );\n\n    // Loop through all given public key IDs and delete them from the existing public key only if it is not a recovery key.\n    for (const publicKey of patch.public_keys) {\n      const existingKey = publicKeyMap.get(publicKey);\n\n      if (existingKey !== undefined) {\n        publicKeyMap.delete(publicKey);\n      }\n      // NOTE: Else we will just treat this key removal as a no-op.\n      // Not throwing error will minimize the need (thus risk) of reusing exposed update reveal value.\n    }\n\n    document.public_keys = Array.from(publicKeyMap.entries()).map(\n      (pkm: any) => pkm[1]\n    );\n\n    return document;\n  }\n\n  private static addServiceEndpoints(\n    document: DocumentModel,\n    patch: any\n  ): DocumentModel {\n    const service_endpoints = patch.service_endpoints;\n\n    if (document.service_endpoints === undefined) {\n      // create a new array if service did not exist\n      document.service_endpoints = [];\n    }\n\n    const idToIndexMapper = new Map();\n    // map all id and their index\n    for (const idx in document.service_endpoints) {\n      idToIndexMapper.set(document.service_endpoints[idx].id, idx);\n    }\n\n    for (const serviceEndpoint of service_endpoints) {\n      if (idToIndexMapper.has(serviceEndpoint.id)) {\n        const idx = idToIndexMapper.get(serviceEndpoint.id);\n        document.service_endpoints[idx] = serviceEndpoint;\n      } else {\n        document.service_endpoints.push(serviceEndpoint);\n      }\n    }\n\n    return document;\n  }\n\n  private static removeServiceEndpoints(\n    document: DocumentModel,\n    patch: any\n  ): DocumentModel {\n    if (document.service_endpoints === undefined) {\n      return document;\n    }\n\n    const idsToRemove = new Set(patch.ids);\n    document.service_endpoints = document.service_endpoints.filter(\n      (serviceEndpoint) => !idsToRemove.has(serviceEndpoint.id)\n    );\n\n    return document;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst yieldableJson = require('yieldable-json');\n\n/**\n * A JSON library that performs operations asynchronously.\n */\nexport default class JsonAsync {\n  /**\n   * Parses the given operation into a JavaScript object asynchronously,\n   * to allow the event loop a chance to handle requests.\n   */\n  public static async parse(jsonData: Buffer | string): Promise<any> {\n    // Create a promise to wrap the successful/failed read events.\n    const jsonParsePromise = new Promise((resolve, reject) => {\n      yieldableJson.parseAsync(jsonData, (err: any, data: any) => {\n        if (err) {\n          reject(err);\n        } else {\n          resolve(data);\n        }\n      });\n    });\n\n    // Wait until the JSON parsing is completed.\n    const result = await jsonParsePromise;\n    return result;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  DeltaModel,\n  Encoder,\n  ErrorCode,\n  Multihash,\n  SidetreeError,\n} from '@sidetree/common';\nimport DocumentComposer from './DocumentComposer';\nimport JsonAsync from './util/JsonAsync';\n\n/**\n * A class that contains Sidetree operation utility methods.\n */\nexport default class OperationUtils {\n  /**\n   * Parses the given encoded delta string into an internal `DeltaModel`.\n   */\n  public static async parseDelta(deltaEncodedString: any): Promise<DeltaModel> {\n    if (typeof deltaEncodedString !== 'string') {\n      throw new SidetreeError(ErrorCode.DeltaMissingOrNotString);\n    }\n\n    const deltaJsonString = Encoder.decodeAsString(deltaEncodedString);\n    const delta = await JsonAsync.parse(deltaJsonString);\n\n    const properties = Object.keys(delta);\n    if (properties.length !== 2) {\n      throw new SidetreeError(ErrorCode.DeltaMissingOrUnknownProperty);\n    }\n\n    if (delta.patches === undefined) {\n      throw new SidetreeError(ErrorCode.OperationDocumentPatchesMissing);\n    }\n\n    // Validate `patches` property using the DocumentComposer.\n    DocumentComposer.validateDocumentPatches(delta.patches);\n\n    const nextUpdateCommitment = Encoder.decodeAsBuffer(\n      delta.update_commitment\n    );\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(\n      nextUpdateCommitment\n    );\n\n    return {\n      patches: delta.patches,\n      update_commitment: delta.update_commitment,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  OperationType,\n  ErrorCode,\n  SidetreeError,\n  DeltaModel,\n  OperationModel,\n  Multihash,\n  Encoder,\n} from '@sidetree/common';\nimport OperationUtils from './OperationUtils';\nimport JsonAsync from './util/JsonAsync';\n\ninterface SuffixDataModel {\n  delta_hash: string;\n  recovery_commitment: string;\n}\n\n/**\n * A class that represents a create operation.\n */\nexport default class CreateOperation implements OperationModel {\n  /** The original request buffer sent by the requester. */\n  public readonly operationBuffer: Buffer;\n\n  /** The unique suffix of the DID. */\n  public readonly didUniqueSuffix: string;\n\n  /** The type of operation. */\n  public readonly type: OperationType;\n\n  /** Data used to generate the unique DID suffix. */\n  public readonly suffixData: SuffixDataModel;\n\n  /** Delta. */\n  public readonly delta: DeltaModel | undefined;\n\n  /** Encoded string of the suffix data. */\n  public readonly encodedSuffixData: string;\n\n  /** Encoded string of the delta. */\n  public readonly encodedDelta: string | undefined;\n\n  /**\n   * NOTE: should only be used by `parse()` and `parseObject()` else the contructed instance could be invalid.\n   */\n  private constructor(\n    operationBuffer: Buffer,\n    didUniqueSuffix: string,\n    encodedSuffixData: string,\n    suffixData: SuffixDataModel,\n    encodedDelta: string | undefined,\n    delta: DeltaModel | undefined\n  ) {\n    this.didUniqueSuffix = didUniqueSuffix;\n    this.type = OperationType.Create;\n    this.operationBuffer = operationBuffer;\n    this.encodedSuffixData = encodedSuffixData;\n    this.suffixData = suffixData;\n    this.encodedDelta = encodedDelta;\n    this.delta = delta;\n  }\n\n  /**\n   * Computes the DID unique suffix given the encoded suffix data string.\n   */\n  private static computeDidUniqueSuffix(encodedSuffixData: string): string {\n    const suffixDataBuffer = Encoder.decodeAsBuffer(encodedSuffixData);\n    const multihash = Multihash.hash(suffixDataBuffer);\n    const encodedMultihash = Encoder.encode(multihash);\n    return encodedMultihash;\n  }\n\n  /**\n   * Parses the given input as a create operation entry in the anchor file.\n   */\n  public static async parseOperationFromAnchorFile(\n    input: any\n  ): Promise<CreateOperation> {\n    // Issue #442 - Replace `operationBuffer` in `OperationModel` and `AnchoredOperationModel` with actual operation request\n    const operationBuffer = Buffer.from(JSON.stringify(input));\n    const operation = await CreateOperation.parseObject(\n      input,\n      operationBuffer,\n      true\n    );\n    return operation;\n  }\n\n  /**\n   * Parses the given buffer as a `CreateOperation`.\n   */\n  public static async parse(operationBuffer: Buffer): Promise<CreateOperation> {\n    const operationJsonString = operationBuffer.toString();\n    const operationObject = await JsonAsync.parse(operationJsonString);\n    const createOperation = await CreateOperation.parseObject(\n      operationObject,\n      operationBuffer,\n      false\n    );\n    return createOperation;\n  }\n\n  /**\n   * Parses the given operation object as a `CreateOperation`.\n   * The `operationBuffer` given is assumed to be valid and is assigned to the `operationBuffer` directly.\n   * NOTE: This method is purely intended to be used as an optimization method over the `parse` method in that\n   * JSON parsing is not required to be performed more than once when an operation buffer of an unknown operation type is given.\n   * @param anchorFileMode If set to true, then `delta` and `type` properties are expected to be absent.\n   */\n  public static async parseObject(\n    operationObject: any,\n    operationBuffer: Buffer,\n    anchorFileMode: boolean\n  ): Promise<CreateOperation> {\n    let expectedPropertyCount = 3;\n    if (anchorFileMode) {\n      expectedPropertyCount = 1;\n    }\n\n    const properties = Object.keys(operationObject);\n    if (properties.length !== expectedPropertyCount) {\n      throw new SidetreeError(\n        ErrorCode.CreateOperationMissingOrUnknownProperty\n      );\n    }\n\n    const encodedSuffixData = operationObject.suffix_data;\n    const suffixData = await CreateOperation.parseSuffixData(encodedSuffixData);\n\n    // If not in anchor file mode, we need to validate `type` and `delta` properties.\n    let encodedDelta = undefined;\n    let delta = undefined;\n    if (!anchorFileMode) {\n      if (operationObject.type !== OperationType.Create) {\n        throw new SidetreeError(ErrorCode.CreateOperationTypeIncorrect);\n      }\n\n      encodedDelta = operationObject.delta;\n      try {\n        delta = await OperationUtils.parseDelta(operationObject.delta);\n      } catch {\n        // For compatibility with data pruning, we have to assume that `delta` may be unavailable,\n        // thus an operation with invalid `delta` needs to be processed as an operation with unavailable `delta`,\n        // so here we let `delta` be `undefined`.\n      }\n    }\n\n    const didUniqueSuffix = CreateOperation.computeDidUniqueSuffix(\n      operationObject.suffix_data\n    );\n    return new CreateOperation(\n      operationBuffer,\n      didUniqueSuffix,\n      encodedSuffixData,\n      suffixData,\n      encodedDelta,\n      delta\n    );\n  }\n\n  private static async parseSuffixData(\n    suffixDataEncodedString: any\n  ): Promise<SuffixDataModel> {\n    if (typeof suffixDataEncodedString !== 'string') {\n      throw new SidetreeError(\n        ErrorCode.CreateOperationSuffixDataMissingOrNotString\n      );\n    }\n\n    const suffixDataJsonString = Encoder.decodeAsString(\n      suffixDataEncodedString\n    );\n    const suffixData = await JsonAsync.parse(suffixDataJsonString);\n\n    const properties = Object.keys(suffixData);\n    if (properties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.CreateOperationSuffixDataMissingOrUnknownProperty\n      );\n    }\n\n    const delta_hash = Encoder.decodeAsBuffer(suffixData.delta_hash);\n    const nextRecoveryCommitment = Encoder.decodeAsBuffer(\n      suffixData.recovery_commitment\n    );\n\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(delta_hash);\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(\n      nextRecoveryCommitment\n    );\n\n    return {\n      delta_hash: suffixData.delta_hash,\n      recovery_commitment: suffixData.recovery_commitment,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ErrorCode,\n  SidetreeError,\n  PublicKeyJwkSecp256k1,\n  PublicKeyJwkEd25519,\n  PrivateKeyJwkSecp256k1,\n  PrivateKeyJwkEd25519,\n  PrivateKeyJwk,\n  PublicKeyJwk,\n} from '@sidetree/common';\nimport { JWK } from 'jose';\nimport * as bip39 from 'bip39';\nimport { Ed25519KeyPair } from '@transmute/did-key-ed25519';\nimport hdkey from 'hdkey';\nimport { from as keytoFrom } from '@trust/keyto';\n\n/**\n * Class containing reusable JWK operations.\n */\nexport default class Jwk {\n  /**\n   * Generates ED25519 key pair.\n   * Mainly used for testing.\n   * @returns [publicKey, privateKey]\n   */\n  public static async generateEd25519KeyPair(): Promise<\n    [PublicKeyJwkEd25519, PrivateKeyJwkEd25519]\n  > {\n    const keyPair = await JWK.generate('OKP', 'Ed25519');\n    const privateKey = keyPair.toJWK(true) as PrivateKeyJwkEd25519;\n    const publicKey = keyPair.toJWK(false) as PublicKeyJwkEd25519;\n    return [publicKey, privateKey];\n  }\n\n  // Helper method to generate keys from a mnemonic\n  public static async getBufferAtIndex(\n    mnemonic: string,\n    index: number\n  ): Promise<Buffer> {\n    const seed = await bip39.mnemonicToSeed(mnemonic);\n    const root = hdkey.fromMasterSeed(seed);\n    // TODO: 60 is specific to ethereum, we could use another value unique to sidetree\n    const hdPath = `m/44'/60'/0'/0/${index}`;\n    const addrNode = root.derive(hdPath);\n    return addrNode.privateKey;\n  }\n\n  private static async generateEd25519KeyPairFromMnemonic(\n    mnemonic: string,\n    index: number\n  ): Promise<[PublicKeyJwkEd25519, PrivateKeyJwkEd25519]> {\n    const privateKeyBuffer = await Jwk.getBufferAtIndex(mnemonic, index);\n    const keyPair = await Ed25519KeyPair.generate({\n      seed: privateKeyBuffer,\n    });\n    const ed25519KeyPair = new Ed25519KeyPair(keyPair);\n    const publicKeyJwk = (await ed25519KeyPair.toJwk(\n      false\n    )) as PublicKeyJwkEd25519;\n    const privateKeyJwk = (await ed25519KeyPair.toJwk(\n      true\n    )) as PrivateKeyJwkEd25519;\n    return [publicKeyJwk, privateKeyJwk];\n  }\n\n  /**\n   * Generates SECP256K1 key pair.\n   * Mainly used for testing.\n   * @returns [publicKey, privateKey]\n   */\n  public static async generateSecp256k1KeyPair(): Promise<\n    [PublicKeyJwkSecp256k1, PrivateKeyJwkSecp256k1]\n  > {\n    const keyPair = await JWK.generate('EC', 'secp256k1');\n    const publicKey = keyPair.toJWK(false) as PublicKeyJwkSecp256k1;\n    const privateKey = keyPair.toJWK(true) as PrivateKeyJwkSecp256k1;\n    return [publicKey, privateKey];\n  }\n\n  public static async generateJwkKeyPairFromMnemonic(\n    keyType: string,\n    mnemonic: string,\n    index: number\n  ): Promise<[PublicKeyJwk, PrivateKeyJwk]> {\n    switch (keyType) {\n      case 'secp256k1':\n        return this.generateSecp256k1KeyPairFromMnemonic(mnemonic, index);\n      case 'ed25519':\n        return this.generateEd25519KeyPairFromMnemonic(mnemonic, index);\n      default:\n        throw new Error('Invalid key type');\n    }\n  }\n\n  private static async generateSecp256k1KeyPairFromMnemonic(\n    mnemonic: string,\n    index: number\n  ): Promise<[PublicKeyJwkSecp256k1, PrivateKeyJwkSecp256k1]> {\n    const privateKeyBuffer = await Jwk.getBufferAtIndex(mnemonic, index);\n    const publicKeyJwk = keytoFrom(privateKeyBuffer, 'blk').toJwk('public');\n    publicKeyJwk.crv = 'secp256k1';\n    const privateKeyJwk = keytoFrom(privateKeyBuffer, 'blk').toJwk('private');\n    privateKeyJwk.crv = 'secp256k1';\n    return [publicKeyJwk, privateKeyJwk];\n  }\n\n  /**\n   * Validates the given key is a public key in JWK format allowed by Sidetree.\n   * @throws SidetreeError if given object is not a key in JWK format allowed by Sidetree.\n   */\n  public static validatePublicJwk(jwk: any): void {\n    if (jwk === undefined) {\n      throw new SidetreeError(ErrorCode.JwkUndefined);\n    }\n\n    // TODO: Check validity with JSON schema...\n    const allowedProperties = new Set(['kty', 'crv', 'x', 'y', 'kid']);\n    for (const property in jwk) {\n      if (!allowedProperties.has(property)) {\n        throw new SidetreeError(ErrorCode.JwkHasUnknownProperty);\n      }\n    }\n\n    switch (jwk.crv) {\n      case 'Ed25519':\n        if (jwk.kty !== 'OKP') {\n          throw new SidetreeError(ErrorCode.JwkMissingOrInvalidKty);\n        }\n        if (typeof jwk.x !== 'string') {\n          throw new SidetreeError(ErrorCode.JwkMissingOrInvalidTypeX);\n        }\n        break;\n      case 'secp256k1':\n        if (jwk.kty !== 'EC') {\n          throw new SidetreeError(ErrorCode.JwkMissingOrInvalidKty);\n        }\n        if (typeof jwk.x !== 'string') {\n          throw new SidetreeError(ErrorCode.JwkMissingOrInvalidTypeX);\n        }\n        if (typeof jwk.y !== 'string') {\n          throw new SidetreeError(ErrorCode.JwkMissingOrInvalidTypeY);\n        }\n        break;\n      default:\n        throw new SidetreeError(ErrorCode.JwkMissingOrInvalidCrv);\n    }\n  }\n\n  /**\n   * Gets the public key given the private ES256K key.\n   * Mainly used for testing purposes.\n   */\n  public static getCurve25519PublicKey(\n    privateKey: PrivateKeyJwkEd25519\n  ): PublicKeyJwkEd25519 {\n    const keyCopy = Object.assign({}, privateKey);\n\n    // Delete the private key portion.\n    delete keyCopy.d;\n\n    return keyCopy;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Encoder,\n  ErrorCode,\n  SidetreeError,\n  PublicKeyJwk,\n  PrivateKeyJwk,\n} from '@sidetree/common';\nimport { EdDSA } from '@transmute/did-key-ed25519';\nimport { ES256K } from '@transmute/did-key-secp256k1';\n\n/**\n * Class containing reusable JWS operations.\n */\nexport default class Jws {\n  /** Protected header. */\n  public readonly protected: string;\n  /** Payload. */\n  public readonly payload: string;\n  /** Signature. */\n  public readonly signature: string;\n\n  /**\n   * Constructs a JWS object.\n   * @param compactJws Input should be a compact JWS string.\n   */\n  private constructor(compactJws: any) {\n    if (typeof compactJws !== 'string') {\n      throw new SidetreeError(ErrorCode.JwsCompactJwsNotString);\n    }\n\n    const parts = compactJws.split('.');\n    if (parts.length !== 3) {\n      throw new SidetreeError(ErrorCode.JwsCompactJwsInvalid);\n    }\n\n    const protectedHeader = parts[0];\n    const payload = parts[1];\n    const signature = parts[2];\n\n    const decodedProtectedHeadJsonString = Encoder.decodeBase64UrlAsString(\n      protectedHeader\n    );\n    const decodedProtectedHeader = JSON.parse(decodedProtectedHeadJsonString);\n\n    const expectedHeaderPropertyCount = 1; // By default we must have header property is `alg`.\n\n    const headerProperties = Object.keys(decodedProtectedHeader);\n    if (headerProperties.length !== expectedHeaderPropertyCount) {\n      throw new SidetreeError(\n        ErrorCode.JwsProtectedHeaderMissingOrUnknownProperty\n      );\n    }\n\n    // Protected header must contain 'alg' property with value 'EdDSA'.\n    if (\n      decodedProtectedHeader.alg !== 'EdDSA' &&\n      decodedProtectedHeader.alg !== 'ES256K'\n    ) {\n      throw new SidetreeError(\n        ErrorCode.JwsProtectedHeaderMissingOrIncorrectAlg\n      );\n    }\n\n    // Must contain Base64URL string 'signature' property.\n    if (!Encoder.isBase64UrlString(signature)) {\n      throw new SidetreeError(ErrorCode.JwsSignatureNotBase64UrlString);\n    }\n\n    // Must contain Base64URL string 'payload' property.\n    if (!Encoder.isBase64UrlString(payload)) {\n      throw new SidetreeError(ErrorCode.JwsPayloadNotBase64UrlString);\n    }\n\n    this.protected = protectedHeader;\n    this.payload = payload;\n    this.signature = signature;\n  }\n\n  /**\n   * Converts this object to a compact JWS string.\n   */\n  public toCompactJws(): string {\n    return Jws.createCompactJws(this.protected, this.payload, this.signature);\n  }\n\n  /**\n   * Verifies the JWS signature.\n   * @returns true if signature is successfully verified, false otherwise.\n   */\n  public async verifySignature(publicKey: PublicKeyJwk): Promise<boolean> {\n    return Jws.verifySignature(\n      this.protected,\n      this.payload,\n      this.signature,\n      publicKey\n    );\n  }\n\n  /**\n   * Verifies the JWS signature.\n   * @returns true if signature is successfully verified, false otherwise.\n   */\n  public static async verifySignature(\n    encodedProtectedHeader: string,\n    encodedPayload: string,\n    signature: string,\n    publicKey: PublicKeyJwk\n  ): Promise<boolean> {\n    const jwsSigningInput =\n      encodedProtectedHeader + '.' + encodedPayload + '.' + signature;\n    const signatureValid = await Jws.verifyCompactJws(\n      jwsSigningInput,\n      publicKey\n    );\n    return signatureValid;\n  }\n\n  /**\n   * Verifies the compact JWS string using the given JWK key.\n   * @returns true if signature is valid; else otherwise.\n   */\n  public static async verifyCompactJws(\n    compactJws: string,\n    jwk: PublicKeyJwk\n  ): Promise<boolean> {\n    try {\n      if (jwk.crv === 'Ed25519') {\n        await EdDSA.verify(compactJws, jwk);\n      } else if (jwk.crv === 'secp256k1') {\n        await ES256K.verify(compactJws, jwk as any);\n      } else {\n        return false;\n      }\n      return true;\n    } catch (error) {\n      console.log(\n        `Input '${compactJws}' failed signature verification: ${SidetreeError.createFromError(\n          ErrorCode.JwsFailedSignatureValidation,\n          error\n        )}`\n      );\n      return false;\n    }\n  }\n\n  /**\n   * Signs the given payload as a compact JWS string.\n   * This is mainly used by tests to create valid test data.\n   */\n  public static async signAsCompactJws(\n    payload: object,\n    privateKey: PrivateKeyJwk,\n    protectedHeader?: any\n  ): Promise<string> {\n    let alg;\n    if (protectedHeader && protectedHeader.alg) {\n      alg = protectedHeader.alg;\n    } else {\n      if (privateKey.crv === 'Ed25519') {\n        alg = 'EdDSA';\n      } else {\n        alg = 'ES256K';\n      }\n    }\n    const header = {\n      ...protectedHeader,\n      alg,\n    };\n    if (privateKey.crv === 'secp256k1') {\n      return await ES256K.sign(payload, privateKey as any, header);\n    }\n    return await EdDSA.sign(payload, privateKey, header);\n  }\n\n  /**\n   * Parses the input as a `Jws` object.\n   */\n  public static parseCompactJws(compactJws: any): Jws {\n    return new Jws(compactJws);\n  }\n\n  /**\n   * Creates a compact JWS string using the given input. No string validation is performed.\n   */\n  public static createCompactJws(\n    protectedHeader: string,\n    payload: string,\n    signature: string\n  ): string {\n    return protectedHeader + '.' + payload + '.' + signature;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Encoder,\n  ErrorCode,\n  PublicKeyJwk,\n  OperationModel,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\nimport JsonAsync from './util/JsonAsync';\nimport Jwk from './util/Jwk';\nimport Jws from './util/Jws';\n\ninterface SignedDataModel {\n  didSuffix: string;\n  recovery_key: PublicKeyJwk;\n}\n\n/**\n * A class that represents a deactivate operation.\n */\nexport default class DeactivateOperation implements OperationModel {\n  /** The original request buffer sent by the requester. */\n  public readonly operationBuffer: Buffer;\n\n  /** The unique suffix of the DID. */\n  public readonly didUniqueSuffix: string;\n\n  /** The type of operation. */\n  public readonly type: OperationType;\n\n  /** Signed data. */\n  public readonly signedDataJws: Jws;\n\n  /** Decoded signed data payload. */\n  public readonly signedData: SignedDataModel;\n\n  /**\n   * NOTE: should only be used by `parse()` and `parseObject()` else the contructed instance could be invalid.\n   */\n  private constructor(\n    operationBuffer: Buffer,\n    didUniqueSuffix: string,\n    signedDataJws: Jws,\n    signedData: SignedDataModel\n  ) {\n    this.operationBuffer = operationBuffer;\n    this.type = OperationType.Deactivate;\n    this.didUniqueSuffix = didUniqueSuffix;\n    this.signedDataJws = signedDataJws;\n    this.signedData = signedData;\n  }\n\n  /**\n   * Parses the given input as a deactivate operation entry in the anchor file.\n   */\n  public static async parseOperationFromAnchorFile(\n    input: any\n  ): Promise<DeactivateOperation> {\n    const operationBuffer = Buffer.from(JSON.stringify(input));\n    const operation = await DeactivateOperation.parseObject(\n      input,\n      operationBuffer,\n      true\n    );\n    return operation;\n  }\n\n  /**\n   * Parses the given buffer as a `UpdateOperation`.\n   */\n  public static async parse(\n    operationBuffer: Buffer\n  ): Promise<DeactivateOperation> {\n    const operationJsonString = operationBuffer.toString();\n    const operationObject = await JsonAsync.parse(operationJsonString);\n    const deactivateOperation = await DeactivateOperation.parseObject(\n      operationObject,\n      operationBuffer,\n      false\n    );\n    return deactivateOperation;\n  }\n\n  /**\n   * Parses the given operation object as a `DeactivateOperation`.\n   * The `operationBuffer` given is assumed to be valid and is assigned to the `operationBuffer` directly.\n   * NOTE: This method is purely intended to be used as an optimization method over the `parse` method in that\n   * JSON parsing is not required to be performed more than once when an operation buffer of an unknown operation type is given.\n   * @param anchorFileMode If set to true, then `type` is expected to be absent.\n   */\n  public static async parseObject(\n    operationObject: any,\n    operationBuffer: Buffer,\n    anchorFileMode: boolean\n  ): Promise<DeactivateOperation> {\n    let expectedPropertyCount = 3;\n    if (anchorFileMode) {\n      expectedPropertyCount = 2;\n    }\n\n    const properties = Object.keys(operationObject);\n    if (properties.length !== expectedPropertyCount) {\n      throw new SidetreeError(\n        ErrorCode.DeactivateOperationMissingOrUnknownProperty\n      );\n    }\n\n    if (typeof operationObject.did_suffix !== 'string') {\n      throw new SidetreeError(\n        ErrorCode.DeactivateOperationMissingOrInvalidDidUniqueSuffix\n      );\n    }\n\n    const signedDataJws = Jws.parseCompactJws(operationObject.signed_data);\n    const signedData = await DeactivateOperation.parseSignedDataPayload(\n      signedDataJws.payload,\n      operationObject.did_suffix\n    );\n\n    // If not in anchor file mode, we need to validate `type` property.\n    if (!anchorFileMode) {\n      if (operationObject.type !== OperationType.Deactivate) {\n        throw new SidetreeError(ErrorCode.DeactivateOperationTypeIncorrect);\n      }\n    }\n\n    return new DeactivateOperation(\n      operationBuffer,\n      operationObject.did_suffix,\n      signedDataJws,\n      signedData\n    );\n  }\n\n  private static async parseSignedDataPayload(\n    deltaEncodedString: string,\n    expectedDidUniqueSuffix: string\n  ): Promise<SignedDataModel> {\n    const signedDataJsonString = Encoder.decodeAsString(deltaEncodedString);\n    const signedData = await JsonAsync.parse(signedDataJsonString);\n\n    const properties = Object.keys(signedData);\n    if (properties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DeactivateOperationSignedDataMissingOrUnknownProperty\n      );\n    }\n\n    if (signedData.did_suffix !== expectedDidUniqueSuffix) {\n      throw new SidetreeError(\n        ErrorCode.DeactivateOperationSignedDidUniqueSuffixMismatch\n      );\n    }\n\n    Jwk.validatePublicJwk(signedData.recovery_key);\n\n    return {\n      didSuffix: signedData.did_suffix,\n      recovery_key: signedData.recovery_key,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  DeltaModel,\n  Encoder,\n  ErrorCode,\n  PublicKeyJwk,\n  Multihash,\n  OperationModel,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\nimport OperationUtils from './OperationUtils';\nimport JsonAsync from './util/JsonAsync';\nimport Jwk from './util/Jwk';\nimport Jws from './util/Jws';\n\ninterface SignedDataModel {\n  delta_hash: string;\n  recovery_key: PublicKeyJwk;\n  recovery_commitment: string;\n}\n\n/**\n * A class that represents a recover operation.\n */\nexport default class RecoverOperation implements OperationModel {\n  /** The original request buffer sent by the requester. */\n  public readonly operationBuffer: Buffer;\n\n  /** The unique suffix of the DID. */\n  public readonly didUniqueSuffix: string;\n\n  /** The type of operation. */\n  public readonly type: OperationType;\n\n  /** Signed data. */\n  public readonly signedDataJws: Jws;\n\n  /** Encoded string of the delta. */\n  public readonly encodedDelta: string | undefined;\n\n  /** Decoded signed data payload. */\n  public readonly signedData: SignedDataModel;\n\n  /** Patch data. */\n  public readonly delta: DeltaModel | undefined;\n\n  /**\n   * NOTE: should only be used by `parse()` and `parseObject()` else the constructed instance could be invalid.\n   */\n  private constructor(\n    operationBuffer: Buffer,\n    didUniqueSuffix: string,\n    signedDataJws: Jws,\n    signedData: SignedDataModel,\n    encodedDelta: string | undefined,\n    delta: DeltaModel | undefined\n  ) {\n    this.operationBuffer = operationBuffer;\n    this.type = OperationType.Recover;\n    this.didUniqueSuffix = didUniqueSuffix;\n    this.signedDataJws = signedDataJws;\n    this.signedData = signedData;\n    this.encodedDelta = encodedDelta;\n    this.delta = delta;\n  }\n\n  /**\n   * Parses the given input as a recover operation entry in the anchor file.\n   */\n  public static async parseOperationFromAnchorFile(\n    input: any\n  ): Promise<RecoverOperation> {\n    const operationBuffer = Buffer.from(JSON.stringify(input));\n    const operation = await RecoverOperation.parseObject(\n      input,\n      operationBuffer,\n      true\n    );\n    return operation;\n  }\n\n  /**\n   * Parses the given buffer as a `UpdateOperation`.\n   */\n  public static async parse(\n    operationBuffer: Buffer\n  ): Promise<RecoverOperation> {\n    const operationJsonString = operationBuffer.toString();\n    const operationObject = await JsonAsync.parse(operationJsonString);\n    const recoverOperation = await RecoverOperation.parseObject(\n      operationObject,\n      operationBuffer,\n      false\n    );\n    return recoverOperation;\n  }\n\n  /**\n   * Parses the given operation object as a `RecoverOperation`.\n   * The `operationBuffer` given is assumed to be valid and is assigned to the `operationBuffer` directly.\n   * NOTE: This method is purely intended to be used as an optimization method over the `parse` method in that\n   * JSON parsing is not required to be performed more than once when an operation buffer of an unknown operation type is given.\n   * @param anchorFileMode If set to true, then `delta` and `type` properties are expected to be absent.\n   */\n  public static async parseObject(\n    operationObject: any,\n    operationBuffer: Buffer,\n    anchorFileMode: boolean\n  ): Promise<RecoverOperation> {\n    let expectedPropertyCount = 4;\n    if (anchorFileMode) {\n      expectedPropertyCount = 2;\n    }\n\n    const properties = Object.keys(operationObject);\n    if (properties.length !== expectedPropertyCount) {\n      throw new SidetreeError(\n        ErrorCode.RecoverOperationMissingOrUnknownProperty\n      );\n    }\n\n    if (typeof operationObject.did_suffix !== 'string') {\n      throw new SidetreeError(\n        ErrorCode.RecoverOperationMissingOrInvalidDidUniqueSuffix\n      );\n    }\n\n    const signedDataJws = Jws.parseCompactJws(operationObject.signed_data);\n    const signedData = await RecoverOperation.parseSignedDataPayload(\n      signedDataJws.payload\n    );\n\n    // If not in anchor file mode, we need to validate `type` and `delta` properties.\n    let encodedDelta = undefined;\n    let delta = undefined;\n    if (!anchorFileMode) {\n      if (operationObject.type !== OperationType.Recover) {\n        throw new SidetreeError(ErrorCode.RecoverOperationTypeIncorrect);\n      }\n\n      encodedDelta = operationObject.delta;\n      try {\n        delta = await OperationUtils.parseDelta(operationObject.delta);\n      } catch {\n        // For compatibility with data pruning, we have to assume that delta may be unavailable,\n        // thus an operation with invalid delta needs to be processed as an operation with unavailable delta,\n        // so here we let delta be `undefined`.\n      }\n    }\n\n    return new RecoverOperation(\n      operationBuffer,\n      operationObject.did_suffix,\n      signedDataJws,\n      signedData,\n      encodedDelta,\n      delta\n    );\n  }\n\n  private static async parseSignedDataPayload(\n    signedDataEncodedString: string\n  ): Promise<SignedDataModel> {\n    const signedDataJsonString = Encoder.decodeAsString(\n      signedDataEncodedString\n    );\n    const signedData = await JsonAsync.parse(signedDataJsonString);\n\n    const properties = Object.keys(signedData);\n\n    // TODO: JSON Schema instead of property count type checking...\n    if (properties.length !== 3) {\n      throw new SidetreeError(\n        ErrorCode.RecoverOperationSignedDataMissingOrUnknownProperty\n      );\n    }\n\n    Jwk.validatePublicJwk(signedData.recovery_key);\n\n    const delta_hash = Encoder.decodeAsBuffer(signedData.delta_hash);\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(delta_hash);\n\n    const nextRecoveryCommitmentHash = Encoder.decodeAsBuffer(\n      signedData.recovery_commitment\n    );\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(\n      nextRecoveryCommitmentHash\n    );\n\n    return {\n      delta_hash: signedData.delta_hash,\n      recovery_key: signedData.recovery_key,\n      recovery_commitment: signedData.recovery_commitment,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AnchorFileModel, ErrorCode, SidetreeError } from '@sidetree/common';\nimport ArrayMethods from '../util/ArrayMethods';\nimport Compressor from '../util/Compressor';\nimport CreateOperation from '../CreateOperation';\nimport DeactivateOperation from '../DeactivateOperation';\nimport JsonAsync from '../util/JsonAsync';\nimport RecoverOperation from '../RecoverOperation';\n\n/**\n * Class containing Anchor File related operations.\n */\nexport default class AnchorFile {\n  /**\n   * Class that represents an anchor file.\n   * NOTE: this class is introduced as an internal structure in replacement to `AnchorFileModel`\n   * to keep useful metadata so that repeated computation can be avoided.\n   */\n  private constructor(\n    public readonly model: AnchorFileModel,\n    public readonly didUniqueSuffixes: string[],\n    public readonly createOperations: CreateOperation[],\n    public readonly recoverOperations: RecoverOperation[],\n    public readonly deactivateOperations: DeactivateOperation[]\n  ) {}\n\n  /**\n   * Parses and validates the given anchor file buffer.\n   * @throws `SidetreeError` if failed parsing or validation.\n   */\n  public static async parse(anchorFileBuffer: Buffer): Promise<AnchorFile> {\n    let anchorFileDecompressedBuffer;\n    try {\n      anchorFileDecompressedBuffer = await Compressor.decompress(\n        anchorFileBuffer\n      );\n    } catch (e) {\n      throw SidetreeError.createFromError(\n        ErrorCode.AnchorFileDecompressionFailure,\n        e\n      );\n    }\n\n    let anchorFileModel;\n    try {\n      anchorFileModel = await JsonAsync.parse(anchorFileDecompressedBuffer);\n    } catch (e) {\n      throw SidetreeError.createFromError(ErrorCode.AnchorFileNotJson, e);\n    }\n\n    const allowedProperties = new Set([\n      'map_file_uri',\n      'operations',\n      'writer_lock_id',\n    ]);\n    for (const property in anchorFileModel) {\n      if (!allowedProperties.has(property)) {\n        throw new SidetreeError(ErrorCode.AnchorFileHasUnknownProperty);\n      }\n    }\n\n    if (\n      !Object.prototype.hasOwnProperty.call(anchorFileModel, 'map_file_uri')\n    ) {\n      throw new SidetreeError(ErrorCode.AnchorFileMapFileHashMissing);\n    }\n\n    if (!Object.prototype.hasOwnProperty.call(anchorFileModel, 'operations')) {\n      throw new SidetreeError(ErrorCode.AnchorFileMissingOperationsProperty);\n    }\n\n    if (\n      Object.prototype.hasOwnProperty.call(anchorFileModel, 'writer_lock_id') &&\n      typeof anchorFileModel.writer_lock_id !== 'string'\n    ) {\n      throw new SidetreeError(ErrorCode.AnchorFileWriterLockIPropertyNotString);\n    }\n\n    // Map file hash validations.\n    const mapFileUri = anchorFileModel.map_file_uri;\n    if (typeof mapFileUri !== 'string') {\n      throw new SidetreeError(ErrorCode.AnchorFileMapFileHashNotString);\n    }\n\n    const allowedOperationsProperties = new Set([\n      'create',\n      'recover',\n      'deactivate',\n    ]);\n    const operations = anchorFileModel.operations;\n    for (const property in operations) {\n      if (!allowedOperationsProperties.has(property)) {\n        throw new SidetreeError(\n          ErrorCode.AnchorFileUnexpectedPropertyInOperations,\n          `Unexpected property ${property} in 'operations' property in anchor file.`\n        );\n      }\n    }\n\n    // Will be populated for later validity check.\n    const didUniqueSuffixes: string[] = [];\n\n    // Validate `create` if exists.\n    const createOperations: CreateOperation[] = [];\n    if (operations.create !== undefined) {\n      if (!Array.isArray(operations.create)) {\n        throw new SidetreeError(ErrorCode.AnchorFileCreatePropertyNotArray);\n      }\n\n      // Validate every create operation.\n      for (const operation of operations.create) {\n        const createOperation = await CreateOperation.parseOperationFromAnchorFile(\n          operation\n        );\n        createOperations.push(createOperation);\n        didUniqueSuffixes.push(createOperation.didUniqueSuffix);\n      }\n    }\n\n    // Validate `recover` if exists.\n    const recoverOperations: RecoverOperation[] = [];\n    if (operations.recover !== undefined) {\n      if (!Array.isArray(operations.recover)) {\n        throw new SidetreeError(ErrorCode.AnchorFileRecoverPropertyNotArray);\n      }\n\n      // Validate every recover operation.\n      for (const operation of operations.recover) {\n        const recoverOperation = await RecoverOperation.parseOperationFromAnchorFile(\n          operation\n        );\n        recoverOperations.push(recoverOperation);\n        didUniqueSuffixes.push(recoverOperation.didUniqueSuffix);\n      }\n    }\n\n    // Validate `deactivate` if exists.\n    const deactivateOperations: DeactivateOperation[] = [];\n    if (operations.deactivate !== undefined) {\n      if (!Array.isArray(operations.deactivate)) {\n        throw new SidetreeError(ErrorCode.AnchorFileDeactivatePropertyNotArray);\n      }\n\n      // Validate every operation.\n      for (const operation of operations.deactivate) {\n        const deactivateOperation = await DeactivateOperation.parseOperationFromAnchorFile(\n          operation\n        );\n        deactivateOperations.push(deactivateOperation);\n        didUniqueSuffixes.push(deactivateOperation.didUniqueSuffix);\n      }\n    }\n\n    if (ArrayMethods.hasDuplicates(didUniqueSuffixes)) {\n      throw new SidetreeError(\n        ErrorCode.AnchorFileMultipleOperationsForTheSameDid\n      );\n    }\n\n    const anchorFile = new AnchorFile(\n      anchorFileModel,\n      didUniqueSuffixes,\n      createOperations,\n      recoverOperations,\n      deactivateOperations\n    );\n    return anchorFile;\n  }\n\n  /**\n   * Creates an `AnchorFileModel`.\n   */\n  public static async createModel(\n    writerLockId: string | undefined,\n    mapFileHash: string,\n    createOperationArray: CreateOperation[],\n    recoverOperationArray: RecoverOperation[],\n    deactivateOperationArray: DeactivateOperation[]\n  ): Promise<AnchorFileModel> {\n    const createOperations = createOperationArray.map((operation) => {\n      return {\n        suffix_data: operation.encodedSuffixData,\n      };\n    });\n\n    const recoverOperations = recoverOperationArray.map((operation) => {\n      return {\n        did_suffix: operation.didUniqueSuffix,\n        signed_data: operation.signedDataJws.toCompactJws(),\n      };\n    });\n\n    const deactivateOperations = deactivateOperationArray.map((operation) => {\n      return {\n        did_suffix: operation.didUniqueSuffix,\n        signed_data: operation.signedDataJws.toCompactJws(),\n      };\n    });\n\n    const anchorFileModel = {\n      writer_lock_id: writerLockId,\n      map_file_uri: mapFileHash,\n      operations: {\n        create: createOperations,\n        recover: recoverOperations,\n        deactivate: deactivateOperations,\n      },\n    };\n\n    return anchorFileModel;\n  }\n\n  /**\n   * Creates an anchor file buffer.\n   */\n  public static async createBuffer(\n    writerLockId: string | undefined,\n    mapFileHash: string,\n    createOperations: CreateOperation[],\n    recoverOperations: RecoverOperation[],\n    deactivateOperations: DeactivateOperation[]\n  ): Promise<Buffer> {\n    const anchorFileModel = await AnchorFile.createModel(\n      writerLockId,\n      mapFileHash,\n      createOperations,\n      recoverOperations,\n      deactivateOperations\n    );\n    const anchorFileJson = JSON.stringify(anchorFileModel);\n    const anchorFileBuffer = Buffer.from(anchorFileJson);\n\n    return Compressor.compress(anchorFileBuffer);\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { IBlockchain, IVersionManager } from '@sidetree/common';\nimport timeSpan from 'time-span';\n\n/**\n * Class that performs periodic writing of batches of Sidetree operations to CAS and blockchain.\n */\nexport default class BatchScheduler {\n  /**\n   * Denotes if the periodic batch writing should continue to occur.\n   * Used mainly for test purposes.\n   */\n  private continuePeriodicBatchWriting = false;\n\n  public constructor(\n    private versionManager: IVersionManager,\n    private blockchain: IBlockchain,\n    private batchingIntervalInSeconds: number\n  ) {}\n\n  /**\n   * The function that starts periodically anchoring operation batches to blockchain.\n   */\n  public startPeriodicBatchWriting() {\n    this.continuePeriodicBatchWriting = true;\n    setImmediate(async () => this.writeOperationBatch());\n  }\n\n  /**\n   * Stops periodic batch writing.\n   * Mainly used for test purposes.\n   */\n  public stopPeriodicBatchWriting() {\n    console.info(`Stopped periodic batch writing.`);\n    this.continuePeriodicBatchWriting = false;\n  }\n\n  /**\n   * Processes the operations in the queue.\n   */\n  public async writeOperationBatch() {\n    const endTimer = timeSpan(); // For calcuating time taken to write operations.\n\n    try {\n      console.info('Start operation batch writing...');\n\n      // Get the correct version of the `BatchWriter`.\n      const currentTime = this.blockchain.approximateTime.time;\n      const batchWriter = this.versionManager.getBatchWriter(currentTime);\n\n      await batchWriter.write();\n    } catch (error) {\n      console.error(\n        'Unexpected and unhandled error during batch writing, investigate and fix:'\n      );\n      console.error(error);\n    } finally {\n      console.info(`End batch writing. Duration: ${endTimer.rounded()} ms.`);\n\n      if (this.continuePeriodicBatchWriting) {\n        console.info(\n          `Waiting for ${this.batchingIntervalInSeconds} seconds before writing another batch.`\n        );\n        setTimeout(\n          async () => this.writeOperationBatch(),\n          this.batchingIntervalInSeconds * 1000\n        );\n      }\n    }\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ChunkFileModel,\n  ErrorCode,\n  SidetreeError,\n  protocolParameters,\n} from '@sidetree/common';\nimport timeSpan from 'time-span';\nimport CreateOperation from '../CreateOperation';\nimport RecoverOperation from '../RecoverOperation';\nimport UpdateOperation from '../UpdateOperation';\nimport Compressor from '../util/Compressor';\nimport JsonAsync from '../util/JsonAsync';\n\n/**\n * Defines schema of a Chunk File and its related operations.\n * NOTE: Must NOT add properties not defined by Sidetree protocol.\n */\nexport default class ChunkFile {\n  /**\n   * Parses and validates the given chunk file buffer and all the operations within it.\n   * @throws SidetreeError if failed parsing or validation.\n   */\n  public static async parse(chunkFileBuffer: Buffer): Promise<ChunkFileModel> {\n    const endTimer = timeSpan();\n    const decompressedChunkFileBuffer = await Compressor.decompress(\n      chunkFileBuffer\n    );\n    const chunkFileObject = await JsonAsync.parse(decompressedChunkFileBuffer);\n    console.info(`Parsed chunk file in ${endTimer.rounded()} ms.`);\n\n    // Ensure only properties specified by Sidetree protocol are given.\n    const allowedProperties = new Set(['deltas']);\n    for (const property in chunkFileObject) {\n      if (!allowedProperties.has(property)) {\n        throw new SidetreeError(\n          ErrorCode.ChunkFileUnexpectedProperty,\n          `Unexpected property ${property} in chunk file.`\n        );\n      }\n    }\n\n    this.validateDeltasProperty(chunkFileObject.deltas);\n\n    return chunkFileObject;\n  }\n\n  private static validateDeltasProperty(deltas: any) {\n    // Make sure deltas is an array.\n    if (!(deltas instanceof Array)) {\n      throw new SidetreeError(\n        ErrorCode.ChunkFileDeltasPropertyNotArray,\n        'Invalid chunk file, deltas property is not an array.'\n      );\n    }\n\n    // Validate every encoded delta string.\n    for (const encodedDelta of deltas) {\n      if (typeof encodedDelta !== 'string') {\n        throw new SidetreeError(\n          ErrorCode.ChunkFileDeltasNotArrayOfStrings,\n          'Invalid chunk file, deltas property is not an array of strings.'\n        );\n      }\n\n      const deltaBuffer = Buffer.from(encodedDelta);\n\n      // Verify size of each delta does not exceed the maximum allowed limit.\n      if (deltaBuffer.length > protocolParameters.maxDeltaSizeInBytes) {\n        throw new SidetreeError(\n          ErrorCode.ChunkFileDeltaSizeExceedsLimit,\n          `Operation size of ${deltaBuffer.length} bytes exceeds the allowed limit of ${protocolParameters.maxDeltaSizeInBytes} bytes.`\n        );\n      }\n    }\n  }\n\n  /**\n   * Creates chunk file buffer.\n   */\n  public static async createBuffer(\n    createOperations: CreateOperation[],\n    recoverOperations: RecoverOperation[],\n    updateOperations: UpdateOperation[]\n  ) {\n    const deltas = [];\n    deltas.push(\n      ...createOperations.map((operation) => operation.encodedDelta!)\n    );\n    deltas.push(\n      ...recoverOperations.map((operation) => operation.encodedDelta!)\n    );\n    deltas.push(\n      ...updateOperations.map((operation) => operation.encodedDelta!)\n    );\n\n    const chunkFileModel = {\n      deltas,\n    };\n\n    const rawData = Buffer.from(JSON.stringify(chunkFileModel));\n    const compressedRawData = await Compressor.compress(Buffer.from(rawData));\n\n    return compressedRawData;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as crypto from 'crypto';\nimport { ICas, FetchResult } from '@sidetree/common';\n\n/**\n * Interface containing information regarding each queued CAS download.\n */\ninterface DownloadInfo {\n  /**\n   * A globally unique handle to this download.\n   */\n  handle: Buffer;\n\n  /**\n   * The content hash used to perform the download from CAS.\n   */\n  contentHash: string;\n\n  /**\n   * The maximum allowed content size.\n   */\n  maxSizeInBytes: number;\n\n  /**\n   * The resolve function that will be invoked by the download manager when download is completed\n   * regarless if the download is successful or not.\n   */\n  resolve: (value?: any | PromiseLike<any> | undefined) => void;\n\n  /**\n   * Set to true if download attempt is completed either successfully or unsuccessfully.\n   */\n  completed: boolean;\n\n  /**\n   * Holds the fetch result once the download is completed.\n   */\n  fetchResult?: FetchResult;\n}\n\n/**\n * A download manager class that performs multiple downloads at the same time.\n */\nexport default class DownloadManager {\n  private pendingDownloads: DownloadInfo[] = [];\n  private activeDownloads: Map<Buffer, DownloadInfo> = new Map();\n  private completedDownloads: Map<Buffer, FetchResult> = new Map();\n\n  /**\n   * Constructs the download manager.\n   * @param cas The Content Adressable Store to use for fetching the actual content.\n   */\n  public constructor(public maxConcurrentDownloads: number, private cas: ICas) {\n    // If maximum concurrent CAS download count is NaN, set it to a default value.\n    if (isNaN(maxConcurrentDownloads)) {\n      const defaultmaxConcurrentDownloads = 20;\n      console.info(\n        `Maximum concurrent CAS download count not given, defaulting to ${defaultmaxConcurrentDownloads}.`\n      );\n      this.maxConcurrentDownloads = defaultmaxConcurrentDownloads;\n    }\n  }\n\n  /**\n   * Starts pending downloads if maximum concurrent download count is not reached,\n   * and resolve downloads that are completed, then invokes this same method again,\n   * thus this method must only be invoked once externally as initialization.\n   */\n  public start() {\n    try {\n      // Move all completed downloads in `activeDownloads` to the `completedDownloads` map.\n      const completedDownloadHandles = [];\n      for (const [downloadHandle, downloadInfo] of this.activeDownloads) {\n        if (downloadInfo.completed) {\n          this.completedDownloads.set(\n            downloadHandle,\n            downloadInfo.fetchResult!\n          );\n          completedDownloadHandles.push(downloadHandle);\n\n          // Resolve the promise associated with the download.\n          downloadInfo.resolve();\n        }\n      }\n      for (const downloadHandle of completedDownloadHandles) {\n        this.activeDownloads.delete(downloadHandle);\n      }\n\n      // If maximum concurrent download count is reached, then we can't schedule more downloads.\n      const availableDownloadLanes =\n        this.maxConcurrentDownloads - this.activeDownloads.size;\n      if (availableDownloadLanes <= 0) {\n        return;\n      }\n\n      // Else we can schedule more downloads, but only if there are pending downloads.\n      if (this.pendingDownloads.length === 0) {\n        return;\n      }\n\n      // Keep start downloading the next queued item until all download lanes are full or there is no more item to download.\n      for (\n        let i = 0;\n        i < this.pendingDownloads.length && i < availableDownloadLanes;\n        i++\n      ) {\n        const downloadInfo = this.pendingDownloads[i];\n\n        // Intentionally not awaiting on a download.\n        void this.downloadAsync(downloadInfo);\n        this.activeDownloads.set(downloadInfo.handle, downloadInfo);\n      }\n\n      // Remove active downloads from `pendingDownloads` list.\n      this.pendingDownloads.splice(0, availableDownloadLanes);\n    } catch (error) {\n      console.error(\n        `Encountered unhandled/unexpected error in DownloadManager, must investigate and fix: ${error}`\n      );\n    } finally {\n      setTimeout(async () => this.start(), 1000);\n    }\n  }\n\n  /**\n   * Downloads the content of the given content hash.\n   * @param contentHash Hash of the content to be downloaded.\n   */\n  public async download(\n    contentHash: string,\n    maxSizeInBytes: number\n  ): Promise<FetchResult> {\n    const handle = crypto.randomBytes(32);\n    const fetchPromise = new Promise((resolve) => {\n      const downloadInfo = {\n        handle,\n        contentHash,\n        maxSizeInBytes,\n        resolve,\n        completed: false,\n        content: undefined,\n      };\n      this.pendingDownloads.push(downloadInfo);\n    });\n\n    await fetchPromise;\n\n    const fetchResult = this.completedDownloads.get(handle);\n    this.completedDownloads.delete(handle);\n\n    return fetchResult!;\n  }\n\n  /**\n   * The internal download method that gets called by the main download manager monitoring loop when download lanes are available to download content.\n   * NOTE: This method MUST NEVER throw (more accurately: ALWAYS set downloadInfo.completed = true),\n   * else it will LEAK the available download lanes and in turn hang the Observer.\n   * @param downloadInfo Data structure containing `completed` flag and `fetchResult`,\n   *                     used to signal to the main download manager monitoring loop when the requested download is completed.\n   */\n  private async downloadAsync(downloadInfo: DownloadInfo): Promise<void> {\n    let contentHash = '';\n    try {\n      contentHash = downloadInfo.contentHash;\n\n      const fetchResult = await this.cas.read(\n        contentHash\n        // downloadInfo.maxSizeInBytes\n      );\n\n      downloadInfo.fetchResult = fetchResult;\n    } catch (error) {\n      console.error(\n        `Unexpected error while downloading '${contentHash}, investigate and fix ${error}'.`\n      );\n    } finally {\n      downloadInfo.completed = true;\n    }\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  DeltaModel,\n  Encoder,\n  ErrorCode,\n  PublicKeyJwk,\n  Multihash,\n  OperationModel,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\nimport JsonAsync from './util/JsonAsync';\nimport Jwk from './util/Jwk';\nimport Jws from './util/Jws';\nimport OperationUtils from './OperationUtils';\n\ninterface SignedDataModel {\n  delta_hash: string;\n  update_key: PublicKeyJwk;\n}\n\n/**\n * A class that represents an update operation.\n */\nexport default class UpdateOperation implements OperationModel {\n  /** The original request buffer sent by the requester. */\n  public readonly operationBuffer: Buffer;\n\n  /** The unique suffix of the DID. */\n  public readonly didUniqueSuffix: string;\n\n  /** The type of operation. */\n  public readonly type: OperationType;\n\n  /** Signed data for the operation. */\n  public readonly signedDataJws: Jws;\n\n  /** Decoded signed data payload. */\n  public readonly signedData: SignedDataModel;\n\n  /** Patch data. */\n  public readonly delta: DeltaModel | undefined;\n\n  /** Encoded string of the delta. */\n  public readonly encodedDelta: string | undefined;\n\n  /**\n   * NOTE: should only be used by `parse()` and `parseObject()` else the contructed instance could be invalid.\n   */\n  private constructor(\n    operationBuffer: Buffer,\n    didUniqueSuffix: string,\n    signedDataJws: Jws,\n    signedData: SignedDataModel,\n    encodedDelta: string | undefined,\n    delta: DeltaModel | undefined\n  ) {\n    this.operationBuffer = operationBuffer;\n    this.type = OperationType.Update;\n    this.didUniqueSuffix = didUniqueSuffix;\n    this.signedDataJws = signedDataJws;\n    this.signedData = signedData;\n    this.encodedDelta = encodedDelta;\n    this.delta = delta;\n  }\n\n  /**\n   * Parses the given input as an update operation entry in the map file.\n   */\n  public static async parseOperationFromMapFile(\n    input: any\n  ): Promise<UpdateOperation> {\n    const operationBuffer = Buffer.from(JSON.stringify(input));\n    const operation = await UpdateOperation.parseObject(\n      input,\n      operationBuffer,\n      true\n    );\n    return operation;\n  }\n\n  /**\n   * Parses the given buffer as a `UpdateOperation`.\n   */\n  public static async parse(operationBuffer: Buffer): Promise<UpdateOperation> {\n    const operationJsonString = operationBuffer.toString();\n    const operationObject = await JsonAsync.parse(operationJsonString);\n    const updateOperation = await UpdateOperation.parseObject(\n      operationObject,\n      operationBuffer,\n      false\n    );\n    return updateOperation;\n  }\n\n  /**\n   * Parses the given operation object as a `UpdateOperation`.\n   * The `operationBuffer` given is assumed to be valid and is assigned to the `operationBuffer` directly.\n   * NOTE: This method is purely intended to be used as an optimization method over the `parse` method in that\n   * JSON parsing is not required to be performed more than once when an operation buffer of an unknown operation type is given.\n   * @param mapFileMode If set to true, then `delta` and `type` properties are expected to be absent.\n   */\n  public static async parseObject(\n    operationObject: any,\n    operationBuffer: Buffer,\n    mapFileMode: boolean\n  ): Promise<UpdateOperation> {\n    let expectedPropertyCount = 4;\n    if (mapFileMode) {\n      expectedPropertyCount = 2;\n    }\n\n    const properties = Object.keys(operationObject);\n    if (properties.length !== expectedPropertyCount) {\n      throw new SidetreeError(\n        ErrorCode.UpdateOperationMissingOrUnknownProperty\n      );\n    }\n\n    if (typeof operationObject.did_suffix !== 'string') {\n      throw new SidetreeError(ErrorCode.UpdateOperationMissingDidUniqueSuffix);\n    }\n\n    const signedData = Jws.parseCompactJws(operationObject.signed_data);\n    const signedDataModel = await UpdateOperation.parseSignedDataPayload(\n      signedData.payload\n    );\n\n    // If not in map file mode, we need to validate `type` and `delta` properties.\n    let encodedDelta = undefined;\n    let delta = undefined;\n    if (!mapFileMode) {\n      if (operationObject.type !== OperationType.Update) {\n        throw new SidetreeError(ErrorCode.UpdateOperationTypeIncorrect);\n      }\n\n      encodedDelta = operationObject.delta;\n      delta = await OperationUtils.parseDelta(encodedDelta);\n    }\n\n    return new UpdateOperation(\n      operationBuffer,\n      operationObject.did_suffix,\n      signedData,\n      signedDataModel,\n      encodedDelta,\n      delta\n    );\n  }\n\n  private static async parseSignedDataPayload(\n    signedDataEncodedString: string\n  ): Promise<SignedDataModel> {\n    const signedDataJsonString = Encoder.decodeAsString(\n      signedDataEncodedString\n    );\n    const signedData = await JsonAsync.parse(signedDataJsonString);\n\n    const properties = Object.keys(signedData);\n    if (properties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.UpdateOperationSignedDataHasMissingOrUnknownProperty\n      );\n    }\n\n    Jwk.validatePublicJwk(signedData.update_key);\n\n    const delta_hash = Encoder.decodeAsBuffer(signedData.delta_hash);\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(delta_hash);\n\n    return {\n      delta_hash: signedData.delta_hash,\n      update_key: signedData.update_key,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ErrorCode, MapFileModel, SidetreeError } from '@sidetree/common';\nimport UpdateOperation from '../UpdateOperation';\nimport ArrayMethods from '../util/ArrayMethods';\nimport Compressor from '../util/Compressor';\nimport JsonAsync from '../util/JsonAsync';\n\n/**\n * Class containing Map File related operations.\n */\nexport default class MapFile {\n  /**\n   * Class that represents a map file.\n   * NOTE: this class is introduced as an internal structure in replacement to `MapFileModel`\n   * to keep useful metadata so that repeated computation can be avoided.\n   */\n  private constructor(\n    public readonly model: MapFileModel,\n    public readonly didUniqueSuffixes: string[],\n    public readonly updateOperations: UpdateOperation[]\n  ) {}\n\n  /**\n   * Parses and validates the given map file buffer.\n   * @throws `SidetreeError` if failed parsing or validation.\n   */\n  public static async parse(mapFileBuffer: Buffer): Promise<MapFile> {\n    let decompressedBuffer;\n    try {\n      decompressedBuffer = await Compressor.decompress(mapFileBuffer);\n    } catch (error) {\n      throw SidetreeError.createFromError(\n        ErrorCode.MapFileDecompressionFailure,\n        error\n      );\n    }\n\n    let mapFileModel;\n    try {\n      mapFileModel = await JsonAsync.parse(decompressedBuffer);\n    } catch (error) {\n      throw SidetreeError.createFromError(ErrorCode.MapFileNotJson, error);\n    }\n\n    const allowedProperties = new Set(['chunks', 'operations']);\n    for (const property in mapFileModel) {\n      if (!allowedProperties.has(property)) {\n        throw new SidetreeError(ErrorCode.MapFileHasUnknownProperty);\n      }\n    }\n\n    MapFile.validateChunksProperty(mapFileModel.chunks);\n\n    const updateOperations = await MapFile.parseOperationsProperty(\n      mapFileModel.operations\n    );\n    const didUniqueSuffixes = updateOperations.map(\n      (operation) => operation.didUniqueSuffix\n    );\n\n    const mapFile = new MapFile(\n      mapFileModel,\n      didUniqueSuffixes,\n      updateOperations\n    );\n    return mapFile;\n  }\n\n  /**\n   * Validates the given `operations` property, throws error if the property fails validation.\n   */\n  private static async parseOperationsProperty(\n    operations: any\n  ): Promise<UpdateOperation[]> {\n    if (operations === undefined) {\n      return [];\n    }\n\n    const properties = Object.keys(operations);\n    if (properties.length !== 1) {\n      throw new SidetreeError(\n        ErrorCode.MapFileOperationsPropertyHasMissingOrUnknownProperty\n      );\n    }\n\n    const updateOperations: UpdateOperation[] = [];\n    if (!Array.isArray(operations.update)) {\n      throw new SidetreeError(ErrorCode.MapFileUpdateOperationsNotArray);\n    }\n\n    // Validate each update operation.\n    for (const operation of operations.update) {\n      const updateOperation = await UpdateOperation.parseOperationFromMapFile(\n        operation\n      );\n      updateOperations.push(updateOperation);\n    }\n\n    // Make sure no operation with same DID.\n    const didUniqueSuffixes = updateOperations.map(\n      (operation) => operation.didUniqueSuffix\n    );\n    if (ArrayMethods.hasDuplicates(didUniqueSuffixes)) {\n      throw new SidetreeError(ErrorCode.MapFileMultipleOperationsForTheSameDid);\n    }\n\n    return updateOperations;\n  }\n\n  /**\n   * Validates the given `chunks` property, throws error if the property fails validation.\n   */\n  private static validateChunksProperty(chunks: any) {\n    if (!Array.isArray(chunks)) {\n      throw new SidetreeError(\n        ErrorCode.MapFileChunksPropertyMissingOrIncorrectType\n      );\n    }\n\n    // This version expects only one hash.\n    if (chunks.length !== 1) {\n      throw new SidetreeError(\n        ErrorCode.MapFileChunksPropertyDoesNotHaveExactlyOneElement\n      );\n    }\n\n    const chunk = chunks[0];\n    const properties = Object.keys(chunk);\n    if (properties.length !== 1) {\n      throw new SidetreeError(\n        ErrorCode.MapFileChunkHasMissingOrUnknownProperty\n      );\n    }\n  }\n\n  /**\n   * Creates the Map File buffer.\n   */\n  public static async createBuffer(\n    chunkFileHash: string,\n    updateOperationArray: UpdateOperation[]\n  ): Promise<Buffer> {\n    const updateOperations = updateOperationArray.map((operation) => {\n      return {\n        did_suffix: operation.didUniqueSuffix,\n        signed_data: operation.signedDataJws.toCompactJws(),\n      };\n    });\n\n    const mapFileModel: MapFileModel = {\n      chunks: [{ chunk_file_uri: chunkFileHash }],\n    };\n\n    // Only insert an `operations` property if there are update operations.\n    if (updateOperations.length > 0) {\n      mapFileModel.operations = {\n        update: updateOperations,\n      };\n    }\n\n    const rawData = JSON.stringify(mapFileModel);\n    const compressedRawData = await Compressor.compress(Buffer.from(rawData));\n\n    return compressedRawData;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { IVersionManager, TransactionModel } from '@sidetree/common';\n\n/**\n * Keeps track of current block and throughput limits based on the state\n */\nexport default class ThroughputLimiter {\n  constructor(private versionManager: IVersionManager) {}\n\n  /**\n   * given a an array of transactions, return an array of qualified transactions per transaction time.\n   * @param transactions array of transactions to filter for\n   */\n  public async getQualifiedTransactions(transactions: TransactionModel[]) {\n    let currentTransactionTime: number | undefined = undefined;\n    const transactionsGroupedByTransactionTime: TransactionModel[][] = [];\n\n    for (const transaction of transactions) {\n      // If transaction is transitioning into a new time, create a new grouping.\n      if (transaction.transactionTime !== currentTransactionTime) {\n        transactionsGroupedByTransactionTime.push([]);\n        currentTransactionTime = transaction.transactionTime;\n      }\n      transactionsGroupedByTransactionTime[\n        transactionsGroupedByTransactionTime.length - 1\n      ].push(transaction);\n    }\n\n    const qualifiedTransactions: TransactionModel[] = [];\n    for (const transactionGroup of transactionsGroupedByTransactionTime) {\n      const transactionSelector = this.versionManager.getTransactionSelector(\n        transactionGroup[0].transactionTime\n      );\n      const qualifiedTransactionsInCurrentGroup = await transactionSelector.selectQualifiedTransactions(\n        transactionGroup\n      );\n      qualifiedTransactions.push(...qualifiedTransactionsInCurrentGroup);\n    }\n    return qualifiedTransactions;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  IBlockchain,\n  IOperationStore,\n  ITransactionProcessor,\n  ITransactionStore,\n  IUnresolvableTransactionStore,\n  IVersionManager,\n  SharedErrorCode,\n  SidetreeError,\n  TransactionModel,\n  TransactionUnderProcessingModel,\n  TransactionProcessingStatus,\n} from '@sidetree/common';\nimport timeSpan from 'time-span';\nimport ThroughputLimiter from './ThroughputLimiter';\n\n/**\n * Class that performs periodic processing of batches of Sidetree operations anchored to the blockchain.\n */\nexport default class Observer {\n  /**\n   * Denotes if the periodic transaction processing should continue to occur.\n   * Used mainly for test purposes.\n   */\n  private continuePeriodicProcessing = false;\n\n  /**\n   * The list of transactions that are being downloaded or processed.\n   */\n  private transactionsUnderProcessing: TransactionUnderProcessingModel[] = [];\n\n  /**\n   * This is the transaction that is used as a timestamp to fetch newer transaction.\n   */\n  private lastKnownTransaction: TransactionModel | undefined;\n\n  private throughputLimiter: ThroughputLimiter;\n\n  public constructor(\n    private versionManager: IVersionManager,\n    private blockchain: IBlockchain,\n    private maxConcurrentDownloads: number,\n    private operationStore: IOperationStore,\n    private transactionStore: ITransactionStore,\n    private unresolvableTransactionStore: IUnresolvableTransactionStore,\n    private observingIntervalInSeconds: number\n  ) {\n    this.throughputLimiter = new ThroughputLimiter(versionManager);\n  }\n\n  public async refreshLastKnownTransaction(): Promise<void> {\n    this.lastKnownTransaction = await this.transactionStore.getLastTransaction();\n  }\n\n  /**\n   * The method that starts the periodic polling and processing of Sidetree operations.\n   */\n  public async startPeriodicProcessing(): Promise<void> {\n    // Initialize the last known transaction before starting processing.\n    await this.refreshLastKnownTransaction();\n\n    console.info(`Starting periodic transactions processing.`);\n    setImmediate(async () => {\n      this.continuePeriodicProcessing = true;\n\n      // tslint:disable-next-line:no-floating-promises - this.processTransactions() never throws.\n      this.processTransactions();\n    });\n  }\n\n  /**\n   * Stops periodic transaction processing.\n   * Mainly used for test purposes.\n   */\n  public stopPeriodicProcessing(): void {\n    console.info(`Stopped periodic transactions processing.`);\n    this.continuePeriodicProcessing = false;\n  }\n\n  /**\n   * Processes new transactions if any, then reprocess a set of unresolvable transactions if any,\n   * then schedules the next round of processing unless `stopPeriodicProcessing()` is invoked.\n   */\n  public async processTransactions(\n    awaitTransactionProcessing = false\n  ): Promise<void> {\n    try {\n      await this.storeConsecutiveTransactionsProcessed(); // Do this in multiple places\n\n      // Keep fetching new Sidetree transactions from blockchain and processing them\n      // until there are no more new transactions or there is a block reorganization.\n      let moreTransactions = false;\n      do {\n        // Get the last transaction to be used as a timestamp to fetch new transactions.\n        const lastKnownTransactionNumber = this.lastKnownTransaction\n          ? this.lastKnownTransaction.transactionNumber\n          : undefined;\n        const lastKnownTransactionTimeHash = this.lastKnownTransaction\n          ? this.lastKnownTransaction.transactionTimeHash\n          : undefined;\n        const lastKnownTransactionTime = this.lastKnownTransaction\n          ? this.lastKnownTransaction.transactionTime\n          : 0;\n\n        let invalidTransactionNumberOrTimeHash = false;\n        let readResult;\n        const endTimer = timeSpan(); // Measure time taken to go blockchain read.\n        try {\n          console.info(\n            'Fetching Sidetree transactions from blockchain service...'\n          );\n          const nextTransactionNumber =\n            lastKnownTransactionNumber !== undefined\n              ? lastKnownTransactionNumber + 1\n              : undefined;\n          readResult = await this.blockchain.read(\n            nextTransactionNumber,\n            lastKnownTransactionTimeHash\n          );\n          console.info(\n            `Fetched ${\n              readResult.transactions.length\n            } Sidetree transactions from blockchain service in ${endTimer.rounded()} ms.`\n          );\n        } catch (error) {\n          if (\n            error instanceof SidetreeError &&\n            error.code === SharedErrorCode.InvalidTransactionNumberOrTimeHash\n          ) {\n            console.info(\n              `Invalid transaction number ${lastKnownTransactionNumber} or time hash ${lastKnownTransactionTimeHash} given to blockchain service.`\n            );\n            invalidTransactionNumberOrTimeHash = true;\n          } else {\n            throw error;\n          }\n        }\n\n        const transactions = readResult ? readResult.transactions : [];\n        moreTransactions = readResult ? readResult.moreTransactions : false;\n        let qualifiedTransactions = await this.throughputLimiter.getQualifiedTransactions(\n          transactions\n        );\n        qualifiedTransactions = qualifiedTransactions.sort(\n          (\n            a: { transactionNumber: number },\n            b: { transactionNumber: number }\n          ) => {\n            return a.transactionNumber - b.transactionNumber;\n          }\n        );\n\n        // Queue parallel downloading and processing of chunk files.\n        for (const transaction of qualifiedTransactions) {\n          const awaitingTransaction = {\n            transaction: transaction,\n            processingStatus: TransactionProcessingStatus.Pending,\n          };\n          this.transactionsUnderProcessing.push(awaitingTransaction);\n          if (awaitTransactionProcessing) {\n            await this.processTransaction(transaction, awaitingTransaction);\n          } else {\n            // Intentionally not awaiting on downloading and processing each operation batch.\n            void this.processTransaction(transaction, awaitingTransaction);\n          }\n        }\n\n        // NOTE: Blockchain reorg has happened for sure only if `invalidTransactionNumberOrTimeHash` AND\n        // latest transaction time is less or equal to blockchain service time.\n        // This check will prevent Core from reverting transactions if/when blockchain service is reinitializing its data itself.\n        let blockReorganizationDetected = false;\n        if (invalidTransactionNumberOrTimeHash) {\n          if (\n            lastKnownTransactionTime <= this.blockchain.approximateTime.time\n          ) {\n            blockReorganizationDetected = true;\n            moreTransactions = true;\n          } else {\n            console.info(\n              `Blockchain microservice blockchain time is behind last known transaction time, waiting for blockchain microservice to catch up...`\n            );\n          }\n        }\n\n        // If block reorg is detected, we must wait until no more operation processing is pending,\n        // then revert invalid transaction and operations.\n        if (blockReorganizationDetected) {\n          console.info(`Block reorganization detected.`);\n          await this.waitUntilCountOfTransactionsUnderProcessingIsLessOrEqualTo(\n            0\n          );\n\n          console.info(`Reverting invalid transactions...`);\n          await this.revertInvalidTransactions();\n          console.info(`Completed reverting invalid transactions.`);\n        } else {\n          // Else it means transaction fetch was successful:\n          // We hold off from fetching more transactions if the list of transactions under processing gets too long.\n          // We will wait for count of transaction being processed to fall to the maximum allowed concurrent downloads\n          // before attempting further transaction fetches.\n          await this.waitUntilCountOfTransactionsUnderProcessingIsLessOrEqualTo(\n            this.maxConcurrentDownloads\n          );\n        }\n\n        // Update the last known transaction.\n        // NOTE: In case of block reorg, last known transaction will be updated in `this.RevertInvalidTransactions()` method.\n        if (transactions && transactions.length > 0) {\n          this.lastKnownTransaction = transactions[transactions.length - 1];\n        }\n      } while (moreTransactions);\n\n      await this.storeConsecutiveTransactionsProcessed();\n      console.info(\n        'Successfully kicked off downloading/processing of all new Sidetree transactions.'\n      );\n\n      // Continue onto processing unresolvable transactions if any.\n      await this.processUnresolvableTransactions(awaitTransactionProcessing);\n    } catch (error) {\n      console.error(\n        `Encountered unhandled and possibly fatal Observer error, must investigate and fix:`\n      );\n      console.error(error);\n    } finally {\n      if (this.continuePeriodicProcessing) {\n        console.info(\n          `Waiting for ${this.observingIntervalInSeconds} seconds before fetching and processing transactions again.`\n        );\n        setTimeout(\n          async () => this.processTransactions(),\n          this.observingIntervalInSeconds * 1000\n        );\n      }\n    }\n  }\n\n  private async waitUntilCountOfTransactionsUnderProcessingIsLessOrEqualTo(\n    count: number\n  ): Promise<void> {\n    while (this.transactionsUnderProcessing.length > count) {\n      // Store the consecutively processed transactions in the transaction store.\n      await this.storeConsecutiveTransactionsProcessed();\n\n      // Wait a little before checking again.\n      await new Promise((resolve) => setTimeout(resolve, 1000));\n    }\n\n    return;\n  }\n\n  /**\n   * Attempts to fetch and process unresolvable transactions due for retry.\n   * Waits until all unresolvable transactions due for retry are processed.\n   */\n  private async processUnresolvableTransactions(\n    awaitTransactionProcessing = false\n  ): Promise<void> {\n    const endTimer = timeSpan();\n    const unresolvableTransactions = await this.unresolvableTransactionStore.getUnresolvableTransactionsDueForRetry();\n    console.info(\n      `Fetched ${\n        unresolvableTransactions.length\n      } unresolvable transactions to retry in ${endTimer.rounded()} ms.`\n    );\n\n    // Download and process each unresolvable transactions.\n    const unresolvableTransactionStatus = [];\n    for (const transaction of unresolvableTransactions) {\n      const awaitingTransaction = {\n        transaction: transaction,\n        processingStatus: TransactionProcessingStatus.Pending,\n      };\n      unresolvableTransactionStatus.push(awaitingTransaction);\n      // Intentionally not awaiting on downloading and processing each operation batch.\n      if (awaitTransactionProcessing) {\n        await this.processTransaction(transaction, awaitingTransaction);\n      } else {\n        // Intentionally not awaiting on downloading and processing each operation batch.\n        void this.processTransaction(transaction, awaitingTransaction);\n      }\n    }\n\n    // Wait until all unresolvable transactions are processed,\n    while (unresolvableTransactionStatus.length > 0) {\n      // Find the index of the first transaction that is not processed yet.\n      let i = 0;\n      while (\n        i < unresolvableTransactionStatus.length &&\n        unresolvableTransactionStatus[i].processingStatus ===\n          TransactionProcessingStatus.Processed\n      ) {\n        i++;\n      }\n\n      // Trim the parallelized transaction list.\n      unresolvableTransactionStatus.splice(0, i);\n\n      // Wait a little before checking again.\n      await new Promise((resolve) => setTimeout(resolve, 1000));\n    }\n  }\n\n  /**\n   * Goes through the `transactionsUnderProcessing` in chronological order, records each processed transaction\n   * in the transaction store and remove it from `transactionsUnderProcessing` until a transaction that has not been processed yet is hit.\n   */\n  private async storeConsecutiveTransactionsProcessed(): Promise<void> {\n    let i = 0;\n    while (\n      i < this.transactionsUnderProcessing.length &&\n      this.transactionsUnderProcessing[i].processingStatus ===\n        TransactionProcessingStatus.Processed\n    ) {\n      await this.transactionStore.addTransaction(\n        this.transactionsUnderProcessing[i].transaction\n      );\n      i++;\n    }\n\n    // Trim the transaction list.\n    this.transactionsUnderProcessing.splice(0, i);\n  }\n\n  /**\n   * Processes the given transaction by passing the transaction to the right version of the transaction processor based on the transaction time.\n   * The transaction processing generically involves first downloading DID operation data from CAS (Content Addressable Storage),\n   * then storing the operations indexed/grouped by DIDs in the persistent operation DB.\n   */\n  private async processTransaction(\n    transaction: TransactionModel,\n    transactionUnderProcessing: TransactionUnderProcessingModel\n  ): Promise<void> {\n    let transactionProcessedSuccessfully;\n\n    try {\n      const transactionProcessor: ITransactionProcessor = this.versionManager.getTransactionProcessor(\n        transaction.transactionTime\n      );\n      transactionProcessedSuccessfully = await transactionProcessor.processTransaction(\n        transaction\n      );\n    } catch (error) {\n      console.error(\n        `Unhandled error encountered processing transaction '${transaction.transactionNumber}'.`\n      );\n      console.error(error);\n      transactionProcessedSuccessfully = false;\n    } finally {\n      // Purposely setting processing status first before rest of the code to prevent any possibility of deadlocking the Observer.\n      console.info(\n        `Finished processing transaction '${transaction.transactionNumber}'.`\n      );\n      transactionUnderProcessing.processingStatus =\n        TransactionProcessingStatus.Processed;\n\n      if (transactionProcessedSuccessfully) {\n        console.info(\n          `Removing transaction '${transaction.transactionNumber}' from unresolvable transactions if exists...`\n        );\n        await this.unresolvableTransactionStore.removeUnresolvableTransaction(\n          transaction\n        );\n      } else {\n        console.info(\n          `Recording failed processing attempt for transaction '${transaction.transactionNumber}'...`\n        );\n        await this.unresolvableTransactionStore.recordUnresolvableTransactionFetchAttempt(\n          transaction\n        );\n      }\n    }\n  }\n\n  /**\n   * Reverts invalid transactions. Used in the event of a block-reorganization.\n   */\n  private async revertInvalidTransactions(): Promise<void> {\n    // Compute a list of exponentially-spaced transactions with their index, starting from the last transaction of the processed transactions.\n    const exponentiallySpacedTransactions = await this.transactionStore.getExponentiallySpacedTransactions();\n\n    // Find a known valid Sidetree transaction that is prior to the block reorganization.\n    const bestKnownValidRecentTransaction = await this.blockchain.getFirstValidTransaction(\n      exponentiallySpacedTransactions\n    );\n\n    const bestKnownValidRecentTransactionNumber =\n      bestKnownValidRecentTransaction === undefined\n        ? undefined\n        : bestKnownValidRecentTransaction.transactionNumber;\n    console.info(\n      `Best known valid recent transaction: ${bestKnownValidRecentTransactionNumber}`\n    );\n\n    // Revert all processed operations that came after the best known valid recent transaction.\n    console.info('Reverting operations...');\n    await this.operationStore.delete(bestKnownValidRecentTransactionNumber);\n\n    // NOTE: MUST do this step LAST to handle incomplete operation rollback due to unexpected scenarios, such as power outage etc.\n    await this.transactionStore.removeTransactionsLaterThan(\n      bestKnownValidRecentTransactionNumber\n    );\n    await this.unresolvableTransactionStore.removeUnresolvableTransactionsLaterThan(\n      bestKnownValidRecentTransactionNumber\n    );\n\n    // Reset the in-memory last known good Transaction so we next processing cycle will fetch from the correct timestamp/maker.\n    this.lastKnownTransaction = bestKnownValidRecentTransaction;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ErrorCode,\n  OperationModel,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\nimport CreateOperation from './CreateOperation';\nimport DeactivateOperation from './DeactivateOperation';\nimport RecoverOperation from './RecoverOperation';\nimport UpdateOperation from './UpdateOperation';\n\n/**\n * A class that contains Sidetree operation utility methods.\n */\nexport default class Operation {\n  /** Maximum allowed encoded reveal value string length. */\n  public static readonly maxEncodedRevealValueLength = 50;\n\n  /**\n   * Parses the given buffer into an `OperationModel`.\n   */\n  public static async parse(operationBuffer: Buffer): Promise<OperationModel> {\n    // Parse request buffer into a JS object.\n    const operationJsonString = operationBuffer.toString();\n    const operationObject = JSON.parse(operationJsonString);\n    const operationType = operationObject.type;\n    const isAnchorFileMode = false;\n\n    if (operationType === OperationType.Create) {\n      return CreateOperation.parseObject(\n        operationObject,\n        operationBuffer,\n        isAnchorFileMode\n      );\n    } else if (operationType === OperationType.Update) {\n      return UpdateOperation.parseObject(\n        operationObject,\n        operationBuffer,\n        isAnchorFileMode\n      );\n    } else if (operationType === OperationType.Recover) {\n      return RecoverOperation.parseObject(\n        operationObject,\n        operationBuffer,\n        isAnchorFileMode\n      );\n    } else if (operationType === OperationType.Deactivate) {\n      return DeactivateOperation.parseObject(\n        operationObject,\n        operationBuffer,\n        isAnchorFileMode\n      );\n    } else {\n      throw new SidetreeError(ErrorCode.OperationTypeUnknownOrMissing);\n    }\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AnchoredOperationModel,\n  Encoder,\n  PublicKeyJwk,\n  Multihash,\n  OperationModel,\n  OperationType,\n  PrivateKeyJwk,\n  PublicKeyModel,\n  ServiceEndpointModel,\n  PublicKeyPurpose,\n  DocumentModel,\n  PrivateKeyJwkEd25519,\n} from '@sidetree/common';\nimport * as crypto from 'crypto';\nimport CreateOperation from '../../CreateOperation';\nimport DeactivateOperation from '../../DeactivateOperation';\nimport RecoverOperation from '../../RecoverOperation';\nimport UpdateOperation from '../../UpdateOperation';\nimport Jwk from '../../util/Jwk';\nimport Jws from '../../util/Jws';\n\ninterface AnchoredCreateOperationGenerationInput {\n  transactionNumber: number;\n  transactionTime: number;\n  operationIndex: number;\n}\n\ninterface RecoverOperationGenerationInput {\n  didUniqueSuffix: string;\n  recoveryPrivateKey: PrivateKeyJwk;\n}\n\ninterface GeneratedRecoverOperationData {\n  operationBuffer: Buffer;\n  recoverOperation: RecoverOperation;\n  recoveryPublicKey: PublicKeyJwk;\n  recoveryPrivateKey: PrivateKeyJwk;\n  signingPublicKey: PublicKeyModel;\n  signingPrivateKey: PrivateKeyJwk;\n  update_key: PublicKeyModel;\n  updatePrivateKey: PrivateKeyJwk;\n}\n\n/**\n * A class that can generate valid operations.\n * Mainly useful for testing purposes.\n */\nexport default class OperationGenerator {\n  /**\n   * Generates random hash.\n   */\n  public static generateRandomHash(): string {\n    const randomBuffer = crypto.randomBytes(32);\n    const randomHash = Encoder.encode(Multihash.hash(randomBuffer));\n\n    return randomHash;\n  }\n\n  /**\n   * Generates Ed25519 key pair to be used in an operation. If purpose not supplied, all purposes will be included\n   * Mainly used for testing.\n   * @returns [publicKey, privateKey]\n   */\n  public static async generateKeyPair(\n    id: string,\n    purpose?: PublicKeyPurpose[]\n  ): Promise<[PublicKeyModel, PrivateKeyJwk]> {\n    const [publicKey, privateKey] = await Jwk.generateEd25519KeyPair();\n    const publicKeyModel = {\n      id,\n      type: 'Ed25519VerificationKey2018',\n      jwk: publicKey,\n      purpose: purpose || Object.values(PublicKeyPurpose),\n    };\n\n    return [publicKeyModel, privateKey];\n  }\n\n  /**\n   * Generates an anchored create operation.\n   */\n  public static async generateAnchoredCreateOperation(\n    input: AnchoredCreateOperationGenerationInput\n  ) {\n    const createOperationData = await OperationGenerator.generateCreateOperation();\n\n    const anchoredOperationModel = {\n      type: OperationType.Create,\n      didUniqueSuffix: createOperationData.createOperation.didUniqueSuffix,\n      operationBuffer: createOperationData.createOperation.operationBuffer,\n      transactionNumber: input.transactionNumber,\n      transactionTime: input.transactionTime,\n      operationIndex: input.operationIndex,\n    };\n\n    return {\n      createOperation: createOperationData.createOperation,\n      operationRequest: createOperationData.operationRequest,\n      anchoredOperationModel,\n      recoveryPublicKey: createOperationData.recoveryPublicKey,\n      recoveryPrivateKey: createOperationData.recoveryPrivateKey,\n      updatePublicKey: createOperationData.updatePublicKey,\n      updatePrivateKey: createOperationData.updatePrivateKey,\n      signingPublicKey: createOperationData.signingPublicKey,\n      signingPrivateKey: createOperationData.signingPrivateKey,\n      nextUpdateRevealValueEncodedString:\n        createOperationData.nextUpdateRevealValueEncodedString,\n    };\n  }\n\n  /**\n   * Generates an create operation.\n   */\n  public static async generateCreateOperation() {\n    const signingKeyId = 'signingKey';\n    const [\n      recoveryPublicKey,\n      recoveryPrivateKey,\n    ] = await Jwk.generateEd25519KeyPair();\n    const [\n      updatePublicKey,\n      updatePrivateKey,\n    ] = await Jwk.generateEd25519KeyPair();\n    const [\n      signingPublicKey,\n      signingPrivateKey,\n    ] = await OperationGenerator.generateKeyPair(signingKeyId);\n    const service = OperationGenerator.generateServiceEndpoints([\n      'serviceEndpointId123',\n    ]);\n\n    const operationRequest = await OperationGenerator.generateCreateOperationRequest(\n      recoveryPublicKey,\n      updatePublicKey,\n      [signingPublicKey],\n      service\n    );\n\n    const operationBuffer = Buffer.from(JSON.stringify(operationRequest));\n\n    const createOperation = await CreateOperation.parse(operationBuffer);\n\n    const nextUpdateRevealValueEncodedString = Multihash.canonicalizeThenHashThenEncode(\n      signingPublicKey.jwk\n    );\n    return {\n      createOperation,\n      operationRequest,\n      recoveryPublicKey,\n      recoveryPrivateKey,\n      updatePublicKey,\n      updatePrivateKey,\n      signingPublicKey,\n      signingPrivateKey,\n      nextUpdateRevealValueEncodedString,\n    };\n  }\n\n  /**\n   * Generates a recover operation.\n   */\n  public static async generateRecoverOperation(\n    input: RecoverOperationGenerationInput\n  ): Promise<GeneratedRecoverOperationData> {\n    const newSigningKeyId = 'newSigningKey';\n    const [\n      newRecoveryPublicKey,\n      newRecoveryPrivateKey,\n    ] = await Jwk.generateEd25519KeyPair();\n    const [\n      newSigningPublicKey,\n      newSigningPrivateKey,\n    ] = await OperationGenerator.generateKeyPair(newSigningKeyId);\n    const [publicKeyToBeInDocument] = await OperationGenerator.generateKeyPair(\n      'newKey'\n    );\n    const services = OperationGenerator.generateServiceEndpoints([\n      'serviceEndpointId123',\n    ]);\n\n    // Generate the next update and recover operation commitment hash reveal value pair.\n    const [\n      update_key,\n      updatePrivateKey,\n    ] = await OperationGenerator.generateKeyPair('update_key');\n\n    const operationJson = await OperationGenerator.generateRecoverOperationRequest(\n      input.didUniqueSuffix,\n      input.recoveryPrivateKey,\n      newRecoveryPublicKey,\n      newSigningPublicKey,\n      services,\n      [publicKeyToBeInDocument]\n    );\n\n    const operationBuffer = Buffer.from(JSON.stringify(operationJson));\n    const recoverOperation = await RecoverOperation.parse(operationBuffer);\n\n    return {\n      recoverOperation,\n      operationBuffer,\n      recoveryPublicKey: newRecoveryPublicKey,\n      recoveryPrivateKey: newRecoveryPrivateKey,\n      signingPublicKey: newSigningPublicKey,\n      signingPrivateKey: newSigningPrivateKey,\n      update_key,\n      updatePrivateKey,\n    };\n  }\n\n  /**\n   * Generates an update operation that adds a new key.\n   */\n  public static async generateUpdateOperation(\n    didUniqueSuffix: string,\n    updatePublicKey: PublicKeyJwk,\n    updatePrivateKey: PrivateKeyJwk\n  ) {\n    const additionalKeyId = `additional-key`;\n    const [\n      additionalPublicKey,\n      additionalPrivateKey,\n    ] = await OperationGenerator.generateKeyPair(additionalKeyId);\n\n    const operationJson = await OperationGenerator.createUpdateOperationRequestForAddingAKey(\n      didUniqueSuffix,\n      updatePublicKey,\n      updatePrivateKey,\n      additionalPublicKey,\n      Multihash.canonicalizeThenHashThenEncode(additionalPublicKey)\n    );\n\n    const operationBuffer = Buffer.from(JSON.stringify(operationJson));\n    const updateOperation = await UpdateOperation.parse(operationBuffer);\n\n    return {\n      updateOperation,\n      operationBuffer,\n      additionalKeyId,\n      additionalPublicKey,\n      additionalPrivateKey,\n      nextUpdateKey: additionalPublicKey.jwk,\n    };\n  }\n\n  /**\n   * Creates a named anchored operation model from `OperationModel`.\n   */\n  public static createAnchoredOperationModelFromOperationModel(\n    operationModel: OperationModel,\n    transactionTime: number,\n    transactionNumber: number,\n    operationIndex: number\n  ): AnchoredOperationModel {\n    const anchoredOperationModel: AnchoredOperationModel = {\n      didUniqueSuffix: operationModel.didUniqueSuffix,\n      type: operationModel.type,\n      operationBuffer: operationModel.operationBuffer,\n      operationIndex,\n      transactionNumber,\n      transactionTime,\n    };\n    return anchoredOperationModel;\n  }\n\n  /**\n   * Generates a create operation request.\n   */\n  public static async generateCreateOperationRequest(\n    recoveryPublicKey: PublicKeyJwk,\n    updatePublicKey: PublicKeyJwk,\n    otherPublicKeys: PublicKeyModel[],\n    service_endpoints?: ServiceEndpointModel[]\n  ) {\n    const document: DocumentModel = {\n      public_keys: otherPublicKeys,\n      service_endpoints,\n    };\n\n    const patches = [\n      {\n        action: 'replace',\n        document,\n      },\n    ];\n\n    const delta = {\n      update_commitment: Multihash.canonicalizeThenHashThenEncode(\n        updatePublicKey\n      ),\n      patches,\n    };\n\n    const deltaBuffer = Buffer.from(JSON.stringify(delta));\n    const delta_hash = Encoder.encode(Multihash.hash(deltaBuffer));\n\n    const suffixData = {\n      delta_hash: delta_hash,\n      recovery_commitment: Multihash.canonicalizeThenHashThenEncode(\n        recoveryPublicKey\n      ),\n    };\n\n    const suffixDataEncodedString = Encoder.encode(JSON.stringify(suffixData));\n    const deltaEncodedString = Encoder.encode(deltaBuffer);\n    const operation = {\n      type: OperationType.Create,\n      suffix_data: suffixDataEncodedString,\n      delta: deltaEncodedString,\n    };\n\n    return operation;\n  }\n\n  /**\n   * Generates an update operation request.\n   */\n  public static async generateUpdateOperationRequest(didUniqueSuffix?: string) {\n    if (didUniqueSuffix === undefined) {\n      didUniqueSuffix = OperationGenerator.generateRandomHash();\n    }\n    const [nextUpdateKey] = await OperationGenerator.generateKeyPair(\n      'nextUpdateKey'\n    );\n    const nextUpdateCommitmentHash = Multihash.canonicalizeThenHashThenEncode(\n      nextUpdateKey.jwk\n    );\n    const anyNewSigningPublicKeyId = 'anyNewKey';\n    const [anyNewSigningKey] = await OperationGenerator.generateKeyPair(\n      anyNewSigningPublicKeyId\n    );\n    const patches = [\n      {\n        action: 'add-public-keys',\n        public_keys: [anyNewSigningKey],\n      },\n    ];\n    const signingKeyId = 'anySigningKeyId';\n    const [\n      signingPublicKey,\n      signingPrivateKey,\n    ] = await OperationGenerator.generateKeyPair(signingKeyId);\n    const request = await OperationGenerator.createUpdateOperationRequest(\n      didUniqueSuffix,\n      signingPublicKey.jwk,\n      signingPrivateKey,\n      nextUpdateCommitmentHash,\n      patches\n    );\n\n    const buffer = Buffer.from(JSON.stringify(request));\n    const updateOperation = await UpdateOperation.parse(buffer);\n\n    return {\n      request,\n      buffer,\n      updateOperation,\n    };\n  }\n\n  /**\n   * Creates an update operation request.\n   */\n  public static async createUpdateOperationRequest(\n    didUniqueSuffix: string,\n    updatePublicKey: PublicKeyJwk,\n    updatePrivateKey: PrivateKeyJwk,\n    nextUpdateCommitmentHash: string,\n    patches: any\n  ) {\n    const delta = {\n      patches,\n      update_commitment: nextUpdateCommitmentHash,\n    };\n    const deltaJsonString = JSON.stringify(delta);\n    const delta_hash = Encoder.encode(\n      Multihash.hash(Buffer.from(deltaJsonString))\n    );\n    const encodedDeltaString = Encoder.encode(deltaJsonString);\n\n    const signedDataPayloadObject = {\n      update_key: updatePublicKey,\n      delta_hash: delta_hash,\n    };\n    const signedData = await OperationGenerator.signUsingEd25519(\n      signedDataPayloadObject,\n      updatePrivateKey\n    );\n\n    const updateOperationRequest = {\n      type: OperationType.Update,\n      did_suffix: didUniqueSuffix,\n      delta: encodedDeltaString,\n      signed_data: signedData,\n    };\n\n    return updateOperationRequest;\n  }\n\n  /**\n   * Generates a recover operation request.\n   */\n  public static async generateRecoverOperationRequest(\n    didUniqueSuffix: string,\n    recoveryPrivateKey: PrivateKeyJwk,\n    newRecoveryPublicKey: PublicKeyJwk,\n    newSigningPublicKey: PublicKeyModel,\n    service_endpoints?: ServiceEndpointModel[],\n    public_keys?: PublicKeyModel[]\n  ) {\n    const document = {\n      public_keys: public_keys,\n      service_endpoints: service_endpoints,\n    };\n    const recoverOperation = await OperationGenerator.createRecoverOperationRequest(\n      didUniqueSuffix,\n      recoveryPrivateKey,\n      newRecoveryPublicKey,\n      Multihash.canonicalizeThenHashThenEncode(newSigningPublicKey.jwk),\n      document\n    );\n    return recoverOperation;\n  }\n\n  /**\n   * Creates a recover operation request.\n   */\n  public static async createRecoverOperationRequest(\n    didUniqueSuffix: string,\n    recoveryPrivateKey: PrivateKeyJwk,\n    newRecoveryPublicKey: PublicKeyJwk,\n    nextUpdateCommitmentHash: string,\n    document: any\n  ) {\n    const patches = [\n      {\n        action: 'replace',\n        document,\n      },\n    ];\n\n    const delta = {\n      patches,\n      update_commitment: nextUpdateCommitmentHash,\n    };\n\n    const deltaBuffer = Buffer.from(JSON.stringify(delta));\n    const delta_hash = Encoder.encode(Multihash.hash(deltaBuffer));\n\n    const signedDataPayloadObject = {\n      delta_hash: delta_hash,\n      recovery_key: Jwk.getCurve25519PublicKey(\n        recoveryPrivateKey as PrivateKeyJwkEd25519\n      ),\n      recovery_commitment: Multihash.canonicalizeThenHashThenEncode(\n        newRecoveryPublicKey\n      ),\n    };\n    const signedData = await OperationGenerator.signUsingEd25519(\n      signedDataPayloadObject,\n      recoveryPrivateKey\n    );\n\n    const deltaEncodedString = Encoder.encode(deltaBuffer);\n    const operation = {\n      type: OperationType.Recover,\n      did_suffix: didUniqueSuffix,\n      signed_data: signedData,\n      delta: deltaEncodedString,\n    };\n\n    return operation;\n  }\n\n  /**\n   * Generates a deactivate operation request.\n   */\n  public static async createDeactivateOperationRequest(\n    didUniqueSuffix: string,\n    recoveryPrivateKey: PrivateKeyJwk\n  ) {\n    const signedDataPayloadObject = {\n      did_suffix: didUniqueSuffix,\n      recovery_key: Jwk.getCurve25519PublicKey(\n        recoveryPrivateKey as PrivateKeyJwkEd25519\n      ),\n    };\n    const signedData = await OperationGenerator.signUsingEd25519(\n      signedDataPayloadObject,\n      recoveryPrivateKey\n    );\n\n    const operation = {\n      type: OperationType.Deactivate,\n      did_suffix: didUniqueSuffix,\n      signed_data: signedData,\n    };\n\n    return operation;\n  }\n\n  /**\n   * Generates a create operation request buffer.\n   * @param nextRecoveryCommitmentHash The encoded commitment hash for the next recovery.\n   * @param nextUpdateCommitmentHash The encoded commitment hash for the next update.\n   */\n  public static async generateCreateOperationBuffer(\n    recoveryPublicKey: PublicKeyJwk,\n    signingPublicKey: PublicKeyModel,\n    service_endpoints?: ServiceEndpointModel[]\n  ): Promise<Buffer> {\n    const operation = await OperationGenerator.generateCreateOperationRequest(\n      recoveryPublicKey,\n      signingPublicKey.jwk,\n      [signingPublicKey],\n      service_endpoints\n    );\n\n    return Buffer.from(JSON.stringify(operation));\n  }\n\n  /**\n   * Creates an update operation for adding a key.\n   */\n  public static async createUpdateOperationRequestForAddingAKey(\n    didUniqueSuffix: string,\n    updatePublicKey: PublicKeyJwk,\n    updatePrivateKey: PrivateKeyJwk,\n    newPublicKey: PublicKeyModel,\n    nextUpdateCommitmentHash: string\n  ) {\n    const patches = [\n      {\n        action: 'add-public-keys',\n        public_keys: [newPublicKey],\n      },\n    ];\n\n    const updateOperationRequest = await OperationGenerator.createUpdateOperationRequest(\n      didUniqueSuffix,\n      updatePublicKey,\n      updatePrivateKey,\n      nextUpdateCommitmentHash,\n      patches\n    );\n\n    return updateOperationRequest;\n  }\n\n  /**\n   * Creates an update operation for adding and/or removing hub service endpoints.\n   */\n  public static async createUpdateOperationRequestForHubEndpoints(\n    didUniqueSuffix: string,\n    updatePublicKey: any,\n    updatePrivateKey: PrivateKeyJwk,\n    nextUpdateCommitmentHash: string,\n    idOfServiceEndpointToAdd: string | undefined,\n    idsOfServiceEndpointToRemove: string[]\n  ) {\n    const patches = [];\n\n    if (idOfServiceEndpointToAdd !== undefined) {\n      const patch = {\n        action: 'add-service-endpoints',\n        service_endpoints: OperationGenerator.generateServiceEndpoints([\n          idOfServiceEndpointToAdd,\n        ]),\n      };\n\n      patches.push(patch);\n    }\n\n    if (idsOfServiceEndpointToRemove.length > 0) {\n      const patch = {\n        action: 'remove-service-endpoints',\n        ids: idsOfServiceEndpointToRemove,\n      };\n\n      patches.push(patch);\n    }\n\n    const updateOperationRequest = await OperationGenerator.createUpdateOperationRequest(\n      didUniqueSuffix,\n      updatePublicKey,\n      updatePrivateKey,\n      nextUpdateCommitmentHash,\n      patches\n    );\n\n    return updateOperationRequest;\n  }\n\n  /**\n   * Signs the given payload as a ed25519 compact JWS.\n   */\n  public static async signUsingEd25519(\n    payload: any,\n    privateKey: PrivateKeyJwk\n  ): Promise<string> {\n    const protectedHeader = {\n      alg: 'EdDSA',\n    };\n\n    const compactJws = await Jws.signAsCompactJws(\n      payload,\n      privateKey,\n      protectedHeader\n    );\n    return compactJws;\n  }\n\n  /**\n   * Generates a Deactivate Operation data.\n   */\n  public static async createDeactivateOperation(\n    didUniqueSuffix: string,\n    recoveryPrivateKey: PrivateKeyJwk\n  ) {\n    const operationRequest = await OperationGenerator.createDeactivateOperationRequest(\n      didUniqueSuffix,\n      recoveryPrivateKey\n    );\n    const operationBuffer = Buffer.from(JSON.stringify(operationRequest));\n    const deactivateOperation = await DeactivateOperation.parse(\n      operationBuffer\n    );\n\n    return {\n      operationRequest,\n      operationBuffer,\n      deactivateOperation,\n    };\n  }\n\n  /**\n   * Generates an array of service endpoints with specified ids\n   * @param ids the id field in endpoint.\n   */\n  public static generateServiceEndpoints(ids: string[]): any[] {\n    const service_endpoints = [];\n    for (const id of ids) {\n      service_endpoints.push({\n        id: id,\n        type: 'someType',\n        endpoint: 'https://www.url.com',\n      });\n    }\n    return service_endpoints;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AnchoredOperationModel,\n  DidState,\n  IOperationStore,\n  IVersionManager,\n  Multihash,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\n\n/**\n * NOTE: Resolver cannot be versioned because it needs to be aware of `VersionManager` to fetch versioned operation processors.\n */\nexport default class Resolver {\n  public constructor(\n    private versionManager: IVersionManager,\n    private operationStore: IOperationStore\n  ) {}\n\n  /**\n   * Resolve the given DID unique suffix to its latest DID state.\n   * @param didUniqueSuffix The unique suffix of the DID to resolve. e.g. if 'did:sidetree:abc123' is the DID, the unique suffix would be 'abc123'\n   * @returns Final DID state of the DID. Undefined if the unique suffix of the DID is not found or the DID state is not constructable.\n   */\n  public async resolve(didUniqueSuffix: string): Promise<DidState | undefined> {\n    console.info(`Resolving DID unique suffix '${didUniqueSuffix}'...`);\n\n    const operations = await this.operationStore.get(didUniqueSuffix);\n    const operationsByType = Resolver.categorizeOperationsByType(operations);\n\n    // Find and apply a valid create operation.\n    let didState = await this.applyCreateOperation(\n      operationsByType.createOperations\n    );\n\n    // If can't construct an initial DID state.\n    if (didState === undefined) {\n      return undefined;\n    }\n\n    // Apply recovery/deactivate operations until an operation matching the next recovery commitment cannot be found.\n    const recoverAndDeactivateOperations = operationsByType.recoverOperations.concat(\n      operationsByType.deactivateOperations\n    );\n    const recoveryCommitValueToOperationMap = await this.constructCommitValueToOperationLookupMap(\n      recoverAndDeactivateOperations\n    );\n    didState = await this.applyRecoverAndDeactivateOperations(\n      didState,\n      recoveryCommitValueToOperationMap\n    );\n\n    // If the previous applied operation is a deactivate. No need to continue further.\n    if (didState.nextRecoveryCommitmentHash === undefined) {\n      return didState;\n    }\n\n    // Apply update operations until an operation matching the next update commitment cannot be found.\n    const updateCommitValueToOperationMap = await this.constructCommitValueToOperationLookupMap(\n      operationsByType.updateOperations\n    );\n    didState = await this.applyUpdateOperations(\n      didState,\n      updateCommitValueToOperationMap\n    );\n\n    return didState;\n  }\n\n  private static categorizeOperationsByType(\n    operations: AnchoredOperationModel[]\n  ): {\n    createOperations: AnchoredOperationModel[];\n    recoverOperations: AnchoredOperationModel[];\n    updateOperations: AnchoredOperationModel[];\n    deactivateOperations: AnchoredOperationModel[];\n  } {\n    const createOperations = [];\n    const recoverOperations = [];\n    const updateOperations = [];\n    const deactivateOperations = [];\n\n    for (const operation of operations) {\n      if (operation.type === OperationType.Create) {\n        createOperations.push(operation);\n      } else if (operation.type === OperationType.Recover) {\n        recoverOperations.push(operation);\n      } else if (operation.type === OperationType.Update) {\n        updateOperations.push(operation);\n      } else {\n        // This is a deactivate operation.\n        deactivateOperations.push(operation);\n      }\n    }\n    return {\n      createOperations,\n      recoverOperations,\n      updateOperations,\n      deactivateOperations,\n    };\n  }\n\n  /**\n   * Iterate through all duplicates of creates until we can construct an initial DID state (some creates maybe incomplete. eg. without `delta`).\n   */\n  private async applyCreateOperation(\n    createOperations: AnchoredOperationModel[]\n  ): Promise<DidState | undefined> {\n    let didState;\n\n    for (const createOperation of createOperations) {\n      didState = await this.applyOperation(createOperation, undefined);\n\n      // Exit loop as soon as we can construct an initial state.\n      if (didState !== undefined) {\n        break;\n      }\n    }\n\n    return didState;\n  }\n\n  /**\n   * Apply recovery/deactivate operations until an operation matching the next recovery commitment cannot be found.\n   */\n  private async applyRecoverAndDeactivateOperations(\n    startingDidState: DidState,\n    commitValueToOperationMap: Map<string, AnchoredOperationModel[]>\n  ): Promise<DidState> {\n    let didState = startingDidState;\n\n    while (\n      commitValueToOperationMap.has(didState.nextRecoveryCommitmentHash!)\n    ) {\n      let operationsWithCorrectRevealValue: AnchoredOperationModel[] = commitValueToOperationMap.get(\n        didState.nextRecoveryCommitmentHash!\n      )!;\n\n      // Sort using blockchain time.\n      operationsWithCorrectRevealValue = operationsWithCorrectRevealValue.sort(\n        (a, b) => a.transactionNumber - b.transactionNumber\n      );\n\n      const newDidState:\n        | DidState\n        | undefined = await this.applyFirstValidOperation(\n        operationsWithCorrectRevealValue,\n        didState\n      );\n\n      // We are done if we can't find a valid recover/deactivate operation to apply.\n      if (newDidState === undefined) {\n        break;\n      }\n\n      // We reach here if we have successfully computed a new DID state.\n      didState = newDidState;\n\n      // If the previous applied operation is a deactivate. No need to continue further.\n      if (didState.nextRecoveryCommitmentHash === undefined) {\n        return didState;\n      }\n    }\n\n    return didState;\n  }\n\n  /**\n   * Apply update operations until an operation matching the next update commitment cannot be found.\n   */\n  private async applyUpdateOperations(\n    startingDidState: DidState,\n    commitValueToOperationMap: Map<string, AnchoredOperationModel[]>\n  ): Promise<DidState> {\n    let didState = startingDidState;\n\n    while (commitValueToOperationMap.has(didState.nextUpdateCommitmentHash!)) {\n      let operationsWithCorrectRevealValue: AnchoredOperationModel[] = commitValueToOperationMap.get(\n        didState.nextUpdateCommitmentHash!\n      )!;\n\n      // Sort using blockchain time.\n      operationsWithCorrectRevealValue = operationsWithCorrectRevealValue.sort(\n        (a, b) => a.transactionNumber - b.transactionNumber\n      );\n\n      const newDidState:\n        | DidState\n        | undefined = await this.applyFirstValidOperation(\n        operationsWithCorrectRevealValue,\n        didState\n      );\n\n      // We are done if we can't find a valid update operation to apply.\n      if (newDidState === undefined) {\n        break;\n      }\n\n      // We reach here if we have successfully computed a new DID state.\n      didState = newDidState;\n    }\n\n    return didState;\n  }\n\n  /**\n   * Applies the given operation to the given DID state.\n   * @param operation The operation to be applied.\n   * @param didState The DID state to apply the operation on top of.\n   * @returns The resultant `DidState`. The given DID state is return if the given operation cannot be applied.\n   */\n  private async applyOperation(\n    operation: AnchoredOperationModel,\n    didState: DidState | undefined\n  ): Promise<DidState | undefined> {\n    let appliedDidState = didState;\n\n    // NOTE: MUST NOT throw error, else a bad operation can be used to denial resolution for a DID.\n    try {\n      const operationProcessor = this.versionManager.getOperationProcessor(\n        operation.transactionTime\n      );\n\n      appliedDidState = await operationProcessor.apply(\n        operation,\n        appliedDidState\n      );\n    } catch (error) {\n      console.log(\n        `Skipped bad operation for DID ${operation.didUniqueSuffix} at time ${\n          operation.transactionTime\n        }. Error: ${SidetreeError.stringify(error)}`\n      );\n    }\n\n    return appliedDidState;\n  }\n\n  /**\n   * @returns The new DID State if a valid operation is applied, `undefined` otherwise.\n   */\n  private async applyFirstValidOperation(\n    operations: AnchoredOperationModel[],\n    originalDidState: DidState\n  ): Promise<DidState | undefined> {\n    let newDidState = originalDidState;\n\n    // Stop as soon as an operation is applied successfully.\n    for (const operation of operations) {\n      newDidState = (await this.applyOperation(operation, newDidState))!;\n\n      // If operation matching the recovery commitment is applied.\n      if (\n        newDidState.lastOperationTransactionNumber !==\n        originalDidState.lastOperationTransactionNumber\n      ) {\n        return newDidState;\n      }\n    }\n\n    // Else we reach the end of operations without being able to apply any of them.\n    return undefined;\n  }\n\n  /**\n   * Constructs a single commit value -> operation lookup map by looping through each supported hash algorithm,\n   * hashing each operations as key, then adding the result to a map.\n   */\n  private async constructCommitValueToOperationLookupMap(\n    nonCreateOperations: AnchoredOperationModel[]\n  ): Promise<Map<string, AnchoredOperationModel[]>> {\n    const commitValueToOperationMap = new Map<\n      string,\n      AnchoredOperationModel[]\n    >();\n\n    // Loop through each supported algorithm and hash each operation.\n    const allSupportedHashAlgorithms = this.versionManager\n      .allSupportedHashAlgorithms;\n    for (const hashAlgorithm of allSupportedHashAlgorithms) {\n      for (const operation of nonCreateOperations) {\n        const operationProcessor = this.versionManager.getOperationProcessor(\n          operation.transactionTime\n        );\n        const revealValueBuffer = await operationProcessor.getRevealValue(\n          operation\n        );\n\n        const hashOfRevealValue = Multihash.hashThenEncode(\n          revealValueBuffer,\n          hashAlgorithm\n        );\n\n        if (commitValueToOperationMap.has(hashOfRevealValue)) {\n          commitValueToOperationMap.get(hashOfRevealValue)!.push(operation);\n        } else {\n          commitValueToOperationMap.set(hashOfRevealValue, [operation]);\n        }\n      }\n    }\n\n    return commitValueToOperationMap;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ServiceVersionModel } from '@sidetree/common';\n/**\n * Encapsulates the functionality to get the information about the service such as\n * version info.\n */\nexport default class ServiceInfoProvider {\n  private static readonly packageJson = require('../package.json');\n  private serviceName: string;\n\n  constructor(serviceName: string) {\n    this.serviceName = serviceName;\n  }\n\n  /**\n   * Gets the service version from the package.json file.\n   */\n  public getServiceVersion(): ServiceVersionModel {\n    return {\n      name: this.serviceName,\n      version: ServiceInfoProvider.packageJson.version,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/master/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AbstractVersionMetadata,\n  Config,\n  CoreErrorCode,\n  IBatchWriter,\n  IBlockchain,\n  ICas,\n  IOperationProcessor,\n  IOperationStore,\n  IRequestHandler,\n  ITransactionProcessor,\n  ITransactionSelector,\n  ITransactionStore,\n  IVersionManager,\n  IVersionMetadataFetcher,\n  ProtocolVersionModel,\n  SidetreeError,\n  IOperationQueue,\n} from '@sidetree/common';\nimport DownloadManager from './DownloadManager';\nimport Resolver from './Resolver';\n\n/**\n * The class that handles the loading of different versions of protocol codebase.\n */\nexport default class VersionManager\n  implements IVersionManager, IVersionMetadataFetcher {\n  public allSupportedHashAlgorithms: number[] = [];\n\n  // Reverse sorted protocol versions. ie. latest version first.\n  private protocolVersionsReverseSorted: ProtocolVersionModel[];\n\n  private batchWriters: Map<string, IBatchWriter>;\n  private operationProcessors: Map<string, IOperationProcessor>;\n  private operationQueues: Map<string, IOperationQueue>;\n  private requestHandlers: Map<string, IRequestHandler>;\n  private transactionProcessors: Map<string, ITransactionProcessor>;\n  private transactionSelectors: Map<string, ITransactionSelector>;\n  private versionMetadatas: Map<string, AbstractVersionMetadata>;\n\n  public constructor(\n    private config: Config,\n    protocolVersions: ProtocolVersionModel[]\n  ) {\n    // Reverse sort protocol versions.\n    this.protocolVersionsReverseSorted = protocolVersions.sort(\n      (a, b) => b.startingBlockchainTime - a.startingBlockchainTime\n    );\n\n    this.batchWriters = new Map();\n    this.operationProcessors = new Map();\n    this.operationQueues = new Map();\n    this.requestHandlers = new Map();\n    this.transactionProcessors = new Map();\n    this.transactionSelectors = new Map();\n    this.versionMetadatas = new Map();\n  }\n\n  /**\n   * Loads all the versions of the protocol codebase.\n   */\n  public async initialize(\n    blockchain: IBlockchain,\n    cas: ICas,\n    downloadManager: DownloadManager,\n    operationStore: IOperationStore,\n    resolver: Resolver,\n    transactionStore: ITransactionStore\n  ): Promise<void> {\n    // Instantiate rest of the protocol components.\n    // NOTE: In principal each version of the interface implemtnations can have different constructors,\n    // but we currently keep the constructor signature the same as much as possible for simple instance construction,\n    // but it is not inherently \"bad\" if we have to have conditional constructions for each if we have to.\n    for (const protocolVersion of this.protocolVersionsReverseSorted) {\n      const version = protocolVersion.version;\n\n      /* tslint:disable-next-line */\n      const MongoDbOperationQueue = await this.loadDefaultExportsForVersion(\n        version,\n        'MongoDbOperationQueue'\n      );\n      const operationQueue = new MongoDbOperationQueue(\n        this.config.mongoDbConnectionString,\n        this.config.databaseName\n      );\n      await operationQueue.initialize();\n      this.operationQueues.set(version, operationQueue);\n\n      /* tslint:disable-next-line */\n      const TransactionProcessor = await this.loadDefaultExportsForVersion(\n        version,\n        'TransactionProcessor'\n      );\n      const transactionProcessor = new TransactionProcessor(\n        downloadManager,\n        operationStore,\n        blockchain,\n        this\n      );\n      this.transactionProcessors.set(version, transactionProcessor);\n\n      /* tslint:disable-next-line */\n      const TransactionSelector = await this.loadDefaultExportsForVersion(\n        version,\n        'TransactionSelector'\n      );\n      const transactionSelector = new TransactionSelector(transactionStore);\n      this.transactionSelectors.set(version, transactionSelector);\n\n      /* tslint:disable-next-line */\n      const BatchWriter = await this.loadDefaultExportsForVersion(\n        version,\n        'BatchWriter'\n      );\n      const batchWriter = new BatchWriter(\n        operationQueue,\n        blockchain,\n        cas,\n        this\n      );\n      this.batchWriters.set(version, batchWriter);\n\n      /* tslint:disable-next-line */\n      const OperationProcessor = await this.loadDefaultExportsForVersion(\n        version,\n        'OperationProcessor'\n      );\n      const operationProcessor = new OperationProcessor();\n      this.operationProcessors.set(version, operationProcessor);\n\n      /* tslint:disable-next-line */\n      const RequestHandler = await this.loadDefaultExportsForVersion(\n        version,\n        'RequestHandler'\n      );\n      const requestHandler = new RequestHandler(\n        resolver,\n        operationQueue,\n        this.config.didMethodName\n      );\n      this.requestHandlers.set(version, requestHandler);\n\n      /* tslint:disable-next-line */\n      const VersionMetadata = await this.loadDefaultExportsForVersion(\n        version,\n        'VersionMetadata'\n      );\n      const versionMetadata = new VersionMetadata();\n      if (!(versionMetadata instanceof AbstractVersionMetadata)) {\n        throw new SidetreeError(\n          CoreErrorCode.VersionManagerVersionMetadataIncorrectType,\n          `make sure VersionMetaData is properly implemented for version ${version}`\n        );\n      }\n      this.versionMetadatas.set(version, versionMetadata);\n    }\n\n    // Get and cache supported hash algorithms.\n    const hashAlgorithmsWithDuplicates = Array.from(\n      this.versionMetadatas.values(),\n      (value) => value.hashAlgorithmInMultihashCode\n    );\n    this.allSupportedHashAlgorithms = Array.from(\n      new Set(hashAlgorithmsWithDuplicates)\n    ); // This line removes duplicates.\n  }\n\n  /**\n   * Gets the corresponding version of the `IBatchWriter` based on the given blockchain time.\n   */\n  public getBatchWriter(blockchainTime: number): IBatchWriter {\n    const version = this.getVersionString(blockchainTime);\n    const batchWriter = this.batchWriters.get(version);\n\n    if (batchWriter === undefined) {\n      throw new SidetreeError(\n        CoreErrorCode.VersionManagerBatchWriterNotFound,\n        `Batch writer for blockchain time ${blockchainTime} not found.`\n      );\n    }\n\n    return batchWriter;\n  }\n\n  /**\n   * Gets the corresponding version of the `IOperationProcessor` based on the given blockchain time.\n   */\n  public getOperationProcessor(blockchainTime: number): IOperationProcessor {\n    const version = this.getVersionString(blockchainTime);\n    const operationProcessor = this.operationProcessors.get(version);\n\n    if (operationProcessor === undefined) {\n      throw new SidetreeError(\n        CoreErrorCode.VersionManagerOperationProcessorNotFound,\n        `Operation processor for blockchain time ${blockchainTime} not found.`\n      );\n    }\n\n    return operationProcessor;\n  }\n\n  /**\n   * Gets the corresponding version of the `IRequestHandler` based on the given blockchain time.\n   */\n  public getRequestHandler(blockchainTime: number): IRequestHandler {\n    const version = this.getVersionString(blockchainTime);\n    const requestHandler = this.requestHandlers.get(version);\n\n    if (requestHandler === undefined) {\n      throw new SidetreeError(\n        CoreErrorCode.VersionManagerRequestHandlerNotFound,\n        `Request handler for blockchain time ${blockchainTime} not found.`\n      );\n    }\n\n    return requestHandler;\n  }\n\n  /**\n   * Gets the corresponding version of the `TransactionProcessor` based on the given blockchain time.\n   */\n  public getTransactionProcessor(\n    blockchainTime: number\n  ): ITransactionProcessor {\n    const version = this.getVersionString(blockchainTime);\n    const transactionProcessor = this.transactionProcessors.get(version);\n\n    if (transactionProcessor === undefined) {\n      throw new SidetreeError(\n        CoreErrorCode.VersionManagerTransactionProcessorNotFound,\n        `Transaction processor for blockchain time ${blockchainTime} not found.`\n      );\n    }\n\n    return transactionProcessor;\n  }\n\n  /**\n   * Gets the corresponding version of the `TransactionSelector` based on the given blockchain time.\n   */\n  public getTransactionSelector(blockchainTime: number): ITransactionSelector {\n    const version = this.getVersionString(blockchainTime);\n    const transactionSelector = this.transactionSelectors.get(version);\n\n    if (transactionSelector === undefined) {\n      throw new SidetreeError(\n        CoreErrorCode.VersionManagerTransactionSelectorNotFound,\n        `Transaction selector for blockchain time ${blockchainTime} not found.`\n      );\n    }\n\n    return transactionSelector;\n  }\n\n  public getVersionMetadata(blockchainTime: number): AbstractVersionMetadata {\n    const versionString = this.getVersionString(blockchainTime);\n    const versionMetadata = this.versionMetadatas.get(versionString);\n    // this is always be defined because if blockchain time is found, version will be defined\n    return versionMetadata!;\n  }\n\n  public getOperationQueue(blockchainTime: number): IOperationQueue {\n    const versionString = this.getVersionString(blockchainTime);\n    const operationQueue = this.operationQueues.get(versionString);\n    // this is always be defined because if blockchain time is found, version will be defined\n    return operationQueue!;\n  }\n\n  /**\n   * Gets the corresponding protocol version string given the blockchain time.\n   */\n  private getVersionString(blockchainTime: number): string {\n    // Iterate through each version to find the right version.\n    for (const protocolVersion of this.protocolVersionsReverseSorted) {\n      if (blockchainTime >= protocolVersion.startingBlockchainTime) {\n        return protocolVersion.version;\n      }\n    }\n\n    throw new SidetreeError(\n      CoreErrorCode.VersionManagerVersionStringNotFound,\n      `Unable to find version string for blockchain time ${blockchainTime}.`\n    );\n  }\n\n  private async loadDefaultExportsForVersion(\n    version: string,\n    className: string\n  ): Promise<any> {\n    if (version === 'latest') {\n      switch (className) {\n        case 'MongoDbOperationQueue':\n          return (await import('@sidetree/db')).MongoDbOperationQueue;\n        case 'TransactionProcessor':\n          return (await import('./TransactionProcessor')).default;\n        case 'TransactionSelector':\n          return (await import('./TransactionSelector')).default;\n        case 'BatchWriter':\n          return (await import('./write/BatchWriter')).default;\n        case 'OperationProcessor':\n          return (await import('./OperationProcessor')).default;\n        case 'RequestHandler':\n          return (await import('./RequestHandler')).default;\n        case 'VersionMetadata':\n          return (await import('./VersionMetadata')).default;\n        default:\n          return;\n      }\n    }\n    return (await import(`./versions/${version}/${className}`)).default;\n  }\n}\n"],"names":["_Pact","prototype","then","onFulfilled","onRejected","result","state","this","s","callback","_settle","v","e","o","_this","value","pact","bind","observer","_isSettledPact","thenable","_forTo","array","body","check","reject","i","_cycle","length","_iteratorSymbol","Symbol","iterator","_forOf","target","step","next","done","return","_fixup","TypeError","values","push","_for","test","update","stage","shouldContinue","updateValue","_resumeAfterTest","_resumeAfterBody","_resumeAfterUpdate","_catch","recover","_finallyRethrows","finalizer","asyncIterator","ArrayMethods","hasDuplicates","uniqueValues","Set","has","add","areMutuallyExclusive","array1","array2","valuesInArray1","pako","require","Compressor","compress","inputAsBuffer","deflate","Buffer","from","decompress","inflate","DocumentComposer","transformToExternalDocument","didState","did","undefined","nextRecoveryCommitmentHash","status","document","shortFormDid","split","authentication","assertionMethod","capabilityInvocation","capabilityDelegation","keyAgreement","public_keys","Array","isArray","publicKey","id","didDocumentPublicKey","controller","type","publicKeyJwk","jwk","purposeSet","purpose","PublicKeyPurpose","General","Auth","AssertionMethod","CapabilityInvocation","CapabilityDelegation","KeyAgreement","service_endpoints","serviceEndpoint","endpoint","didDocument","service","JSON","parse","stringify","methodMetadata","recoveryCommitment","updateCommitment","nextUpdateCommitmentHash","applyUpdateOperation","operation","resultantDocument","applyPatches","delta","patches","validateDocument","SidetreeError","ErrorCode","DocumentComposerDocumentMissing","allowedProperties","property","DocumentComposerUnknownPropertyInDocument","Object","hasOwnProperty","call","validatePublicKeys","validateServiceEndpoints","validateDocumentPatches","DocumentComposerUpdateOperationDocumentPatchesNotArray","validatePatch","patch","action","validateAddPublicKeysPatch","validateRemovePublicKeysPatch","validateAddServiceEndpointsPatch","validateRemoveServiceEndpointsPatch","validateIetfJsonPatch","DocumentComposerPatchMissingOrUnknownAction","keys","DocumentComposerPatchMissingOrUnknownProperty","error","jsonpatch","validate","console","warn","name","DocumentComposerPublicKeysNotArray","publicKeyIdSet","DocumentComposerPublicKeyMissingOrUnknownProperty","DocumentComposerPublicKeyJwkMissingOrIncorrectType","DocumentComposerPublicKeyTypeMissingOrIncorrectType","validateId","DocumentComposerPublicKeyIdDuplicated","DocumentComposerPublicKeyPurposeMissingOrUnknown","DocumentComposerPublicKeyPurposeExceedsMaxLength","validPurposes","DocumentComposerPublicKeyInvalidPurpose","DocumentComposerPatchPublicKeyIdsNotArray","DocumentComposerPatchPublicKeyIdNotString","ids","DocumentComposerPatchServiceEndpointIdsNotArray","DocumentComposerPatchServiceEndpointsNotArray","DocumentComposerServiceEndpointMissingOrUnknownProperty","DocumentComposerPatchServiceEndpointTypeNotString","DocumentComposerPatchServiceEndpointTypeTooLong","DocumentComposerPatchServiceEndpointServiceEndpointNotString","DocumentComposerPatchServiceEndpointServiceEndpointTooLong","URL","DocumentComposerPatchServiceEndpointServiceEndpointNotValidUrl","DocumentComposerIdNotString","DocumentComposerIdTooLong","Encoder","isBase64UrlString","DocumentComposerIdNotUsingBase64UrlCharacterSet","applyPatchToDidDocument","addPublicKeys","removePublicKeys","addServiceEndpoints","removeServiceEndpoints","applyIetfJsonPatch","applyPatch","newDocument","publicKeyMap","Map","map","set","entries","pkm","get","idToIndexMapper","idx","idsToRemove","filter","yieldableJson","JsonAsync","jsonData","jsonParsePromise","Promise","resolve","parseAsync","err","data","OperationUtils","parseDelta","deltaEncodedString","DeltaMissingOrNotString","deltaJsonString","decodeAsString","DeltaMissingOrUnknownProperty","OperationDocumentPatchesMissing","nextUpdateCommitment","decodeAsBuffer","update_commitment","Multihash","verifyHashComputedUsingLatestSupportedAlgorithm","CreateOperation","operationBuffer","didUniqueSuffix","encodedSuffixData","suffixData","encodedDelta","OperationType","Create","computeDidUniqueSuffix","suffixDataBuffer","multihash","hash","encode","parseOperationFromAnchorFile","input","parseObject","operationJsonString","toString","operationObject","anchorFileMode","expectedPropertyCount","CreateOperationMissingOrUnknownProperty","suffix_data","parseSuffixData","CreateOperationTypeIncorrect","suffixDataEncodedString","CreateOperationSuffixDataMissingOrNotString","suffixDataJsonString","CreateOperationSuffixDataMissingOrUnknownProperty","delta_hash","nextRecoveryCommitment","recovery_commitment","Jwk","generateEd25519KeyPair","JWK","generate","keyPair","privateKey","toJWK","getBufferAtIndex","mnemonic","index","bip39","seed","hdkey","fromMasterSeed","derive","generateEd25519KeyPairFromMnemonic","privateKeyBuffer","Ed25519KeyPair","ed25519KeyPair","toJwk","privateKeyJwk","generateSecp256k1KeyPair","generateJwkKeyPairFromMnemonic","keyType","generateSecp256k1KeyPairFromMnemonic","Error","keytoFrom","crv","validatePublicJwk","JwkUndefined","JwkHasUnknownProperty","kty","JwkMissingOrInvalidKty","x","JwkMissingOrInvalidTypeX","y","JwkMissingOrInvalidTypeY","JwkMissingOrInvalidCrv","getCurve25519PublicKey","keyCopy","assign","d","Jws","compactJws","JwsCompactJwsNotString","parts","JwsCompactJwsInvalid","protectedHeader","payload","signature","decodedProtectedHeadJsonString","decodeBase64UrlAsString","decodedProtectedHeader","JwsProtectedHeaderMissingOrUnknownProperty","alg","JwsProtectedHeaderMissingOrIncorrectAlg","JwsSignatureNotBase64UrlString","JwsPayloadNotBase64UrlString","toCompactJws","createCompactJws","verifySignature","encodedProtectedHeader","encodedPayload","verifyCompactJws","EdDSA","verify","ES256K","log","createFromError","JwsFailedSignatureValidation","signAsCompactJws","sign","header","parseCompactJws","DeactivateOperation","signedDataJws","signedData","Deactivate","DeactivateOperationMissingOrUnknownProperty","did_suffix","DeactivateOperationMissingOrInvalidDidUniqueSuffix","signed_data","parseSignedDataPayload","DeactivateOperationTypeIncorrect","expectedDidUniqueSuffix","signedDataJsonString","DeactivateOperationSignedDataMissingOrUnknownProperty","DeactivateOperationSignedDidUniqueSuffixMismatch","recovery_key","didSuffix","RecoverOperation","Recover","RecoverOperationMissingOrUnknownProperty","RecoverOperationMissingOrInvalidDidUniqueSuffix","RecoverOperationTypeIncorrect","signedDataEncodedString","RecoverOperationSignedDataMissingOrUnknownProperty","AnchorFile","model","didUniqueSuffixes","createOperations","recoverOperations","deactivateOperations","anchorFileBuffer","anchorFileDecompressedBuffer","anchorFileModel","AnchorFileMultipleOperationsForTheSameDid","operations","deactivate","AnchorFileDeactivatePropertyNotArray","deactivateOperation","AnchorFileRecoverPropertyNotArray","recoverOperation","AnchorFileHasUnknownProperty","AnchorFileMapFileHashMissing","AnchorFileMissingOperationsProperty","writer_lock_id","AnchorFileWriterLockIPropertyNotString","map_file_uri","AnchorFileMapFileHashNotString","allowedOperationsProperties","AnchorFileUnexpectedPropertyInOperations","create","AnchorFileCreatePropertyNotArray","createOperation","AnchorFileNotJson","AnchorFileDecompressionFailure","createModel","writerLockId","mapFileHash","createOperationArray","recoverOperationArray","deactivateOperationArray","createBuffer","anchorFileJson","BatchScheduler","versionManager","blockchain","batchingIntervalInSeconds","startPeriodicBatchWriting","continuePeriodicBatchWriting","setImmediate","writeOperationBatch","stopPeriodicBatchWriting","info","endTimer","timeSpan","batchWriter","_this3","getBatchWriter","approximateTime","time","write","rounded","setTimeout","ChunkFile","chunkFileBuffer","decompressedChunkFileBuffer","chunkFileObject","ChunkFileUnexpectedProperty","validateDeltasProperty","deltas","ChunkFileDeltasPropertyNotArray","ChunkFileDeltasNotArrayOfStrings","deltaBuffer","protocolParameters","maxDeltaSizeInBytes","ChunkFileDeltaSizeExceedsLimit","updateOperations","rawData","DownloadManager","maxConcurrentDownloads","cas","isNaN","start","completedDownloadHandles","activeDownloads","downloadHandle","downloadInfo","completed","completedDownloads","fetchResult","availableDownloadLanes","size","pendingDownloads","downloadAsync","handle","splice","download","contentHash","maxSizeInBytes","crypto","fetchPromise","content","_this5","read","UpdateOperation","Update","parseOperationFromMapFile","mapFileMode","UpdateOperationMissingOrUnknownProperty","UpdateOperationMissingDidUniqueSuffix","signedDataModel","UpdateOperationTypeIncorrect","UpdateOperationSignedDataHasMissingOrUnknownProperty","update_key","MapFile","mapFileBuffer","decompressedBuffer","mapFileModel","MapFileHasUnknownProperty","validateChunksProperty","chunks","parseOperationsProperty","MapFileNotJson","MapFileDecompressionFailure","MapFileMultipleOperationsForTheSameDid","MapFileOperationsPropertyHasMissingOrUnknownProperty","MapFileUpdateOperationsNotArray","updateOperation","MapFileChunksPropertyMissingOrIncorrectType","MapFileChunksPropertyDoesNotHaveExactlyOneElement","MapFileChunkHasMissingOrUnknownProperty","chunkFileHash","updateOperationArray","chunk_file_uri","ThroughputLimiter","getQualifiedTransactions","transactions","currentTransactionTime","transactionsGroupedByTransactionTime","transaction","transactionTime","qualifiedTransactions","transactionGroup","transactionSelector","_this2","getTransactionSelector","selectQualifiedTransactions","qualifiedTransactionsInCurrentGroup","Observer","operationStore","transactionStore","unresolvableTransactionStore","observingIntervalInSeconds","throughputLimiter","refreshLastKnownTransaction","getLastTransaction","lastKnownTransaction","startPeriodicProcessing","_this4","continuePeriodicProcessing","processTransactions","stopPeriodicProcessing","awaitTransactionProcessing","_this6","storeConsecutiveTransactionsProcessed","processUnresolvableTransactions","moreTransactions","awaitBody","readResult","blockReorganizationDetected","invalidTransactionNumberOrTimeHash","lastKnownTransactionTime","waitUntilCountOfTransactionsUnderProcessingIsLessOrEqualTo","revertInvalidTransactions","sort","a","b","transactionNumber","awaitingTransaction","processingStatus","TransactionProcessingStatus","Pending","transactionsUnderProcessing","processTransaction","lastKnownTransactionNumber","lastKnownTransactionTimeHash","transactionTimeHash","code","SharedErrorCode","InvalidTransactionNumberOrTimeHash","count","_this8","_this10","getUnresolvableTransactionsDueForRetry","unresolvableTransactions","unresolvableTransactionStatus","Processed","_this12","addTransaction","transactionUnderProcessing","transactionProcessedSuccessfully","transactionProcessor","_this14","getTransactionProcessor","removeUnresolvableTransaction","recordUnresolvableTransactionFetchAttempt","_this16","getExponentiallySpacedTransactions","exponentiallySpacedTransactions","getFirstValidTransaction","bestKnownValidRecentTransaction","bestKnownValidRecentTransactionNumber","removeTransactionsLaterThan","removeUnresolvableTransactionsLaterThan","Operation","operationType","OperationTypeUnknownOrMissing","OperationGenerator","generateRandomHash","randomBuffer","generateKeyPair","generateAnchoredCreateOperation","generateCreateOperation","createOperationData","operationRequest","anchoredOperationModel","operationIndex","recoveryPublicKey","recoveryPrivateKey","updatePublicKey","updatePrivateKey","signingPublicKey","signingPrivateKey","nextUpdateRevealValueEncodedString","generateServiceEndpoints","generateCreateOperationRequest","canonicalizeThenHashThenEncode","generateRecoverOperation","newRecoveryPublicKey","newRecoveryPrivateKey","newSigningPublicKey","newSigningPrivateKey","publicKeyToBeInDocument","services","generateRecoverOperationRequest","operationJson","generateUpdateOperation","additionalPublicKey","additionalPrivateKey","createUpdateOperationRequestForAddingAKey","additionalKeyId","nextUpdateKey","createAnchoredOperationModelFromOperationModel","operationModel","otherPublicKeys","generateUpdateOperationRequest","createUpdateOperationRequest","request","buffer","encodedDeltaString","signUsingEd25519","createRecoverOperationRequest","signedDataPayloadObject","createDeactivateOperationRequest","generateCreateOperationBuffer","newPublicKey","createUpdateOperationRequestForHubEndpoints","idOfServiceEndpointToAdd","idsOfServiceEndpointToRemove","createDeactivateOperation","Resolver","operationsByType","categorizeOperationsByType","applyCreateOperation","recoverAndDeactivateOperations","concat","constructCommitValueToOperationLookupMap","recoveryCommitValueToOperationMap","applyRecoverAndDeactivateOperations","updateCommitValueToOperationMap","applyUpdateOperations","applyOperation","startingDidState","commitValueToOperationMap","operationsWithCorrectRevealValue","applyFirstValidOperation","newDidState","appliedDidState","operationProcessor","getOperationProcessor","apply","originalDidState","lastOperationTransactionNumber","nonCreateOperations","allSupportedHashAlgorithms","hashAlgorithm","getRevealValue","revealValueBuffer","hashOfRevealValue","hashThenEncode","ServiceInfoProvider","serviceName","getServiceVersion","version","packageJson","VersionManager","config","protocolVersions","protocolVersionsReverseSorted","startingBlockchainTime","batchWriters","operationProcessors","operationQueues","requestHandlers","transactionProcessors","transactionSelectors","versionMetadatas","initialize","downloadManager","resolver","hashAlgorithmsWithDuplicates","hashAlgorithmInMultihashCode","protocolVersion","loadDefaultExportsForVersion","MongoDbOperationQueue","operationQueue","mongoDbConnectionString","databaseName","TransactionProcessor","TransactionSelector","BatchWriter","OperationProcessor","RequestHandler","requestHandler","didMethodName","VersionMetadata","versionMetadata","AbstractVersionMetadata","CoreErrorCode","VersionManagerVersionMetadataIncorrectType","blockchainTime","getVersionString","VersionManagerBatchWriterNotFound","VersionManagerOperationProcessorNotFound","getRequestHandler","VersionManagerRequestHandlerNotFound","VersionManagerTransactionProcessorNotFound","VersionManagerTransactionSelectorNotFound","getVersionMetadata","versionString","getOperationQueue","VersionManagerVersionStringNotFound","className","_import8","_import","_import2","_import3","_import4","_import5","_import6","_import7","discriminant","cases","dispatchIndex","outer","testValue","fallthroughCheck"],"mappings":"slBACO,MAAMA,EAAqB,WACjC,SAASA,KAiCT,OAhCAA,EAAMC,UAAUC,KAAO,SAASC,EAAaC,GAC5C,MAAMC,EAAS,IAAIL,EACbM,EAAQC,KAAKC,EACnB,GAAIF,EAAO,CACV,MAAMG,EAAmB,EAARH,EAAYH,EAAcC,EAC3C,GAAIK,EAAU,CACb,IACCC,EAAQL,EAAQ,EAAGI,EAASF,KAAKI,IAChC,MAAOC,GACRF,EAAQL,EAAQ,EAAGO,GAEpB,OAAOP,EAEP,OAAOE,KAiBT,OAdAA,KAAKM,EAAI,SAASC,GACjB,IACC,MAAMC,EAAQD,EAAMH,EACN,EAAVG,EAAMN,EACTE,EAAQL,EAAQ,EAAGF,EAAcA,EAAYY,GAASA,GAC5CX,EACVM,EAAQL,EAAQ,EAAGD,EAAWW,IAE9BL,EAAQL,EAAQ,EAAGU,GAEnB,MAAOH,GACRF,EAAQL,EAAQ,EAAGO,KAGdP,GAEDL,EAlC0B,GAsC3B,SAASU,EAAQM,EAAMV,EAAOS,GACpC,IAAKC,EAAKR,EAAG,CACZ,GAAIO,aAAiBf,EAAO,CAC3B,IAAIe,EAAMP,EAOT,YADAO,EAAMF,EAAIH,EAAQO,KAAK,KAAMD,EAAMV,IALvB,EAARA,IACHA,EAAQS,EAAMP,GAEfO,EAAQA,EAAMJ,EAMhB,GAAII,GAASA,EAAMb,KAElB,YADAa,EAAMb,KAAKQ,EAAQO,KAAK,KAAMD,EAAMV,GAAQI,EAAQO,KAAK,KAAMD,EAAM,IAGtEA,EAAKR,EAAIF,EACTU,EAAKL,EAAII,EACT,MAAMG,EAAWF,EAAKH,EAClBK,GACHA,EAASF,IAKL,SAASG,EAAeC,GAC9B,OAAOA,aAAoBpB,GAAsB,EAAboB,EAASZ,EAgDvC,SAASa,EAAOC,EAAOC,EAAMC,GACnC,IAAYR,EAAMS,EAAdC,GAAK,EAwBT,OAvBA,SAASC,EAAOtB,GACf,IACC,OAASqB,EAAIJ,EAAMM,UAAYJ,IAAUA,MAExC,IADAnB,EAASkB,EAAKG,KACArB,EAAOH,KAAM,CAC1B,IAAIiB,EAAed,GAIlB,YADAA,EAAOH,KAAKyB,EAAQF,IAAWA,EAASf,EAAQO,KAAK,KAAMD,EAAO,IAAIhB,EAAS,KAF/EK,EAASA,EAAOM,EAOfK,EACHN,EAAQM,EAAM,EAAGX,GAEjBW,EAAOX,EAEP,MAAOO,GACRF,EAAQM,IAASA,EAAO,IAAIhB,GAAU,EAAGY,IAG3Ce,GACOX,EAyBD,MAAMa,EAAkD,oBAAXC,OAA0BA,OAAOC,WAAaD,OAAOC,SAAWD,OAAO,oBAAuB,aAI3I,SAASE,EAAOC,EAAQV,EAAMC,GACpC,GAAuC,mBAA5BS,EAAOJ,GAAiC,CAClD,IAA0CK,EAAMlB,EAAMS,EAAlDM,EAAWE,EAAOJ,KAwBtB,GAvBA,SAASF,EAAOtB,GACf,IACC,QAAS6B,EAAOH,EAASI,QAAQC,MAAUZ,GAAUA,MAEpD,IADAnB,EAASkB,EAAKW,EAAKnB,SACLV,EAAOH,KAAM,CAC1B,IAAIiB,EAAed,GAIlB,YADAA,EAAOH,KAAKyB,EAAQF,IAAWA,EAASf,EAAQO,KAAK,KAAMD,EAAO,IAAIhB,EAAS,KAF/EK,EAASA,EAAOM,EAOfK,EACHN,EAAQM,EAAM,EAAGX,GAEjBW,EAAOX,EAEP,MAAOO,GACRF,EAAQM,IAASA,EAAO,IAAIhB,GAAU,EAAGY,IAG3Ce,GACII,EAASM,OAAQ,CACpB,IAAIC,EAAS,SAASvB,GACrB,IACMmB,EAAKE,MACTL,EAASM,SAET,MAAMzB,IAER,OAAOG,GAER,GAAIC,GAAQA,EAAKd,KAChB,OAAOc,EAAKd,KAAKoC,GAAQ,SAAS1B,GACjC,MAAM0B,EAAO1B,MAGf0B,IAED,OAAOtB,EAGR,KAAM,WAAYiB,GACjB,MAAM,IAAIM,UAAU,0BAIrB,IADA,IAAIC,EAAS,GACJd,EAAI,EAAGA,EAAIO,EAAOL,OAAQF,IAClCc,EAAOC,KAAKR,EAAOP,IAEpB,OAAOL,EAAOmB,GAAQ,SAASd,GAAK,OAAOH,EAAKiB,EAAOd,MAAQF,GAiCzD,SAASkB,EAAKC,EAAMC,EAAQrB,GAElC,IADA,IAAIsB,IACK,CACR,IAAIC,EAAiBH,IAIrB,GAHIxB,EAAe2B,KAClBA,EAAiBA,EAAenC,IAE5BmC,EACJ,OAAOzC,EAER,GAAIyC,EAAe5C,KAAM,CACxB2C,EAAQ,EACR,MAED,IAAIxC,EAASkB,IACb,GAAIlB,GAAUA,EAAOH,KAAM,CAC1B,IAAIiB,EAAed,GAEZ,CACNwC,EAAQ,EACR,MAHAxC,EAASA,EAAOG,EAMlB,GAAIoC,EAAQ,CACX,IAAIG,EAAcH,IAClB,GAAIG,GAAeA,EAAY7C,OAASiB,EAAe4B,GAAc,CACpEF,EAAQ,EACR,QAIH,IAAI7B,EAAO,IAAIhB,EACXyB,EAASf,EAAQO,KAAK,KAAMD,EAAM,GAEtC,OADW,IAAV6B,EAAcC,EAAe5C,KAAK8C,GAA8B,IAAVH,EAAcxC,EAAOH,KAAK+C,GAAoBF,EAAY7C,KAAKgD,IAAqBhD,UAAK,EAAQuB,GACjJT,EACP,SAASiC,EAAiBlC,GACzBV,EAASU,EACT,EAAG,CACF,GAAI6B,IACHG,EAAcH,MACKG,EAAY7C,OAASiB,EAAe4B,GAEtD,YADAA,EAAY7C,KAAKgD,GAAoBhD,UAAK,EAAQuB,GAKpD,KADAqB,EAAiBH,MACOxB,EAAe2B,KAAoBA,EAAenC,EAEzE,YADAD,EAAQM,EAAM,EAAGX,GAGlB,GAAIyC,EAAe5C,KAElB,YADA4C,EAAe5C,KAAK8C,GAAkB9C,UAAK,EAAQuB,GAIhDN,EADJd,EAASkB,OAERlB,EAASA,EAAOM,UAERN,IAAWA,EAAOH,MAC5BG,EAAOH,KAAK+C,GAAkB/C,UAAK,EAAQuB,GAE5C,SAASuB,EAAiBF,GACrBA,GACHzC,EAASkB,MACKlB,EAAOH,KACpBG,EAAOH,KAAK+C,GAAkB/C,UAAK,EAAQuB,GAE3CwB,EAAiB5C,GAGlBK,EAAQM,EAAM,EAAGX,GAGnB,SAAS6C,KACJJ,EAAiBH,KAChBG,EAAe5C,KAClB4C,EAAe5C,KAAK8C,GAAkB9C,UAAK,EAAQuB,GAEnDuB,EAAiBF,GAGlBpC,EAAQM,EAAM,EAAGX,IAkOb,SAAS8C,EAAO5B,EAAM6B,GAC5B,IACC,IAAI/C,EAASkB,IACZ,MAAMX,GACP,OAAOwC,EAAQxC,GAEhB,OAAIP,GAAUA,EAAOH,KACbG,EAAOH,UAAK,EAAQkD,GAErB/C,EAID,SAASgD,EAAiB9B,EAAM+B,GACtC,IACC,IAAIjD,EAASkB,IACZ,MAAOX,GACR,OAAO0C,GAAU,EAAM1C,GAExB,OAAIP,GAAUA,EAAOH,KACbG,EAAOH,KAAKoD,EAAUrC,KAAK,MAAM,GAAQqC,EAAUrC,KAAK,MAAM,IAE/DqC,GAAU,EAAOjD,ihCAvW2C,oBAAXyB,SAA0BA,OAAOyB,gBAAkBzB,OAAOyB,cAAgBzB,OAAO,8BC3MrH0B,oCAILC,cAAP,SAAwBnC,WACvBoC,EAAe,IAAIC,IAEhBjC,EAAI,EAAGA,EAAIJ,EAAMM,OAAQF,IAAK,KAC/BX,EAAQO,EAAMI,MAChBgC,EAAaE,IAAI7C,UACZ,EAET2C,EAAaG,IAAI9C,UAGZ,KAMK+C,qBAAP,SACLC,EACAC,aAEMC,EAAiB,IAAIN,IAAOI,OAEdC,qBACdC,EAAeL,oBACV,SAIJ,QCpCLM,EAAOC,QAAQ,QAKAC,oCAKCC,kBAASC,WACrBjE,EAAS6D,EAAKK,QAAQC,OAAOC,KAAKH,2BACjCE,OAAOC,KAAKpE,0CAODqE,oBAAWJ,WACvBjE,EAAS6D,EAAKS,QAAQL,0BACrBE,OAAOC,KAAKpE,6CCPFuE,oCAILC,4BAAP,SACLC,EACAC,WAG4CC,IAAxCF,EAASG,iCACJ,CAAEC,OAAQ,mBAGbC,EAAWL,EAASK,SAEpBC,EAAeL,EAAIM,MAAM,KAAK,GAI9BC,EAAwB,GACxBC,EAAyB,GACzBC,EAA8B,GAC9BC,EAA8B,GAC9BC,EAAsB,GAEtBC,EAAqB,MACvBC,MAAMC,QAAQV,EAASQ,2BACDR,EAASQ,4BAAa,KAAnCG,UACHC,EAAK,IAAMD,EAAUC,GACrBC,EAAuB,CAC3BD,GAAIA,EACJE,WAAYb,EACZc,KAAMJ,EAAUI,KAChBC,aAAcL,EAAUM,KAEpBC,EAA0B,IAAI1C,IAAImC,EAAUQ,SAE9CD,EAAWzC,IAAI2C,mBAAiBC,UAClCb,EAAYlD,KAAKuD,GAEbK,EAAWzC,IAAI2C,mBAAiBE,OAClCnB,EAAe7C,KAAKsD,GAElBM,EAAWzC,IAAI2C,mBAAiBG,kBAClCnB,EAAgB9C,KAAKsD,GAEnBM,EAAWzC,IAAI2C,mBAAiBI,uBAClCnB,EAAqB/C,KAAKsD,GAExBM,EAAWzC,IAAI2C,mBAAiBK,uBAClCnB,EAAqBhD,KAAKsD,GAExBM,EAAWzC,IAAI2C,mBAAiBM,eAClCnB,EAAajD,KAAKsD,IAEXM,EAAWzC,IAAI2C,mBAAiBE,MACzCnB,EAAe7C,KAAKuD,GACXK,EAAWzC,IAAI2C,mBAAiBG,iBACzCnB,EAAgB9C,KAAK8C,GACZc,EAAWzC,IAAI2C,mBAAiBI,sBACzCnB,EAAqB/C,KAAKuD,GACjBK,EAAWzC,IAAI2C,mBAAiBK,sBACzCnB,EAAqBhD,KAAKuD,GACjBK,EAAWzC,IAAI2C,mBAAiBM,eACzCnB,EAAajD,KAAKuD,OAMlBc,EAAoB,MACtBlB,MAAMC,QAAQV,EAAS2B,iCACK3B,EAAS2B,kCAAmB,KAA/CC,UAMTD,EAAkBrE,KALiB,CACjCsD,GAAI,IAAMgB,EAAgBhB,GAC1BG,KAAMa,EAAgBb,KACtBa,gBAAiBA,EAAgBC,eAMjCC,EAAmB,CACvBlB,GAAIX,aACQ,CAAC,+BAAgC,SAAWA,YAG/B,IAAvBO,EAAY/D,SACdqF,EAAYnB,UAAYH,GAGI,IAA1BL,EAAe1D,SACjBqF,EAAY3B,eAAiBA,GAGA,IAA3BC,EAAgB3D,SAClBqF,EAAY1B,gBAAkBA,GAGI,IAAhCC,EAAqB5D,SACvBqF,EAAYzB,qBAAuBA,GAGD,IAAhCC,EAAqB7D,SACvBqF,EAAYxB,qBAAuBA,GAGT,IAAxBC,EAAa9D,SACfqF,EAAYvB,aAAeA,GAGI,IAA7BoB,EAAkBlF,SACpBqF,EAAYC,QAAUJ,GAYjBK,KAAKC,MAAMD,KAAKE,UATU,YACnB,0CACZJ,YAAaA,EACbK,eAAgB,CACdC,mBAAoBzC,EAASG,2BAC7BuC,iBAAkB1C,EAAS2C,gCAYbC,8BAClBC,EACAxC,WAEMyC,EAAoBhD,EAAiBiD,aACzC1C,EACAwC,EAAUG,MAAOC,gCAGZH,yCAOMI,iBAAP,SAAwB7C,WACbH,IAAbG,QACI,IAAI8C,gBAAcC,YAAUC,qCAG9BC,EAAoB,IAAIzE,IAAI,CAAC,cAAe,0BAC7C,IAAM0E,KAAYlD,MAChBiD,EAAkBxE,IAAIyE,SACnB,IAAIJ,gBACRC,YAAUI,iEACaD,mBAMzBE,OAAOtI,UAAUuI,eAAeC,KAAKtD,EAAU,gBACjDP,EAAiB8D,mBAAmBvD,EAASQ,aAI3C4C,OAAOtI,UAAUuI,eAAeC,KAAKtD,EAAU,sBAEjDP,EAAiB+D,yBAAyBxD,EAAS2B,sBAQzC8B,wBAAP,SAA+Bb,OAC/BnC,MAAMC,QAAQkC,SACX,IAAIE,gBACRC,YAAUW,sEAIMd,kBAClBnD,EAAiBkE,0BAINA,cAAP,SAAqBC,UACZA,EAAMC,YAEd,UACHpE,EAAiBoD,iBAAiBe,EAAM5D,oBAErC,kBACHP,EAAiBqE,2BAA2BF,aAEzC,qBACHnE,EAAiBsE,8BAA8BH,aAE5C,wBACHnE,EAAiBuE,iCAAiCJ,aAE/C,2BACHnE,EAAiBwE,oCAAoCL,aAElD,kBACHnE,EAAiByE,sBAAsBN,uBAGjC,IAAId,gBACRC,YAAUoB,iDAKHD,sBAAP,SAA6BN,MAEJ,IADPR,OAAOgB,KAAKR,GAChBnH,aACZ,IAAIqG,gBACRC,YAAUsB,mDAGRC,EAAQC,EAAUC,SAASZ,EAAMhB,YACnC0B,QACFG,QAAQC,KAAKJ,GACP,IAAIxB,gBAAcwB,EAAMK,SAInBb,2BAAP,SAAkCF,MAET,IADPR,OAAOgB,KAAKR,GAChBnH,aACZ,IAAIqG,gBACRC,YAAUsB,+CAId5E,EAAiB8D,mBAAmBK,EAAMpD,gBAG7B+C,mBAAP,SAA0B/C,OAC3BC,MAAMC,QAAQF,SACX,IAAIsC,gBAAcC,YAAU6B,8CAG9BC,EAA8B,IAAIrG,QAChBgC,kBAAa,KAA1BG,aAG0B,IAFPyC,OAAOgB,KAAKzD,GAEhBlE,aAChB,IAAIqG,gBACRC,YAAU+B,sDAIe,iBAAlBnE,EAAUM,KAAoBR,MAAMC,QAAQC,EAAUM,WACzD,IAAI6B,gBACRC,YAAUgC,uDAIgB,iBAAnBpE,EAAUI,WACb,IAAI+B,gBACRC,YAAUiC,wDAIdvF,EAAiBwF,WAAWtE,EAAUC,IAGlCiE,EAAepG,IAAIkC,EAAUC,UACzB,IAAIkC,gBACRC,YAAUmC,0CAGdL,EAAenG,IAAIiC,EAAUC,KAExBH,MAAMC,QAAQC,EAAUQ,UAAyC,IAA7BR,EAAUQ,QAAQ1E,aACnD,IAAIqG,gBACRC,YAAUoC,qDAIVxE,EAAUQ,QAAQ1E,OAAS2G,OAAO/F,OAAO+D,oBAAkB3E,aACvD,IAAIqG,gBACRC,YAAUqC,4DAIRC,EAAgB,IAAI7G,IAAI4E,OAAO/F,OAAO+D,yBAEtBT,EAAUQ,4BACzBkE,EAAc5G,mBACX,IAAIqE,gBACRC,YAAUuC,6CAOLvB,8BAAP,SAAqCH,MAEZ,IADPR,OAAOgB,KAAKR,GAChBnH,aACZ,IAAIqG,gBACRC,YAAUsB,mDAIT5D,MAAMC,QAAQkD,EAAMpD,mBACjB,IAAIsC,gBACRC,YAAUwC,yDAIY3B,EAAMpD,+BACH,+BACnB,IAAIsC,gBACRC,YAAUyC,8CASHvB,oCAAP,SAA2CL,MAElB,IADPR,OAAOgB,KAAKR,GAChBnH,aACZ,IAAIqG,gBACRC,YAAUsB,mDAIT5D,MAAMC,QAAQkD,EAAM6B,WACjB,IAAI3C,gBACRC,YAAU2C,+DAIG9B,EAAM6B,oBACrBhG,EAAiBwF,uBAONjB,iCAAP,SAAwCJ,MAEf,IADPR,OAAOgB,KAAKR,GAChBnH,aACZ,IAAIqG,gBACRC,YAAUsB,mDAIT5D,MAAMC,QAAQkD,EAAMjC,yBACjB,IAAImB,gBACRC,YAAU4C,+CAIdlG,EAAiB+D,yBAAyBI,EAAMjC,sBAOnC6B,yBAAP,SAAgC7B,OACjClB,MAAMC,QAAQiB,SACX,IAAImB,gBACRC,YAAU4C,6DAIgBhE,kBAAmB,KAAtCC,aAEgC,IADPwB,OAAOgB,KAAKxC,GAChBnF,aAEtB,IAAIqG,gBACRC,YAAU6C,4DAIdnG,EAAiBwF,WAAWrD,EAAgBhB,IAER,iBAAzBgB,EAAgBb,WACnB,IAAI+B,gBACRC,YAAU8C,sDAGVjE,EAAgBb,KAAKtE,OAAS,SAC1B,IAAIqG,gBACRC,YAAU+C,oDAG0B,iBAA7BlE,EAAgBC,eACnB,IAAIiB,gBACRC,YAAUgD,iEAGVnE,EAAgBC,SAASpF,OAAS,UAC9B,IAAIqG,gBACRC,YAAUiD,oEAORC,IAAIrE,EAAgBC,UACxB,eACM,IAAIiB,gBACRC,YAAUmD,qEAMHjB,WAAP,SAAkBrE,MACN,iBAAPA,QACH,IAAIkC,gBACRC,YAAUoD,8CACQnE,KAAKE,UAAUtB,0BAA0BA,UAG3DA,EAAGnE,OAAS,SACR,IAAIqG,gBAAcC,YAAUqD,+BAG/BC,UAAQC,kBAAkB1F,SACvB,IAAIkC,gBACRC,YAAUwD,oDAUF7D,aAAP,SAAoB1C,EAAe4C,aAEpCH,EAAoBzC,MACJ4C,kBAClBH,EAAoBhD,EAAiB+G,wBACnC/D,kBAKGA,KAMM+D,wBAAP,SACNxG,EACA4D,SAEqB,YAAjBA,EAAMC,OACDD,EAAM5D,SACa,oBAAjB4D,EAAMC,OACRpE,EAAiBgH,cAAczG,EAAU4D,GACtB,uBAAjBA,EAAMC,OACRpE,EAAiBiH,iBAAiB1G,EAAU4D,GACzB,0BAAjBA,EAAMC,OACRpE,EAAiBkH,oBAAoB3G,EAAU4D,GAC5B,6BAAjBA,EAAMC,OACRpE,EAAiBmH,uBAAuB5G,EAAU4D,GAC/B,oBAAjBA,EAAMC,OACRpE,EAAiBoH,mBAAmB7G,EAAU4D,QADhD,KAKMiD,mBAAP,SAA0B7G,EAAe4D,UACnCW,EAAUuC,gBAAgB9G,GAAY4D,EAAMhB,SAC7CmE,eAMEN,cAAP,SACNzG,EACA4D,aAEMoD,EAAe,IAAIC,KACtBjH,EAASQ,aAAe,IAAI0G,KAAI,SAACvG,SAAc,CAACA,EAAUC,GAAID,WAIzCiD,EAAMpD,4BAAa,KAAhCG,UAGTqG,EAAaG,IAAIxG,EAAUC,GAAID,UAGjCX,EAASQ,YAAcC,MAAMnB,KAAK0H,EAAaI,WAAWF,KACxD,SAACG,UAAaA,EAAI,MAGbrH,KAMM0G,iBAAP,SACN1G,EACA4D,aAEMoD,EAAe,IAAIC,KACtBjH,EAASQ,aAAe,IAAI0G,KAAI,SAACvG,SAAc,CAACA,EAAUC,GAAID,WAIzCiD,EAAMpD,4BAAa,KAAhCG,eAGWd,IAFAmH,EAAaM,IAAI3G,IAGnCqG,SAAoBrG,UAMxBX,EAASQ,YAAcC,MAAMnB,KAAK0H,EAAaI,WAAWF,KACxD,SAACG,UAAaA,EAAI,MAGbrH,KAGM2G,oBAAP,SACN3G,EACA4D,OAEMjC,EAAoBiC,EAAMjC,uBAEG9B,IAA/BG,EAAS2B,oBAEX3B,EAAS2B,kBAAoB,QAGzB4F,EAAkB,IAAIN,QAEvB,IAAMO,KAAOxH,EAAS2B,kBACzB4F,EAAgBJ,IAAInH,EAAS2B,kBAAkB6F,GAAK5G,GAAI4G,iBAG5B7F,kBAAmB,KAAtCC,aACL2F,EAAgB9I,IAAImD,EAAgBhB,IAAK,KACrC4G,EAAMD,EAAgBD,IAAI1F,EAAgBhB,IAChDZ,EAAS2B,kBAAkB6F,GAAO5F,OAElC5B,EAAS2B,kBAAkBrE,KAAKsE,UAI7B5B,KAGM4G,uBAAP,SACN5G,EACA4D,WAEmC/D,IAA/BG,EAAS2B,yBACJ3B,MAGHyH,EAAc,IAAIjJ,IAAIoF,EAAM6B,YAClCzF,EAAS2B,kBAAoB3B,EAAS2B,kBAAkB+F,QACtD,SAAC9F,UAAqB6F,EAAYhJ,IAAImD,EAAgBhB,OAGjDZ,QCtlBL2H,EAAgB3I,QAAQ,kBAKT4I,oCAKC3F,eAAM4F,WAElBC,EAAmB,IAAIC,SAAQ,SAACC,EAAS1L,GAC7CqL,EAAcM,WAAWJ,GAAU,SAACK,EAAUC,GACxCD,EACF5L,EAAO4L,GAEPF,EAAQG,gCAMOL,4CCVJM,oCAICC,oBAAWC,UACK,iBAAvBA,QACH,IAAIxF,gBAAcC,YAAUwF,6BAG9BC,EAAkBnC,UAAQoC,eAAeH,0BAC3BV,EAAU3F,MAAMuG,mBAA9B7F,MAGoB,IADPS,OAAOgB,KAAKzB,GAChBlG,aACP,IAAIqG,gBAAcC,YAAU2F,uCAGd7I,IAAlB8C,EAAMC,cACF,IAAIE,gBAAcC,YAAU4F,iCAIpClJ,EAAiBgE,wBAAwBd,EAAMC,aAEzCgG,EAAuBvC,UAAQwC,eACnClG,EAAMmG,0BAERC,YAAUC,gDACRJ,GAGK,CACLhG,QAASD,EAAMC,QACfkG,kBAAmBnG,EAAMmG,+DC1BVG,wBA0BjBC,EACAC,EACAC,EACAC,EACAC,EACA3G,QAEKwG,gBAAkBA,OAClBpI,KAAOwI,gBAAcC,YACrBN,gBAAkBA,OAClBE,kBAAoBA,OACpBC,WAAaA,OACbC,aAAeA,OACf3G,MAAQA,WAMA8G,uBAAP,SAA8BL,OAC9BM,EAAmBrD,UAAQwC,eAAeO,GAC1CO,EAAYZ,YAAUa,KAAKF,UACRrD,UAAQwD,OAAOF,MAOtBG,sCAClBC,WAGMb,EAAkB7J,OAAOC,KAAK0C,KAAKE,UAAU6H,2BAC3Bd,EAAgBe,YACtCD,EACAb,GACA,0CAQgBjH,eAAMiH,WAClBe,EAAsBf,EAAgBgB,kCACdtC,EAAU3F,MAAMgI,mBAAxCE,0BACwBlB,EAAgBe,YAC5CG,EACAjB,GACA,6CAYgBc,qBAClBG,EACAjB,EACAkB,WAEIC,EAAwB,KACxBD,IACFC,EAAwB,GAGPjH,OAAOgB,KAAK+F,GAChB1N,SAAW4N,QAClB,IAAIvH,gBACRC,YAAUuH,6CAIRlB,EAAoBe,EAAgBI,mCACjBtB,EAAgBuB,gBAAgBpB,mBAAnDC,qBAoBAF,EAAkBF,EAAgBQ,uBACtCU,EAAgBI,oBAEX,IAAItB,EACTC,EACAC,EACAC,EACAC,EACAC,EACA3G,OA1BE2G,OAAezJ,EACf8C,OAAQ9C,mBACPuK,MACCD,EAAgBpJ,OAASwI,gBAAcC,aACnC,IAAI1G,gBAAcC,YAAU0H,8BAGpCnB,EAAea,EAAgBxH,iDAEfyF,EAAeC,WAAW8B,EAAgBxH,0BAAxDA,gJAqBe6H,yBACnBE,UAEuC,iBAA5BA,QACH,IAAI5H,gBACRC,YAAU4H,iDAIRC,EAAuBvE,UAAQoC,eACnCiC,0BAEuB9C,EAAU3F,MAAM2I,mBAAnCvB,MAGoB,IADPjG,OAAOgB,KAAKiF,GAChB5M,aACP,IAAIqG,gBACRC,YAAU8H,uDAIRC,EAAazE,UAAQwC,eAAeQ,EAAWyB,YAC/CC,EAAyB1E,UAAQwC,eACrCQ,EAAW2B,4BAGbjC,YAAUC,gDAAgD8B,GAC1D/B,YAAUC,gDACR+B,GAGK,CACLD,WAAYzB,EAAWyB,WACvBE,oBAAqB3B,EAAW2B,iEC9KjBC,oCAMCC,6DAGIC,MAAIC,SAAS,MAAO,2BAApCC,OACAC,EAAaD,EAAQE,OAAM,SAE1B,CADWF,EAAQE,OAAM,GACbD,4CAIDE,0BAClBC,EACAC,8BAEmBC,iBAAqBF,mBAAlCG,UACOC,EAAMC,eAAeF,GAGZG,yBADWL,GAEjBJ,oDAGGU,4CACnBP,EACAC,8BAE+BT,EAAIO,iBAAiBC,EAAUC,mBAAxDO,0BACgBC,iBAAed,SAAS,CAC5CQ,KAAMK,oBADFZ,OAGAc,EAAiB,IAAID,iBAAeb,0BACdc,EAAeC,OACzC,mBADIpL,0BAGuBmL,EAAeC,OAC1C,mBADIC,SAGC,CAACrL,EAAcqL,qDAQJC,+DAGInB,MAAIC,SAAS,KAAM,6BAAnCC,SAGC,CAFWA,EAAQE,OAAM,GACbF,EAAQE,OAAM,6CAIfgB,wCAClBC,EACAf,EACAC,cAEQc,OACD,mCACIpR,KAAKqR,qCAAqChB,EAAUC,QACxD,iCADItQ,KAEK4Q,mCAAmCP,EAAUC,kBAEnD,IAAIgB,MAAM,2DAIDD,8CACnBhB,EACAC,8BAE+BT,EAAIO,iBAAiBC,EAAUC,mBAAxDO,OACAjL,EAAe2L,OAAUV,EAAkB,OAAOG,MAAM,UAC9DpL,EAAa4L,IAAM,gBACbP,EAAgBM,OAAUV,EAAkB,OAAOG,MAAM,kBAC/DC,EAAcO,IAAM,YACb,CAAC5L,EAAcqL,4CAOVQ,kBAAP,SAAyB5L,WAClBpB,IAARoB,QACI,IAAI6B,gBAAcC,YAAU+J,kBAI9B7J,EAAoB,IAAIzE,IAAI,CAAC,MAAO,MAAO,IAAK,IAAK,YACtD,IAAM0E,KAAYjC,MAChBgC,EAAkBxE,IAAIyE,SACnB,IAAIJ,gBAAcC,YAAUgK,8BAI9B9L,EAAI2L,SACL,aACa,QAAZ3L,EAAI+L,UACA,IAAIlK,gBAAcC,YAAUkK,2BAEf,iBAAVhM,EAAIiM,QACP,IAAIpK,gBAAcC,YAAUoK,oCAGjC,eACa,OAAZlM,EAAI+L,UACA,IAAIlK,gBAAcC,YAAUkK,2BAEf,iBAAVhM,EAAIiM,QACP,IAAIpK,gBAAcC,YAAUoK,6BAEf,iBAAVlM,EAAImM,QACP,IAAItK,gBAAcC,YAAUsK,8CAI9B,IAAIvK,gBAAcC,YAAUuK,4BAQ1BC,uBAAP,SACLjC,OAEMkC,EAAUpK,OAAOqK,OAAO,GAAInC,iBAG3BkC,EAAQE,EAERF,QCnJUG,wBAYCC,MACQ,iBAAfA,QACH,IAAI9K,gBAAcC,YAAU8K,4BAG9BC,EAAQF,EAAW1N,MAAM,QACV,IAAjB4N,EAAMrR,aACF,IAAIqG,gBAAcC,YAAUgL,0BAG9BC,EAAkBF,EAAM,GACxBG,EAAUH,EAAM,GAChBI,EAAYJ,EAAM,GAElBK,EAAiC9H,UAAQ+H,wBAC7CJ,GAEIK,EAAyBrM,KAAKC,MAAMkM,MAEN,IAEX/K,OAAOgB,KAAKiK,GAChB5R,aACb,IAAIqG,gBACRC,YAAUuL,+CAMmB,UAA/BD,EAAuBE,KACQ,WAA/BF,EAAuBE,UAEjB,IAAIzL,gBACRC,YAAUyL,6CAKTnI,UAAQC,kBAAkB4H,SACvB,IAAIpL,gBAAcC,YAAU0L,oCAI/BpI,UAAQC,kBAAkB2H,SACvB,IAAInL,gBAAcC,YAAU2L,6CAGnBV,OACZC,QAAUA,OACVC,UAAYA,6BAMZS,aAAA,kBACEhB,EAAIiB,iBAAiBxT,eAAgBA,KAAK6S,QAAS7S,KAAK8S,cAOpDW,yBAAgBlO,8BACpBgN,EAAIkB,gBACTzT,eAAAA,KACK6S,QADL7S,KAEK8S,UACLvN,0CAQgBkO,yBAClBC,EACAC,EACAb,EACAvN,8BAI6BgN,EAAIqB,iBAD/BF,EAAyB,IAAMC,EAAiB,IAAMb,EAGtDvN,0CASgBqO,0BAClBpB,EACA3M,2DAGkB,YAAZA,EAAI2L,oBACAqC,QAAMC,OAAOtB,EAAY3M,yBACV,cAAZA,EAAI2L,oBACPuC,SAAOD,OAAOtB,EAAY3M,gCAEzB,yEAGFqD,UACPG,QAAQ2K,cACIxB,sCAA8C9K,gBAAcuM,gBACpEtM,YAAUuM,6BACVhL,KAGG,4CAQSiL,0BAClBtB,EACA3C,EACA0C,oDAmBaiB,QAAMO,KAAKvB,EAAS3C,EAAYmE,UAPvCA,OACDzB,GACHO,IAXEP,GAAmBA,EAAgBO,IAC/BP,EAAgBO,IAEC,YAAnBjD,EAAWsB,IACP,QAEA,2BAOa,cAAnBtB,EAAWsB,gCACAuC,SAAOK,KAAKvB,EAAS3C,EAAmBmE,8FAQ3CC,gBAAP,SAAuB9B,UACrB,IAAID,EAAIC,MAMHgB,iBAAP,SACLZ,EACAC,EACAC,UAEOF,EAAkB,IAAMC,EAAU,IAAMC,QCzK9ByB,wBAoBjBzG,EACAC,EACAyG,EACAC,QAEK3G,gBAAkBA,OAClBnI,KAAOwI,gBAAcuG,gBACrB3G,gBAAkBA,OAClByG,cAAgBA,OAChBC,WAAaA,WAMA/F,sCAClBC,WAEMb,EAAkB7J,OAAOC,KAAK0C,KAAKE,UAAU6H,2BAC3B4F,EAAoB3F,YAC1CD,EACAb,GACA,0CAQgBjH,eAClBiH,WAEMe,EAAsBf,EAAgBgB,kCACdtC,EAAU3F,MAAMgI,mBAAxCE,0BAC4BwF,EAAoB3F,YACpDG,EACAjB,GACA,6CAYgBc,qBAClBG,EACAjB,EACAkB,WAEIC,EAAwB,KACxBD,IACFC,EAAwB,GAGPjH,OAAOgB,KAAK+F,GAChB1N,SAAW4N,QAClB,IAAIvH,gBACRC,YAAUgN,gDAI4B,iBAA/B5F,EAAgB6F,iBACnB,IAAIlN,gBACRC,YAAUkN,wDAIRL,EAAgBjC,EAAI+B,gBAAgBvF,EAAgB+F,oCACjCP,EAAoBQ,uBAC3CP,EAAc3B,QACd9D,EAAgB6F,4BAFZH,OAMDzF,GACCD,EAAgBpJ,OAASwI,gBAAcuG,iBACnC,IAAIhN,gBAAcC,YAAUqN,yCAI/B,IAAIT,EACTzG,EACAiB,EAAgB6F,WAChBJ,EACAC,4CAIiBM,gCACnB7H,EACA+H,WAEMC,EAAuBjK,UAAQoC,eAAeH,0BAC3BV,EAAU3F,MAAMqO,mBAAnCT,MAGoB,IADPzM,OAAOgB,KAAKyL,GAChBpT,aACP,IAAIqG,gBACRC,YAAUwN,0DAIVV,EAAWG,aAAeK,QACtB,IAAIvN,gBACRC,YAAUyN,yDAIdvF,EAAI4B,kBAAkBgD,EAAWY,cAE1B,CACLC,UAAWb,EAAWG,WACtBS,aAAcZ,EAAWY,0DCtIVE,wBA0BjBzH,EACAC,EACAyG,EACAC,EACAvG,EACA3G,QAEKuG,gBAAkBA,OAClBnI,KAAOwI,gBAAcqH,aACrBzH,gBAAkBA,OAClByG,cAAgBA,OAChBC,WAAaA,OACbvG,aAAeA,OACf3G,MAAQA,WAMKmH,sCAClBC,WAEMb,EAAkB7J,OAAOC,KAAK0C,KAAKE,UAAU6H,2BAC3B4G,EAAiB3G,YACvCD,EACAb,GACA,0CAQgBjH,eAClBiH,WAEMe,EAAsBf,EAAgBgB,kCACdtC,EAAU3F,MAAMgI,mBAAxCE,0BACyBwG,EAAiB3G,YAC9CG,EACAjB,GACA,6CAYgBc,qBAClBG,EACAjB,EACAkB,WAEIC,EAAwB,KACxBD,IACFC,EAAwB,GAGPjH,OAAOgB,KAAK+F,GAChB1N,SAAW4N,QAClB,IAAIvH,gBACRC,YAAU8N,6CAI4B,iBAA/B1G,EAAgB6F,iBACnB,IAAIlN,gBACRC,YAAU+N,qDAIRlB,EAAgBjC,EAAI+B,gBAAgBvF,EAAgB+F,oCACjCS,EAAiBR,uBACxCP,EAAc3B,yBADV4B,wBAsBC,IAAIc,EACTzH,EACAiB,EAAgB6F,WAChBJ,EACAC,EACAvG,EACA3G,OAvBE2G,OAAezJ,EACf8C,OAAQ9C,mBACPuK,MACCD,EAAgBpJ,OAASwI,gBAAcqH,cACnC,IAAI9N,gBAAcC,YAAUgO,+BAGpCzH,EAAea,EAAgBxH,iDAEfyF,EAAeC,WAAW8B,EAAgBxH,0BAAxDA,gJAkBewN,gCACnBa,WAEMV,EAAuBjK,UAAQoC,eACnCuI,0BAEuBpJ,EAAU3F,MAAMqO,mBAAnCT,MAKoB,IAHPzM,OAAOgB,KAAKyL,GAGhBpT,aACP,IAAIqG,gBACRC,YAAUkO,oDAIdhG,EAAI4B,kBAAkBgD,EAAWY,kBAE3B3F,EAAazE,UAAQwC,eAAegH,EAAW/E,YACrD/B,YAAUC,gDAAgD8B,OAEpDhL,EAA6BuG,UAAQwC,eACzCgH,EAAW7E,4BAEbjC,YAAUC,gDACRlJ,GAGK,CACLgL,WAAY+E,EAAW/E,WACvB2F,aAAcZ,EAAWY,aACzBzF,oBAAqB6E,EAAW7E,iECrLjBkG,wBAODC,EACAC,EACAC,EACAC,EACAC,cAJAJ,yBACAC,wBACAC,yBACAC,4BACAC,WAOEtP,eAAMuP,WACpBC,oBAYAC,2EA8GArT,EAAaC,cAAc8S,SACvB,IAAItO,gBACRC,YAAU4O,kDAIK,IAAIT,EACrBQ,EACAN,EACAC,EACAC,EACAC,OA3BIA,EAA8C,wBACtB1R,IAA1B+R,EAAWC,gBACRpR,MAAMC,QAAQkR,EAAWC,kBACtB,IAAI/O,gBAAcC,YAAU+O,8CAIZF,EAAWC,qBAAxBrP,0BACyBmN,EAAoB7F,6BACpDtH,mBADIuP,GAGNR,EAAqBjU,KAAKyU,GAC1BX,EAAkB9T,KAAKyU,EAAoB5I,yGA7BzCmI,EAAwC,wBACnBzR,IAAvB+R,EAAW3T,aACRwC,MAAMC,QAAQkR,EAAW3T,eACtB,IAAI6E,gBAAcC,YAAUiP,2CAIZJ,EAAW3T,kBAAxBuE,0BACsBmO,EAAiB7G,6BAC9CtH,mBADIyP,GAGNX,EAAkBhU,KAAK2U,GACvBb,EAAkB9T,KAAK2U,EAAiB9I,yGAlFtClG,EAAoB,IAAIzE,IAAI,CAChC,eACA,aACA,uBAEG,IAAM0E,KAAYwO,MAChBzO,EAAkBxE,IAAIyE,SACnB,IAAIJ,gBAAcC,YAAUmP,kCAKnC9O,OAAOtI,UAAUuI,eAAeC,KAAKoO,EAAiB,sBAEjD,IAAI5O,gBAAcC,YAAUoP,kCAG/B/O,OAAOtI,UAAUuI,eAAeC,KAAKoO,EAAiB,oBACnD,IAAI5O,gBAAcC,YAAUqP,wCAIlChP,OAAOtI,UAAUuI,eAAeC,KAAKoO,EAAiB,mBACZ,iBAAnCA,EAAgBW,qBAEjB,IAAIvP,gBAAcC,YAAUuP,2CAKV,iBADPZ,EAAgBa,mBAE3B,IAAIzP,gBAAcC,YAAUyP,oCAG9BC,EAA8B,IAAIjU,IAAI,CAC1C,SACA,UACA,eAEIoT,EAAaF,EAAgBE,eAC9B,IAAM1O,KAAY0O,MAChBa,EAA4BhU,IAAIyE,SAC7B,IAAIJ,gBACRC,YAAU2P,gEACaxP,mDAMvBkO,EAA8B,GAG9BC,EAAsC,wBAClBxR,IAAtB+R,EAAWe,YACRlS,MAAMC,QAAQkR,EAAWe,cACtB,IAAI7P,gBAAcC,YAAU6P,0CAIZhB,EAAWe,iBAAxBnQ,0BACqByG,EAAgBa,6BAC5CtH,mBADIqQ,GAGNxB,EAAiB/T,KAAKuV,GACtBzB,EAAkB9T,KAAKuV,EAAgB1J,gJAtEjBvB,EAAU3F,MAAMwP,sBAAxCC,mBACOjW,SACDqH,gBAAcuM,gBAAgBtM,YAAU+P,kBAAmBrX,kFAd5BwD,EAAWM,WAC9CiS,sBADFC,mBAGOhW,SACDqH,gBAAcuM,gBAClBtM,YAAUgQ,+BACVtX,6FAqIcuX,qBAClBC,EACAC,EACAC,EACAC,EACAC,WAEMhC,EAAmB8B,EAAqBjM,KAAI,SAAC1E,SAC1C,CACL+H,YAAa/H,EAAU4G,sBAIrBkI,EAAoB8B,EAAsBlM,KAAI,SAAC1E,SAC5C,CACLwN,WAAYxN,EAAU2G,gBACtB+G,YAAa1N,EAAUoN,cAAcjB,mBAInC4C,EAAuB8B,EAAyBnM,KAAI,SAAC1E,SAClD,CACLwN,WAAYxN,EAAU2G,gBACtB+G,YAAa1N,EAAUoN,cAAcjB,0CAIjB,CACtB0D,eAAgBY,EAChBV,aAAcW,EACdtB,WAAY,CACVe,OAAQtB,EACRpT,QAASqT,EACTO,WAAYN,2CAUE+B,sBAClBL,EACAC,EACA7B,EACAC,EACAC,8BAE8BL,EAAW8B,YACvCC,EACAC,EACA7B,EACAC,EACAC,mBALIG,OAOA6B,EAAiBvR,KAAKE,UAAUwP,GAChCF,EAAmBnS,OAAOC,KAAKiU,UAE9BtU,EAAWC,SAASsS,+CCjOVgC,wBAQTC,EACAC,EACAC,uBAFAF,kBACAC,iCACAC,qCAL6B,6BAWhCC,0BAAA,iBAEoBxY,UADpByY,8BAA+B,EACpCC,oDAAyBnY,EAAKoY,gEAOzBC,yBAAA,WACLvP,QAAQwP,6CACHJ,8BAA+B,KAMzBE,yCAOW3Y,KANhB8Y,EAAWC,yCAGf1P,QAAQwP,KAAK,wCAIPG,EAAcC,EAAKZ,eAAea,eADpBD,EAAKX,WAAWa,gBAAgBC,6BAG9CJ,EAAYK,0CACXnQ,GACPG,QAAQH,MACN,6EAEFG,QAAQH,MAAMA,0BAEdG,QAAQwP,qCAAqCC,EAASQ,kBAElDL,EAAKR,+BACPpP,QAAQwP,oBACSI,EAAKV,oEAEtBgB,kDACcN,EAAKN,4DACgB,IAAjCM,EAAKV,2JC/CMiB,oCAKC3S,eAAM4S,aAmBxBzZ,KAlBM8Y,EAAWC,2BACyBlV,EAAWM,WACnDsV,mBADIC,0BAGwBlN,EAAU3F,MAAM6S,mBAAxCC,GACNtQ,QAAQwP,6BAA6BC,EAASQ,sBAGxCzR,EAAoB,IAAIzE,IAAI,CAAC,eAC9B,IAAM0E,KAAY6R,MAChB9R,EAAkBxE,IAAIyE,SACnB,IAAIJ,gBACRC,YAAUiS,mDACa9R,8BAKxB+R,uBAAuBF,EAAgBG,QAErCH,8CAGME,uBAAP,SAA8BC,QAE9BA,aAAkBzU,aAChB,IAAIqC,gBACRC,YAAUoS,gCACV,sEAKuBD,kBAAQ,KAAxB5L,aACmB,iBAAjBA,QACH,IAAIxG,gBACRC,YAAUqS,iCACV,uEAIEC,EAAchW,OAAOC,KAAKgK,MAG5B+L,EAAY5Y,OAAS6Y,qBAAmBC,0BACpC,IAAIzS,gBACRC,YAAUyS,oDACWH,EAAY5Y,8CAA6C6Y,qBAAmBC,mCASrFjC,sBAClBjC,EACAC,EACAmE,WAEMP,EAAS,GACfA,EAAO5X,WAAP4X,EACK7D,EAAiBnK,KAAI,SAAC1E,UAAcA,EAAU8G,iBAEnD4L,EAAO5X,WAAP4X,EACK5D,EAAkBpK,KAAI,SAAC1E,UAAcA,EAAU8G,iBAEpD4L,EAAO5X,WAAP4X,EACKO,EAAiBvO,KAAI,SAAC1E,UAAcA,EAAU8G,qBAO7CoM,EAAUrW,OAAOC,KAAK0C,KAAKE,UAJV,CACrBgT,OAAAA,4BAI8BjW,EAAWC,SAASG,OAAOC,KAAKoW,8CC1D/CC,wBASOC,EAAwCC,+BAAxCD,WAAwCC,wBARvB,wBACU,IAAI5O,4BACF,IAAIA,IAQrD6O,MAAMF,KAERnR,QAAQwP,gFAGH2B,uBAJiC,+BAanCG,MAAA,iBAoDoB3a,mBAjDjB4a,EAA2B,OACY5a,KAAK6a,gCAAiB,eAAvDC,OAAgBC,OACtBA,EAAaC,iBACVC,mBAAmBlP,IACtB+O,EACAC,EAAaG,aAEfN,EAAyB1Y,KAAK4Y,GAG9BC,EAAanO,yBAGYgO,sBACtBC,iCAIDM,EACJnb,KAAKwa,uBAAyBxa,KAAK6a,gBAAgBO,QACjDD,GAA0B,YAKO,IAAjCnb,KAAKqb,iBAAiBha,kBAMxB,IAAIF,EAAI,EACRA,EAAInB,KAAKqb,iBAAiBha,QAAUF,EAAIga,EACxCha,IACA,KACM4Z,EAAe/a,KAAKqb,iBAAiBla,GAGtCnB,KAAKsb,cAAcP,QACnBF,gBAAgB9O,IAAIgP,EAAaQ,OAAQR,QAI3CM,iBAAiBG,OAAO,EAAGL,GAChC,MAAOjS,GACPG,QAAQH,8FACkFA,WAG1FqQ,kDAAuBhZ,EAAKoa,8CAAS,SAQ5Bc,kBACXC,EACAC,aAYE3b,KAVIub,EAASK,cAAmB,IAC5BC,EAAe,IAAIlP,SAAQ,SAACC,KAS3ByO,iBAAiBnZ,KARD,CACnBqZ,OAAAA,EACAG,YAAAA,EACAC,eAAAA,EACA/O,QAAAA,EACAoO,WAAW,EACXc,aAASrX,8BAKPoX,wBAEAX,EAAcjC,EAAKgC,mBAAmB/O,IAAIqP,YAC3CN,0BAA0BM,GAExBL,2CAUKI,uBAAcP,aAKE/a,KAJxB0b,EAAc,+CAEhBA,EAAcX,EAAaW,4BAEDK,EAAKtB,IAAIuB,KACjCN,mBADIR,GAKNH,EAAaG,YAAcA,iBACpBhS,GACPG,QAAQH,6CACiCwS,2BAAoCxS,+BAG7E6R,EAAaC,WAAY,iICxJViB,wBA0BjBnO,EACAC,EACAyG,EACAC,EACAvG,EACA3G,QAEKuG,gBAAkBA,OAClBnI,KAAOwI,gBAAc+N,YACrBnO,gBAAkBA,OAClByG,cAAgBA,OAChBC,WAAaA,OACbvG,aAAeA,OACf3G,MAAQA,WAMK4U,mCAClBxN,WAEMb,EAAkB7J,OAAOC,KAAK0C,KAAKE,UAAU6H,2BAC3BsN,EAAgBrN,YACtCD,EACAb,GACA,0CAQgBjH,eAAMiH,WAClBe,EAAsBf,EAAgBgB,kCACdtC,EAAU3F,MAAMgI,mBAAxCE,0BACwBkN,EAAgBrN,YAC5CG,EACAjB,GACA,6CAYgBc,qBAClBG,EACAjB,EACAsO,WAEInN,EAAwB,KACxBmN,IACFnN,EAAwB,GAGPjH,OAAOgB,KAAK+F,GAChB1N,SAAW4N,QAClB,IAAIvH,gBACRC,YAAU0U,4CAI4B,iBAA/BtN,EAAgB6F,iBACnB,IAAIlN,gBAAcC,YAAU2U,2CAG9B7H,EAAalC,EAAI+B,gBAAgBvF,EAAgB+F,oCACzBmH,EAAgBlH,uBAC5CN,EAAW5B,yBADP0J,wBAgBC,IAAIN,EACTnO,EACAiB,EAAgB6F,WAChBH,EACA8H,EACArO,EACA3G,OAjBE2G,OAAezJ,EACf8C,OAAQ9C,mBACP2X,MACCrN,EAAgBpJ,OAASwI,gBAAc+N,aACnC,IAAIxU,gBAAcC,YAAU6U,qCAGpCtO,EAAea,EAAgBxH,sBACjByF,EAAeC,WAAWiB,sBAAxC3G,mFAaiBwN,gCACnBa,WAEMV,EAAuBjK,UAAQoC,eACnCuI,0BAEuBpJ,EAAU3F,MAAMqO,mBAAnCT,MAGoB,IADPzM,OAAOgB,KAAKyL,GAChBpT,aACP,IAAIqG,gBACRC,YAAU8U,sDAId5M,EAAI4B,kBAAkBgD,EAAWiI,gBAE3BhN,EAAazE,UAAQwC,eAAegH,EAAW/E,mBACrD/B,YAAUC,gDAAgD8B,GAEnD,CACLA,WAAY+E,EAAW/E,WACvBgN,WAAYjI,EAAWiI,wDClKRC,wBAOD5G,EACAC,EACAqE,cAFAtE,yBACAC,wBACAqE,WAOExT,eAAM+V,WACpBC,oBAUAC,kCAOEjV,EAAoB,IAAIzE,IAAI,CAAC,SAAU,mBACxC,IAAM0E,KAAYgV,MAChBjV,EAAkBxE,IAAIyE,SACnB,IAAIJ,gBAAcC,YAAUoV,kCAItCJ,EAAQK,uBAAuBF,EAAaG,wBAEbN,EAAQO,wBACrCJ,EAAatG,4BADT6D,OAGArE,EAAoBqE,EAAiBvO,KACzC,SAAC1E,UAAcA,EAAU2G,0BAGX,IAAI4O,EAClBG,EACA9G,EACAqE,iDAxBqB7N,EAAU3F,MAAMgW,sBAArCC,mBACO5T,SACDxB,gBAAcuM,gBAAgBtM,YAAUwV,eAAgBjU,kFAZnCrF,EAAWM,WAAWyY,sBAAjDC,mBACO3T,SACDxB,gBAAcuM,gBAClBtM,YAAUyV,4BACVlU,6FAsCegU,iCACnB1G,4BA2BMR,EAAoBqE,EAAiBvO,KACzC,SAAC1E,UAAcA,EAAU2G,sBAEvB9K,EAAaC,cAAc8S,SACvB,IAAItO,gBAAcC,YAAU0V,+CAG7BhD,WAhCY5V,IAAf+R,yBACK,OAIiB,IADPxO,OAAOgB,KAAKwN,GAChBnV,aACP,IAAIqG,gBACRC,YAAU2V,0DAIRjD,EAAsC,OACvChV,MAAMC,QAAQkR,EAAWnU,cACtB,IAAIqF,gBAAcC,YAAU4V,yCAIZ/G,EAAWnU,iBAAxB+E,0BACqB6U,EAAgBE,0BAC5C/U,mBADIoW,GAGNnD,EAAiBnY,KAAKsb,+FAiBXR,uBAAP,SAA8BC,OAC/B5X,MAAMC,QAAQ2X,SACX,IAAIvV,gBACRC,YAAU8V,gDAKQ,IAAlBR,EAAO5b,aACH,IAAIqG,gBACRC,YAAU+V,sDAMY,IADP1V,OAAOgB,KADZiU,EAAO,IAEN5b,aACP,IAAIqG,gBACRC,YAAUgW,4CAQIzF,sBAClB0F,EACAC,WAEMxD,EAAmBwD,EAAqB/R,KAAI,SAAC1E,SAC1C,CACLwN,WAAYxN,EAAU2G,gBACtB+G,YAAa1N,EAAUoN,cAAcjB,mBAInCuJ,EAA6B,CACjCG,OAAQ,CAAC,CAAEa,eAAgBF,KAIzBvD,EAAiBhZ,OAAS,IAC5Byb,EAAatG,WAAa,CACxBnU,OAAQgY,QAINC,EAAU1T,KAAKE,UAAUgW,0BACCjZ,EAAWC,SAASG,OAAOC,KAAKoW,8CC3J/CyD,wBACC1F,uBAAAA,qBAMP2F,kCAAyBC,mBAiBNje,KAhB1Bke,OAA6CzZ,EAC3C0Z,EAA6D,OAEzCF,kBAAc,KAA7BG,UAELA,EAAYC,kBAAoBH,IAClCC,EAAqCjc,KAAK,IAC1Cgc,EAAyBE,EAAYC,iBAEvCF,EACEA,EAAqC9c,OAAS,GAC9Ca,KAAKkc,OAGHE,EAA4C,OACnBH,YAApBI,OACHC,EAAsBC,EAAKpG,eAAeqG,uBAC9CH,EAAiB,GAAGF,wCAE4BG,EAAoBG,4BACpEJ,mBADIK,GAGNN,EAAsBpc,WAAtBoc,EAA8BM,oEAEzBN,KAAAA,4CClBUO,wBAoBTxG,EACAC,EACAkC,EACAsE,EACAC,EACAC,EACAC,uBANA5G,kBACAC,8BACAkC,sBACAsE,wBACAC,oCACAC,kCACAC,mCArB2B,mCAKoC,QAkBlEC,kBAAoB,IAAInB,EAAkB1F,8BAGpC8G,iDACXnf,4BAAkCye,EAAKM,iBAAiBK,0CAAnDC,gEAMMC,6CAELtf,4BAAAuf,EAAKJ,gDAEX9V,QAAQwP,mDACRH,sCACO8G,4BAA6B,IAG7BC,uHAQFC,uBAAA,WACLrW,QAAQwP,uDACH2G,4BAA6B,KAOvBC,6BACXE,YAAAA,IAAAA,GAA6B,aAGrB3f,sFAAA4f,EAAKC,+FA6HLD,EAAKC,iEACXxW,QAAQwP,KACN,oGAII+G,EAAKE,gCAAgCH,gCA/HvCI,GAAmB,IlBwOtB,SAAa/e,EAAMoB,GACzB,IAAI4d,EACJ,EAAG,CACF,IAAIlgB,EAASkB,IACb,GAAIlB,GAAUA,EAAOH,KAAM,CAC1B,IAAIiB,EAAed,GAEZ,CACNkgB,GAAY,EACZ,MAHAlgB,EAASA,EAAOM,EAMlB,IAAImC,EAAiBH,IAIrB,GAHIxB,EAAe2B,KAClBA,EAAiBA,EAAenC,IAE5BmC,EACJ,OAAOzC,SAECyC,EAAe5C,MACzB,MAAMc,EAAO,IAAIhB,EACXyB,EAASf,EAAQO,KAAK,KAAMD,EAAM,GAExC,OADCuf,EAAYlgB,EAAOH,KAAK+C,GAAoBH,EAAe5C,KAAK8C,IAAmB9C,UAAK,EAAQuB,GAC1FT,EACP,SAASiC,EAAiBlC,GAEzB,IADAV,EAASU,EAGJI,EADJ2B,EAAiBH,OAEhBG,EAAiBA,EAAenC,GAE5BmC,GALG,CAQR,GAAIA,EAAe5C,KAElB,YADA4C,EAAe5C,KAAK8C,GAAkB9C,UAAK,EAAQuB,GAIpD,IADApB,EAASkB,MACKlB,EAAOH,KAAM,CAC1B,IAAIiB,EAAed,GAIlB,YADAA,EAAOH,KAAK+C,GAAkB/C,UAAK,EAAQuB,GAF3CpB,EAASA,EAAOM,GAOnBD,EAAQM,EAAM,EAAGX,GAElB,SAAS2C,EAAiBF,GACzB,GAAIA,EAAgB,CACnB,EAAG,CAEF,IADAzC,EAASkB,MACKlB,EAAOH,KAAM,CAC1B,IAAIiB,EAAed,GAIlB,YADAA,EAAOH,KAAK+C,GAAkB/C,UAAK,EAAQuB,GAF3CpB,EAASA,EAAOM,EAUlB,GAHIQ,EADJ2B,EAAiBH,OAEhBG,EAAiBA,EAAenC,IAE5BmC,EAEJ,YADApC,EAAQM,EAAM,EAAGX,UAGTyC,EAAe5C,MACzB4C,EAAe5C,KAAK8C,GAAkB9C,UAAK,EAAQuB,QAEnDf,EAAQM,EAAM,EAAGX,mCkBlQNme,EAAegC,EAAaA,EAAWhC,aAAe,UAC5D8B,IAAmBE,GAAaA,EAAWF,iCACTH,EAAKV,kBAAkBlB,yBACvDC,mBADEK,6BAmEAL,GAAgBA,EAAa5c,OAAS,MACnCge,qBAAuBpB,EAAaA,EAAa5c,OAAS,QAtC7D6e,GAA8B,EAC9BC,IAEAC,GAA4BR,EAAKtH,WAAWa,gBAAgBC,MAE5D8G,GAA8B,EAC9BH,GAAmB,GAEnB1W,QAAQwP,iJAQRqH,GACF7W,QAAQwP,uDACF+G,EAAKS,2DACT,4BAGFhX,QAAQwP,0DACF+G,EAAKU,8CACXjX,QAAQwP,yEAMF+G,EAAKS,2DACTT,EAAKpF,qFA1DT8D,EAAwBA,EAAsBiC,MAC5C,SACEC,EACAC,UAEOD,EAAEE,kBAAoBD,EAAEC,+BAKxBtC,OACHuC,EAAsB,CAC1BvC,YAAaA,EACbwC,iBAAkBC,8BAA4BC,WAE3CC,4BAA4B7e,KAAKye,uBAClChB,yBACIC,EAAKoB,mBAAmB5C,EAAauC,yBAGtCf,EAAKoB,mBAAmB5C,EAAauC,0FA1D1CV,EAXEgB,EAA6BrB,EAAKP,qBACpCO,EAAKP,qBAAqBqB,uBAC1Bjc,EACEyc,EAA+BtB,EAAKP,qBACtCO,EAAKP,qBAAqB8B,yBAC1B1c,EACE2b,EAA2BR,EAAKP,qBAClCO,EAAKP,qBAAqBhB,gBAC1B,EAEA8B,GAAqC,EAEnCrH,EAAWC,2BAEf1P,QAAQwP,KACN,6EAMiB+G,EAAKtH,WAAW0D,UAHFvX,IAA/Bwc,EACIA,EAA6B,OAC7Bxc,EAGJyc,sBAFFjB,IAIA5W,QAAQwP,gBAEJoH,EAAWhC,aAAa5c,4DAC2ByX,EAASQ,iCAEzDpQ,QAELA,aAAiBxB,iBACjBwB,EAAMkY,OAASC,kBAAgBC,0CAOzBpY,EALNG,QAAQwP,mCACwBoI,mBAA2CC,mCAE3Ef,GAAqC,0DA8ElCJ,mDASF7W,GACPG,QAAQH,4FAGRG,QAAQH,MAAMA,0BAEV0W,EAAKJ,6BACPnW,QAAQwP,oBACS+G,EAAKX,0FAEtB1F,kDACcqG,EAAKH,4DACiB,IAAlCG,EAAKX,0FAMCoB,oEACZkB,aAEOvhB,4BAAAwhB,EAAKT,4BAA4B1f,OAASkgB,8CAEzCC,EAAK3B,iFAGL,IAAIlT,SAAQ,SAACC,UAAY2M,WAAW3M,EAAS,0IAUzCkT,yCACZH,YAAAA,IAAAA,GAA6B,aAGU3f,KADjC8Y,EAAWC,2BACsB0I,EAAKzC,6BAA6B0C,yDAAnEC,2CAyBCC,EAA8BvgB,OAAS,+BAExCF,EAAI,EAENA,EAAIygB,EAA8BvgB,QAClCugB,EAA8BzgB,GAAGyf,mBAC/BC,8BAA4BgB,WAE9B1gB,WAIFygB,EAA8BpG,OAAO,EAAGra,mBAGlC,IAAIwL,SAAQ,SAACC,UAAY2M,WAAW3M,EAAS,4EAvCrDvD,QAAQwP,gBAEJ8I,EAAyBtgB,iDACeyX,EAASQ,sBAI/CsI,EAAgC,OACZD,YAAfvD,OACHuC,EAAsB,CAC1BvC,YAAaA,EACbwC,iBAAkBC,8BAA4BC,SAEhDc,EAA8B1f,KAAKye,uBAE/BhB,yBACI8B,EAAKT,mBAAmB5C,EAAauC,yBAGtCc,EAAKT,mBAAmB5C,EAAauC,4HA4BlCd,wEAcPkB,4BAA4BvF,OAAO,EAAGra,MAXrCnB,KAFFmB,EAAI,yBAENA,EAAI2gB,EAAKf,4BAA4B1f,QACrCygB,EAAKf,4BAA4B5f,GAAGyf,mBAClCC,8BAA4BgB,sDAExBC,EAAK/C,iBAAiBgD,eAC1BD,EAAKf,4BAA4B5f,GAAGid,+BAEtCjd,gGAYU6f,4BACZ5C,EACA4D,WAEIC,IAGkDjiB,8CAA9CkiB,EAA8CC,EAAK9J,eAAe+J,wBACtEhE,EAAYC,wCAE2B6D,EAAqBlB,mBAC5D5C,sBADF6D,mBAGO/Y,GACPG,QAAQH,6DACiDkV,EAAYsC,wBAErErX,QAAQH,MAAMA,GACd+Y,GAAmC,yDAGnC5Y,QAAQwP,yCAC8BuF,EAAYsC,wBAElDsB,EAA2BpB,iBACzBC,8BAA4BgB,gBAE1BI,GACF5Y,QAAQwP,8BACmBuF,EAAYsC,mFAEjCyB,EAAKnD,6BAA6BqD,8BACtCjE,2BAGF/U,QAAQwP,6DACkDuF,EAAYsC,0CAEhEyB,EAAKnD,6BAA6BsD,0CACtClE,kKASMkC,+CAEkCtgB,4BAAAuiB,EAAKxD,iBAAiByD,qDAA9DC,0BAGwCF,EAAKjK,WAAWoK,yBAC5DD,mBADIE,OAIAC,OACgCne,IAApCke,OACIle,EACAke,EAAgCjC,yBACtCrX,QAAQwP,6CACkC+J,GAI1CvZ,QAAQwP,KAAK,2CACP0J,EAAKzD,sBAAsB8D,4CAG3BL,EAAKxD,iBAAiB8D,4BAC1BD,4CAEIL,EAAKvD,6BAA6B8D,wCACtCF,uBAIGvD,qBAAuBsD,0DCzYXI,oCAOClc,eAAMiH,WAElBe,EAAsBf,EAAgBgB,WACtCC,EAAkBnI,KAAKC,MAAMgI,GAC7BmU,EAAgBjU,EAAgBpJ,QAGlCqd,IAAkB7U,gBAAcC,8BAC3BP,EAAgBe,YACrBG,EACAjB,GALqB,IAQlB,GAAIkV,IAAkB7U,gBAAc+N,8BAClCD,EAAgBrN,YACrBG,EACAjB,GAXqB,IAclB,GAAIkV,IAAkB7U,gBAAcqH,+BAClCD,EAAiB3G,YACtBG,EACAjB,GAjBqB,IAoBlB,GAAIkV,IAAkB7U,gBAAcuG,kCAClCH,EAAoB3F,YACzBG,EACAjB,GAvBqB,UA2BjB,IAAIpG,gBAAcC,YAAUsb,wEArCfF,8BAA8B,OCgClCG,oCAILC,mBAAP,eACCC,EAAexH,cAAmB,WACrB3Q,UAAQwD,OAAOd,YAAUa,KAAK4U,OAU/BC,yBAClB7d,EACAO,8BAEsC8J,EAAIC,gDAAxBI,aAQX,CAPgB,CACrB1K,GAAAA,EACAG,KAAM,6BACNE,SACAE,QAASA,GAAWiC,OAAO/F,OAAO+D,qBAGZkK,4CAMNoT,yCAClB3U,8BAEkCuU,EAAmBK,0CAA/CC,SAWC,CACL/L,gBAAiB+L,EAAoB/L,gBACrCgM,iBAAkBD,EAAoBC,iBACtCC,uBAZ6B,CAC7B/d,KAAMwI,gBAAcC,OACpBL,gBAAiByV,EAAoB/L,gBAAgB1J,gBACrDD,gBAAiB0V,EAAoB/L,gBAAgB3J,gBACrD4S,kBAAmB/R,EAAM+R,kBACzBrC,gBAAiB1P,EAAM0P,gBACvBsF,eAAgBhV,EAAMgV,gBAOtBC,kBAAmBJ,EAAoBI,kBACvCC,mBAAoBL,EAAoBK,mBACxCC,gBAAiBN,EAAoBM,gBACrCC,iBAAkBP,EAAoBO,iBACtCC,iBAAkBR,EAAoBQ,iBACtCC,kBAAmBT,EAAoBS,kBACvCC,mCACEV,EAAoBU,6EAONX,8DAKR1T,EAAIC,gDAFZ8T,OACAC,8BAKQhU,EAAIC,gDAFZgU,OACAC,8BAKQb,EAAmBG,gBAZR,qCAUnBW,OACAC,OAEItd,EAAUuc,EAAmBiB,yBAAyB,CAC1D,gDAG6BjB,EAAmBkB,+BAChDR,EACAE,EACA,CAACE,GACDrd,mBAJI8c,OAOA3V,EAAkB7J,OAAOC,KAAK0C,KAAKE,UAAU2c,2BAErB5V,EAAgBhH,MAAMiH,mBAA9C2J,OAEAyM,EAAqCvW,YAAU0W,+BACnDL,EAAiBne,WAEZ,CACL4R,gBAAAA,EACAgM,iBAAAA,EACAG,kBAAAA,EACAC,mBAAAA,EACAC,gBAAAA,EACAC,iBAAAA,EACAC,iBAAAA,EACAC,kBAAAA,EACAC,mCAAAA,wDAOgBI,kCAClB3V,8BAMUkB,EAAIC,gDAFZyU,OACAC,8BAKQtB,EAAmBG,gBARL,wCAMtBoB,OACAC,8BAEsCxB,EAAmBG,gBACzD,iCADKsB,OAGDC,EAAW1B,EAAmBiB,yBAAyB,CAC3D,gDAOQjB,EAAmBG,gBAAgB,qCAF3C3G,OACAqH,8BAG0Bb,EAAmB2B,gCAC7ClW,EAAMZ,gBACNY,EAAMkV,mBACNU,EACAE,EACAG,EACA,CAACD,oBANGG,OASAhX,EAAkB7J,OAAOC,KAAK0C,KAAKE,UAAUge,2BACpBvP,EAAiB1O,MAAMiH,mBAAhD+I,SAEC,CACLA,iBAAAA,EACA/I,gBAAAA,EACA8V,kBAAmBW,EACnBV,mBAAoBW,EACpBR,iBAAkBS,EAClBR,kBAAmBS,EACnBhI,WAAAA,EACAqH,iBAAAA,2DAOgBgB,iCAClBhX,EACA+V,EACAC,8BAMUb,EAAmBG,yDAF3B2B,OACAC,8BAG0B/B,EAAmBgC,0CAC7CnX,EACA+V,EACAC,EACAiB,EACArX,YAAU0W,+BAA+BW,oBALrCF,OAQAhX,EAAkB7J,OAAOC,KAAK0C,KAAKE,UAAUge,2BACrB7I,EAAgBpV,MAAMiH,mBAA9C0P,SAEC,CACLA,gBAAAA,EACA1P,gBAAAA,EACAqX,iCACAH,oBAAAA,EACAC,qBAAAA,EACAG,cAAeJ,EAAoBnf,oDAOzBwf,+CAAP,SACLC,EACAjH,EACAqC,EACAiD,SAEuD,CACrD5V,gBAAiBuX,EAAevX,gBAChCpI,KAAM2f,EAAe3f,KACrBmI,gBAAiBwX,EAAexX,gBAChC6V,eAAAA,EACAjD,kBAAAA,EACArC,gBAAAA,MAQgB+F,wCAClBR,EACAE,EACAyB,EACAhf,WAOMiB,EAAU,CACd,CACEiB,OAAQ,UACR7D,SAR4B,CAC9BQ,YAAamgB,EACbhf,kBAAAA,KAUIgB,EAAQ,CACZmG,kBAAmBC,YAAU0W,+BAC3BP,GAEFtc,QAAAA,GAGIyS,EAAchW,OAAOC,KAAK0C,KAAKE,UAAUS,IAGzC0G,EAAa,CACjByB,WAHiBzE,UAAQwD,OAAOd,YAAUa,KAAKyL,IAI/CrK,oBAAqBjC,YAAU0W,+BAC7BT,IAIEtU,EAA0BrE,UAAQwD,OAAO7H,KAAKE,UAAUmH,IACxDf,EAAqBjC,UAAQwD,OAAOwL,0BACxB,CAChBtU,KAAMwI,gBAAcC,OACpBe,YAAaG,EACb/H,MAAO2F,0CASSsY,wCAA+BzX,mBACzBtJ,IAApBsJ,IACFA,EAAkBmV,EAAmBC,sCAETD,EAAmBG,gBAC/C,wCAEInc,EAA2ByG,YAAU0W,oCAC3Bxe,4BAGiBqd,EAAmBG,gBADnB,oCAI3B7b,EAAU,CACd,CACEiB,OAAQ,kBACRrD,YAAa,gCAOP8d,EAAmBG,gBAJR,6DAKCH,EAAmBuC,6BACvC1X,OACiBlI,SAEjBqB,EACAM,mBALIke,OAQAC,EAAS1hB,OAAOC,KAAK0C,KAAKE,UAAU4e,2BACZzJ,EAAgBpV,MAAM8e,mBAA9CnI,SAEC,CACLkI,QAAAA,EACAC,OAAAA,EACAnI,gBAAAA,wDAOgBiI,sCAClB1X,EACA+V,EACAC,EACA7c,EACAM,WAMM4F,EAAkBxG,KAAKE,UAJf,CACZU,QAAAA,EACAkG,kBAAmBxG,IAGfwI,EAAazE,UAAQwD,OACzBd,YAAUa,KAAKvK,OAAOC,KAAKkJ,KAEvBwY,EAAqB3a,UAAQwD,OAAOrB,0BAMjB8V,EAAmB2C,iBAJZ,CAC9BnJ,WAAYoH,EACZpU,WAAYA,GAIZqU,mBAFItP,SAKyB,CAC7B9O,KAAMwI,gBAAc+N,OACpBtH,WAAY7G,EACZxG,MAAOqe,EACP9Q,YAAaL,4CASGoQ,yCAClB9W,EACA8V,EACAU,EACAE,EACAle,EACAnB,WAEMR,EAAW,CACfQ,YAAaA,EACbmB,kBAAmBA,0BAEU2c,EAAmB4C,8BAChD/X,EACA8V,EACAU,EACA5W,YAAU0W,+BAA+BI,EAAoB5e,KAC7DjB,0CAQgBkhB,uCAClB/X,EACA8V,EACAU,EACArd,EACAtC,WAcMqV,EAAchW,OAAOC,KAAK0C,KAAKE,UALvB,CACZU,QARc,CACd,CACEiB,OAAQ,UACR7D,SAAAA,IAMF8I,kBAAmBxG,KAMf6e,EAA0B,CAC9BrW,WAHiBzE,UAAQwD,OAAOd,YAAUa,KAAKyL,IAI/C5E,aAAcxF,EAAIsC,uBAChB0R,GAEFjU,oBAAqBjC,YAAU0W,+BAC7BE,2BAGqBrB,EAAmB2C,iBAC1CE,EACAlC,mBAFIpP,OAKAvH,EAAqBjC,UAAQwD,OAAOwL,SACxB,CAChBtU,KAAMwI,gBAAcqH,QACpBZ,WAAY7G,EACZ+G,YAAaL,EACblN,MAAO2F,4CASS8Y,0CAClBjY,EACA8V,WAEMkC,EAA0B,CAC9BnR,WAAY7G,EACZsH,aAAcxF,EAAIsC,uBAChB0R,2BAGqBX,EAAmB2C,iBAC1CE,EACAlC,mBAFIpP,SAKY,CAChB9O,KAAMwI,gBAAcuG,WACpBE,WAAY7G,EACZ+G,YAAaL,4CAWGwR,uCAClBrC,EACAI,EACAzd,8BAEwB2c,EAAmBkB,+BACzCR,EACAI,EAAiBne,IACjB,CAACme,GACDzd,mBAJIa,UAOCnD,OAAOC,KAAK0C,KAAKE,UAAUM,6CAMhB8d,mDAClBnX,EACA+V,EACAC,EACAmC,EACAhf,8BASqCgc,EAAmBuC,6BACtD1X,EACA+V,EACAC,EACA7c,EAXc,CACd,CACEuB,OAAQ,kBACRrD,YAAa,CAAC8gB,6CAkBAC,qDAClBpY,EACA+V,EACAC,EACA7c,EACAkf,EACAC,WAEM7e,EAAU,WAEiB/C,IAA7B2hB,EAAwC,KACpC5d,EAAQ,CACZC,OAAQ,wBACRlC,kBAAmB2c,EAAmBiB,yBAAyB,CAC7DiC,KAIJ5e,EAAQtF,KAAKsG,UAGX6d,EAA6BhlB,OAAS,GAMxCmG,EAAQtF,KALM,CACZuG,OAAQ,2BACR4B,IAAKgc,oBAM4BnD,EAAmBuC,6BACtD1X,EACA+V,EACAC,EACA7c,EACAM,0CASgBqe,0BAClBhT,EACA3C,8BAMyBqC,EAAI4B,iBAC3BtB,EACA3C,EANsB,CACtBiD,IAAK,iDAcWmT,mCAClBvY,EACA8V,8BAE+BX,EAAmB8C,iCAChDjY,EACA8V,mBAFIJ,OAIA3V,EAAkB7J,OAAOC,KAAK0C,KAAKE,UAAU2c,2BACjBlP,EAAoB1N,MACpDiH,mBADI6I,SAIC,CACL8M,iBAAAA,EACA3V,gBAAAA,EACA6I,oBAAAA,+CAQUwN,yBAAP,SAAgC9Z,aAC/B9D,EAAoB,OACT8D,kBACf9D,EAAkBrE,KAAK,CACrBsD,WACAG,KAAM,WACNc,SAAU,+BAGPF,QC5nBUggB,wBAETlO,EACAyG,uBADAzG,sBACAyG,6BAQGlS,iBAAQmB,aAGM/N,YAFzBqJ,QAAQwP,qCAAqC9K,0BAEpB0Q,EAAKK,eAAe5S,IAAI6B,mBAA3CyI,OACAgQ,EAAmBD,EAASE,2BAA2BjQ,0BAGxCiI,EAAKiI,qBACxBF,EAAiBvQ,kCADf1R,WAKaE,IAAbF,OAKEoiB,EAAiCH,EAAiBtQ,kBAAkB0Q,OACxEJ,EAAiBrQ,6CAE6BsI,EAAKoI,yCACnDF,mBADIG,0BAGWrI,EAAKsI,oCACpBxiB,EACAuiB,kCAI0CriB,KAN5CF,KAMaG,2BACJH,kBAIqCka,EAAKoI,yCACjDL,EAAiBnM,kCADb2M,0BAGWvI,EAAKwI,sBACpB1iB,EACAyiB,6BAFFziB,6DAQakiB,2BAAP,SACNjQ,aAOMP,EAAmB,GACnBC,EAAoB,GACpBmE,EAAmB,GACnBlE,EAAuB,OAELK,kBAAY,KAAzBpP,UACLA,EAAUzB,OAASwI,gBAAcC,OACnC6H,EAAiB/T,KAAKkF,GACbA,EAAUzB,OAASwI,gBAAcqH,QAC1CU,EAAkBhU,KAAKkF,GACdA,EAAUzB,OAASwI,gBAAc+N,OAC1C7B,EAAiBnY,KAAKkF,GAGtB+O,EAAqBjU,KAAKkF,SAGvB,CACL6O,iBAAAA,EACAC,kBAAAA,EACAmE,iBAAAA,EACAlE,qBAAAA,MAOUuQ,8BACZzQ,WAEI1R,SAGevE,SADWiW,YAAnBwB,0BACQ8H,EAAK2H,eAAezP,OAAiBhT,2BAGrCA,KAHjBF,qGAQKA,KAAAA,yCAMKwiB,6CACZI,EACAC,uBAkBwBpnB,KAhBpBuE,EAAW4iB,iCAGbC,EAA0B/jB,IAAIkB,EAASG,sDAEnC2iB,EAA6DD,EAA0Blb,IACzF3H,EAASG,mCAIX2iB,EAAmCA,EAAiC9G,MAClE,SAACC,EAAGC,UAAMD,EAAEE,kBAAoBD,EAAEC,qCAKdd,EAAK0H,yBACzBD,EACA9iB,mBAJIgjB,WAQc9iB,IAAhB8iB,cAQwC9iB,KAH5CF,EAAWgjB,GAGE7iB,iCACJH,qFAIJA,SAAAA,yCAMK0iB,+BACZE,EACAC,kBAgBwBpnB,KAdpBuE,EAAW4iB,8BAERC,EAA0B/jB,IAAIkB,EAAS2C,mDACxCmgB,EAA6DD,EAA0Blb,IACzF3H,EAAS2C,iCAIXmgB,EAAmCA,EAAiC9G,MAClE,SAACC,EAAGC,UAAMD,EAAEE,kBAAoBD,EAAEC,qCAKdc,EAAK8F,yBACzBD,EACA9iB,mBAJIgjB,QAQc9iB,IAAhB8iB,EAKJhjB,EAAWgjB,wEAGNhjB,KAAAA,yCASK2iB,wBACZ9f,EACA7C,aAM6BvE,KAJzBwnB,EAAkBjjB,sBAIdkjB,EAAqBhG,EAAKpJ,eAAeqP,sBAC7CtgB,EAAUiX,wCAGYoJ,EAAmBE,MACzCvgB,EACAogB,sBAFFA,mBAIOte,GACPG,QAAQ2K,qCAC2B5M,EAAU2G,4BACzC3G,EAAUiX,4BACA3W,gBAAcZ,UAAUoC,kEAIjCse,KAAAA,yCAMKF,kCACZ9Q,EACAoR,kBAMuB5nB,KAJnBunB,EAAcK,MAGMpR,YAAbpP,0BACY0a,EAAKoF,eAAe9f,EAAWmgB,0BAApDA,KAIcM,iCACZD,EAAiBC,2CAEVN,oGAKJ9iB,cAAAA,yCAOKoiB,kDACZiB,aAQmC9nB,KAN7BonB,EAA4B,IAAIvb,QAMHsW,EAAK9J,eACrC0P,qCACQC,WACeF,YAAb1gB,OACHqgB,EAAqBtF,EAAK9J,eAAeqP,sBAC7CtgB,EAAUiX,wCAEoBoJ,EAAmBQ,eACjD7gB,mBADI8gB,OAIAC,EAAoBxa,YAAUya,eAClCF,EACAF,GAGEZ,EAA0B/jB,IAAI8kB,GAChCf,EAA0Blb,IAAIic,GAAoBjmB,KAAKkF,GAEvDggB,EAA0Brb,IAAIoc,EAAmB,CAAC/gB,mHAKjDggB,KAAAA,4CCxSUiB,wBAIPC,QACLA,YAAcA,qBAMdC,kBAAA,iBACE,CACLhf,KAAMvJ,KAAKsoB,YACXE,QAASH,EAAoBI,YAAYD,eAbrBH,cAAczkB,QAAQ,uBCmB3B8kB,wBAgBTC,EACRC,eADQD,kCAdoC,QAkBvCE,8BAAgCD,EAAiBrI,MACpD,SAACC,EAAGC,UAAMA,EAAEqI,uBAAyBtI,EAAEsI,+BAGpCC,aAAe,IAAIld,SACnBmd,oBAAsB,IAAInd,SAC1Bod,gBAAkB,IAAIpd,SACtBqd,gBAAkB,IAAIrd,SACtBsd,sBAAwB,IAAItd,SAC5Bud,qBAAuB,IAAIvd,SAC3Bwd,iBAAmB,IAAIxd,+BAMjByd,oBACXhR,EACAmC,EACA8O,EACAzK,EACA0K,EACAzK,2CA2FM0K,EAA+BpkB,MAAMnB,KACzCua,EAAK4K,iBAAiBpnB,UACtB,SAACzB,UAAUA,EAAMkpB,kCAEd3B,2BAA6B1iB,MAAMnB,KACtC,IAAId,IAAIqmB,YA1FoBzpB,SAAAye,EAAKoK,wCAAxBc,OACHnB,EAAUmB,EAAgBnB,+BAGI/J,EAAKmL,6BACvCpB,EACA,yCAFIqB,OAIAC,EAAiB,IAAID,EACzBpL,EAAKkK,OAAOoB,wBACZtL,EAAKkK,OAAOqB,qCAERF,EAAeR,wCAChBL,gBAAgBld,IAAIyc,EAASsB,mBAGCrL,EAAKmL,6BACtCpB,EACA,wCAFIyB,OAIA/H,EAAuB,IAAI+H,EAC/BV,EACAzK,EACAxG,cAGG6Q,sBAAsBpd,IAAIyc,EAAStG,mBAGNzD,EAAKmL,6BACrCpB,EACA,uCAFI0B,OAIA1L,EAAsB,IAAI0L,EAAoBnL,YAC/CqK,qBAAqBrd,IAAIyc,EAAShK,mBAGbC,EAAKmL,6BAC7BpB,EACA,+BAFI2B,OAIAnR,EAAc,IAAImR,EACtBL,EACAxR,EACAmC,cAGGsO,aAAahd,IAAIyc,EAASxP,mBAGEyF,EAAKmL,6BACpCpB,EACA,sCAFI4B,OAIA3C,EAAqB,IAAI2C,WAC1BpB,oBAAoBjd,IAAIyc,EAASf,mBAGThJ,EAAKmL,6BAChCpB,EACA,kCAFI6B,OAIAC,EAAiB,IAAID,EACzBb,EACAM,EACArL,EAAKkK,OAAO4B,wBAETrB,gBAAgBnd,IAAIyc,EAAS8B,mBAGJ7L,EAAKmL,6BACjCpB,EACA,mCAFIgC,OAIAC,EAAkB,IAAID,OACtBC,aAA2BC,iCACzB,IAAIhjB,gBACRijB,gBAAcC,4GACmDpC,KAGhEa,iBAAiBtd,IAAIyc,EAASiC,4IAgBhCvR,eAAA,SAAe2R,OACdrC,EAAUxoB,KAAK8qB,iBAAiBD,GAChC7R,EAAchZ,KAAK+oB,aAAa7c,IAAIsc,WAEtB/jB,IAAhBuU,QACI,IAAItR,gBACRijB,gBAAcI,sEACsBF,wBAIjC7R,KAMF0O,sBAAA,SAAsBmD,OACrBrC,EAAUxoB,KAAK8qB,iBAAiBD,GAChCpD,EAAqBznB,KAAKgpB,oBAAoB9c,IAAIsc,WAE7B/jB,IAAvBgjB,QACI,IAAI/f,gBACRijB,gBAAcK,oFAC6BH,wBAIxCpD,KAMFwD,kBAAA,SAAkBJ,OACjBrC,EAAUxoB,KAAK8qB,iBAAiBD,GAChCP,EAAiBtqB,KAAKkpB,gBAAgBhd,IAAIsc,WAEzB/jB,IAAnB6lB,QACI,IAAI5iB,gBACRijB,gBAAcO,4EACyBL,wBAIpCP,KAMFlI,wBAAA,SACLyI,OAEMrC,EAAUxoB,KAAK8qB,iBAAiBD,GAChC3I,EAAuBliB,KAAKmpB,sBAAsBjd,IAAIsc,WAE/B/jB,IAAzByd,QACI,IAAIxa,gBACRijB,gBAAcQ,wFAC+BN,wBAI1C3I,KAMFxD,uBAAA,SAAuBmM,OACtBrC,EAAUxoB,KAAK8qB,iBAAiBD,GAChCrM,EAAsBxe,KAAKopB,qBAAqBld,IAAIsc,WAE9B/jB,IAAxB+Z,QACI,IAAI9W,gBACRijB,gBAAcS,sFAC8BP,wBAIzCrM,KAGF6M,mBAAA,SAAmBR,OAClBS,EAAgBtrB,KAAK8qB,iBAAiBD,UACpB7qB,KAAKqpB,iBAAiBnd,IAAIof,MAK7CC,kBAAA,SAAkBV,OACjBS,EAAgBtrB,KAAK8qB,iBAAiBD,UACrB7qB,KAAKipB,gBAAgB/c,IAAIof,MAQ1CR,iBAAA,SAAiBD,iBAEO7qB,KAAK6oB,8CAA+B,KAAvDc,aACLkB,GAAkBlB,EAAgBb,8BAC7Ba,EAAgBnB,cAIrB,IAAI9gB,gBACRijB,gBAAca,yFACuCX,UAI3CjB,sCACZpB,EACAiD,oDAsBc,mDAAqBjD,MAAWiD,kCAAvCC,mCApBS,WAAZlD,SACMiD,OACD,oDACW,qCAAO,+CAAdE,EAA+B9B,6BACnC,mDACW,mCAAO,oEAAd+B,iBACJ,kDACW,mCAAO,mEAAdC,iBACJ,0CACW,mCAAO,2DAAdC,iBACJ,iDACW,mCAAO,kEAAdC,iBACJ,6CACW,mCAAO,8DAAdC,iBACJ,8CACW,mCAAO,+DAAdC,gzBvBkGV,SAAiBC,EAAcC,GACrC,IACInM,EADAoM,GAAiB,EAErBC,EAAO,CACN,IAAK,IAAIlrB,EAAI,EAAGA,EAAIgrB,EAAM9qB,OAAQF,IAAK,CACtC,IAAIiB,EAAO+pB,EAAMhrB,GAAG,GACpB,GAAIiB,EAAM,CACT,IAAIkqB,EAAYlqB,IAChB,GAAIkqB,GAAaA,EAAU3sB,KAC1B,MAAM0sB,EAEP,GAAIC,IAAcJ,EAAc,CAC/BE,EAAgBjrB,EAChB,YAIDirB,EAAgBjrB,EAGlB,IAAuB,IAAnBirB,EAAsB,CACzB,EAAG,CAEF,IADA,IAAIprB,EAAOmrB,EAAMC,GAAe,IACxBprB,GACPorB,IACAprB,EAAOmrB,EAAMC,GAAe,GAE7B,IAAItsB,EAASkB,IACb,GAAIlB,GAAUA,EAAOH,KAAM,CAC1BqgB,GAAY,EACZ,MAAMqM,EAEP,IAAIE,EAAmBJ,EAAMC,GAAe,GAC5CA,UACQG,IAAqBA,KAC9B,OAAOzsB,GAGT,MAAMW,EAAO,IAAIhB,EACXyB,EAASf,EAAQO,KAAK,KAAMD,EAAM,GAExC,OADCuf,EAAYlgB,EAAOH,KAAK+C,GAAoB4pB,EAAU3sB,MAEvD,SAAS8C,EAAiBjC,GACzB,OAAS,CACR,GAAIA,IAAU0rB,EAAc,CAC3BE,EAAgBjrB,EAChB,MAED,KAAMA,IAAMgrB,EAAM9qB,OAAQ,CACzB,IAAuB,IAAnB+qB,EACH,MAGA,YADAjsB,EAAQM,EAAM,EAAGX,GAKnB,GADAsC,EAAO+pB,EAAMhrB,GAAG,IAGf,IADAX,EAAQ4B,MACK5B,EAAMb,KAElB,YADAa,EAAMb,KAAK8C,GAAkB9C,UAAK,EAAQuB,QAI3CkrB,EAAgBjrB,EAGlB,EAAG,CAEF,IADA,IAAIH,EAAOmrB,EAAMC,GAAe,IACxBprB,GACPorB,IACAprB,EAAOmrB,EAAMC,GAAe,GAE7B,IAAItsB,EAASkB,IACb,GAAIlB,GAAUA,EAAOH,KAEpB,YADAG,EAAOH,KAAK+C,GAAkB/C,UAAK,EAAQuB,GAG5C,IAAIqrB,EAAmBJ,EAAMC,GAAe,GAC5CA,UACQG,IAAqBA,KAC9BpsB,EAAQM,EAAM,EAAGX,OAzC6DH,UAAK,EAAQuB,GACrFT,EA0CP,SAASiC,EAAiB5C,GACzB,OAAS,CACR,IAAIysB,EAAmBJ,EAAMC,GAAe,GAC5C,IAAKG,GAAoBA,IACxB,MAEDH,IAEA,IADA,IAAIprB,EAAOmrB,EAAMC,GAAe,IACxBprB,GACPorB,IACAprB,EAAOmrB,EAAMC,GAAe,GAG7B,IADAtsB,EAASkB,MACKlB,EAAOH,KAEpB,YADAG,EAAOH,KAAK+C,GAAkB/C,UAAK,EAAQuB,GAI7Cf,EAAQM,EAAM,EAAGX"}